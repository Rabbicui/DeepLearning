{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQ7NBkEebp7ssZlsg61dsx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rabbicui/DeepLearning/blob/master/%E8%AE%BA%E6%96%87%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc0IlavCvgSD"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from process import *\n",
        "from utils import *\n",
        "from model import *\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data\n",
        "from utils import *\n",
        "from model import *\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score\n",
        "import uuid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "I1d3TSAN8qtp",
        "outputId": "c013adc8-d340-434d-dab3-6d3b0f435fab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0c50e3fe6079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rSE9Qj9e9lrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 参数设置\n",
        "seed = 42\n",
        "epochs = 1500\n",
        "lr = 0.01\n",
        "weight_decay = 5e-6\n",
        "layer = 16\n",
        "hidden = 64\n",
        "dropout = 0.5\n",
        "patience = 50\n",
        "data = 'pubmed'\n",
        "dev = 0\n",
        "alpha = 0.1\n",
        "lamda = 0.5\n",
        "variant = True\n"
      ],
      "metadata": {
        "id": "z0w_h8XJxtvS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1vV0DU02s4g",
        "outputId": "55019549-6c67-4f7e-ccf0-3dc671113b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "cudaid = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(cudaid)\n",
        "checkpt_file = uuid.uuid4().hex+'.pt'\n",
        "print(cudaid,checkpt_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRJp2Mea0G5C",
        "outputId": "60316126-e291-4216-c4d3-9db31e628957"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda ab50f9460dc9470e8a476a569b34420c.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model,optimizer,features,labels,adj,idx_train):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(features,adj)\n",
        "    acc_train = accuracy(output[idx_train], labels[idx_train].to(device))\n",
        "    loss_train = F.nll_loss(output[idx_train], labels[idx_train].to(device))\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    return loss_train.item(),acc_train.item()\n",
        "\n",
        "def validate_step(model,features,labels,adj,idx_val):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(features,adj)\n",
        "        loss_val = F.nll_loss(output[idx_val], labels[idx_val].to(device))\n",
        "        acc_val = accuracy(output[idx_val], labels[idx_val].to(device))\n",
        "        return loss_val.item(),acc_val.item()\n",
        "\n",
        "def test_step(model,features,labels,adj,idx_test):\n",
        "    model.load_state_dict(torch.load(checkpt_file))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(features, adj)\n",
        "        loss_test = F.nll_loss(output[idx_test], labels[idx_test].to(device))\n",
        "        acc_test = accuracy(output[idx_test], labels[idx_test].to(device))\n",
        "        return loss_test.item(),acc_test.item()\n",
        "    "
      ],
      "metadata": {
        "id": "Et39lqZ40Rzj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(datastr,splitstr):\n",
        "    adj, features, labels, idx_train, idx_val, idx_test, num_features, num_labels = full_load_data(datastr,splitstr)\n",
        "    features = features.to(device)\n",
        "    adj = adj.to(device)\n",
        "    model = GCNII(nfeat=num_features,\n",
        "                nlayers=layer,\n",
        "                nhidden=hidden,\n",
        "                nclass=num_labels,\n",
        "                dropout=dropout,\n",
        "                lamda = lamda, \n",
        "                alpha=alpha,\n",
        "                variant=variant).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr,\n",
        "                            weight_decay=weight_decay)\n",
        "\n",
        "    bad_counter = 0\n",
        "    best = 999999999\n",
        "    for epoch in range(epochs):\n",
        "        loss_tra,acc_tra = train_step(model,optimizer,features,labels,adj,idx_train)\n",
        "        loss_val,acc_val = validate_step(model,features,labels,adj,idx_val)\n",
        "        if(epoch+1)%1 == 0: \n",
        "            print('Epoch:{:04d}'.format(epoch+1),\n",
        "                'train',\n",
        "                'loss:{:.3f}'.format(loss_tra),\n",
        "                'acc:{:.2f}'.format(acc_tra*100),\n",
        "                '| val',\n",
        "                'loss:{:.3f}'.format(loss_val),\n",
        "                'acc:{:.2f}'.format(acc_val*100))\n",
        "        if loss_val < best:\n",
        "            best = loss_val\n",
        "            torch.save(model.state_dict(), checkpt_file)\n",
        "            bad_counter = 0\n",
        "        else:\n",
        "            bad_counter += 1\n",
        "\n",
        "        if bad_counter == patience:\n",
        "            break\n",
        "    acc = test_step(model,features,labels,adj,idx_test)[1]\n",
        "\n",
        "    return acc*100"
      ],
      "metadata": {
        "id": "WUw-flMX0lJq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_total = time.time()\n",
        "acc_list = []\n",
        "# 十折交叉验证\n",
        "for i in range(10):\n",
        "    datastr = data\n",
        "    splitstr = data+'_split_0.6_0.2_'+str(i)+'.npz'\n",
        "    acc_list.append(train(datastr,splitstr))\n",
        "    print(i,\": {:.2f}\".format(acc_list[-1]))\n",
        "print(\"Train cost: {:.4f}s\".format(time.time() - t_total))\n",
        "print(\"Test acc.:{:.2f}\".format(np.mean(acc_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFi5LAVD1Aq-",
        "outputId": "699d9797-5e0b-4169-aaa6-9fd1254338c3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "Epoch:0341 train loss:0.287 acc:89.36 | val loss:0.264 acc:90.19\n",
            "Epoch:0342 train loss:0.290 acc:89.45 | val loss:0.262 acc:90.24\n",
            "Epoch:0343 train loss:0.288 acc:89.49 | val loss:0.265 acc:90.14\n",
            "Epoch:0344 train loss:0.289 acc:89.12 | val loss:0.263 acc:90.14\n",
            "Epoch:0345 train loss:0.286 acc:89.35 | val loss:0.263 acc:90.27\n",
            "Epoch:0346 train loss:0.288 acc:89.36 | val loss:0.262 acc:90.19\n",
            "Epoch:0347 train loss:0.276 acc:89.82 | val loss:0.263 acc:90.11\n",
            "Epoch:0348 train loss:0.289 acc:89.60 | val loss:0.263 acc:90.22\n",
            "Epoch:0349 train loss:0.289 acc:88.86 | val loss:0.262 acc:90.16\n",
            "Epoch:0350 train loss:0.281 acc:89.58 | val loss:0.261 acc:90.25\n",
            "Epoch:0351 train loss:0.284 acc:89.55 | val loss:0.262 acc:90.25\n",
            "Epoch:0352 train loss:0.278 acc:89.93 | val loss:0.263 acc:90.14\n",
            "Epoch:0353 train loss:0.277 acc:89.90 | val loss:0.264 acc:90.16\n",
            "Epoch:0354 train loss:0.280 acc:89.80 | val loss:0.263 acc:90.13\n",
            "Epoch:0355 train loss:0.281 acc:89.80 | val loss:0.263 acc:90.16\n",
            "Epoch:0356 train loss:0.291 acc:89.40 | val loss:0.262 acc:90.16\n",
            "Epoch:0357 train loss:0.282 acc:90.02 | val loss:0.261 acc:90.14\n",
            "Epoch:0358 train loss:0.279 acc:89.94 | val loss:0.261 acc:90.25\n",
            "Epoch:0359 train loss:0.283 acc:89.04 | val loss:0.260 acc:90.36\n",
            "Epoch:0360 train loss:0.287 acc:89.46 | val loss:0.259 acc:90.17\n",
            "Epoch:0361 train loss:0.283 acc:89.76 | val loss:0.259 acc:90.14\n",
            "Epoch:0362 train loss:0.284 acc:89.68 | val loss:0.260 acc:90.22\n",
            "Epoch:0363 train loss:0.285 acc:89.80 | val loss:0.261 acc:90.27\n",
            "Epoch:0364 train loss:0.276 acc:89.70 | val loss:0.261 acc:90.13\n",
            "Epoch:0365 train loss:0.280 acc:89.36 | val loss:0.262 acc:90.19\n",
            "Epoch:0366 train loss:0.283 acc:89.72 | val loss:0.260 acc:90.22\n",
            "Epoch:0367 train loss:0.280 acc:89.84 | val loss:0.259 acc:90.36\n",
            "Epoch:0368 train loss:0.281 acc:89.49 | val loss:0.260 acc:90.38\n",
            "Epoch:0369 train loss:0.284 acc:89.77 | val loss:0.260 acc:90.22\n",
            "Epoch:0370 train loss:0.280 acc:89.99 | val loss:0.261 acc:90.11\n",
            "Epoch:0371 train loss:0.287 acc:89.24 | val loss:0.263 acc:90.10\n",
            "Epoch:0372 train loss:0.280 acc:89.46 | val loss:0.263 acc:90.19\n",
            "Epoch:0373 train loss:0.275 acc:89.99 | val loss:0.261 acc:90.21\n",
            "Epoch:0374 train loss:0.274 acc:89.86 | val loss:0.261 acc:90.13\n",
            "Epoch:0375 train loss:0.285 acc:89.55 | val loss:0.259 acc:90.17\n",
            "Epoch:0376 train loss:0.282 acc:89.46 | val loss:0.260 acc:90.41\n",
            "Epoch:0377 train loss:0.277 acc:89.92 | val loss:0.262 acc:90.24\n",
            "Epoch:0378 train loss:0.282 acc:89.67 | val loss:0.260 acc:90.22\n",
            "Epoch:0379 train loss:0.285 acc:89.59 | val loss:0.260 acc:90.11\n",
            "Epoch:0380 train loss:0.286 acc:89.37 | val loss:0.265 acc:90.35\n",
            "Epoch:0381 train loss:0.285 acc:89.47 | val loss:0.261 acc:90.06\n",
            "Epoch:0382 train loss:0.274 acc:89.96 | val loss:0.266 acc:90.02\n",
            "Epoch:0383 train loss:0.287 acc:89.53 | val loss:0.261 acc:90.10\n",
            "Epoch:0384 train loss:0.282 acc:89.51 | val loss:0.260 acc:90.25\n",
            "Epoch:0385 train loss:0.279 acc:89.71 | val loss:0.261 acc:90.21\n",
            "Epoch:0386 train loss:0.278 acc:89.60 | val loss:0.261 acc:90.33\n",
            "Epoch:0387 train loss:0.286 acc:89.38 | val loss:0.262 acc:90.19\n",
            "Epoch:0388 train loss:0.274 acc:89.89 | val loss:0.264 acc:90.11\n",
            "Epoch:0389 train loss:0.282 acc:89.73 | val loss:0.261 acc:90.22\n",
            "Epoch:0390 train loss:0.277 acc:89.88 | val loss:0.261 acc:90.30\n",
            "Epoch:0391 train loss:0.279 acc:89.96 | val loss:0.260 acc:90.30\n",
            "Epoch:0392 train loss:0.275 acc:90.08 | val loss:0.260 acc:90.32\n",
            "Epoch:0393 train loss:0.283 acc:89.75 | val loss:0.260 acc:90.25\n",
            "Epoch:0394 train loss:0.281 acc:89.60 | val loss:0.259 acc:90.27\n",
            "Epoch:0395 train loss:0.278 acc:89.79 | val loss:0.258 acc:90.29\n",
            "Epoch:0396 train loss:0.276 acc:90.02 | val loss:0.258 acc:90.29\n",
            "Epoch:0397 train loss:0.285 acc:89.40 | val loss:0.260 acc:90.22\n",
            "Epoch:0398 train loss:0.280 acc:89.68 | val loss:0.260 acc:90.24\n",
            "Epoch:0399 train loss:0.279 acc:89.56 | val loss:0.261 acc:90.17\n",
            "Epoch:0400 train loss:0.282 acc:89.60 | val loss:0.261 acc:90.29\n",
            "Epoch:0401 train loss:0.275 acc:90.08 | val loss:0.262 acc:90.27\n",
            "Epoch:0402 train loss:0.282 acc:89.92 | val loss:0.260 acc:90.32\n",
            "Epoch:0403 train loss:0.275 acc:89.73 | val loss:0.261 acc:90.36\n",
            "Epoch:0404 train loss:0.278 acc:89.70 | val loss:0.258 acc:90.24\n",
            "Epoch:0405 train loss:0.275 acc:89.65 | val loss:0.261 acc:90.21\n",
            "Epoch:0406 train loss:0.282 acc:89.67 | val loss:0.260 acc:90.27\n",
            "Epoch:0407 train loss:0.271 acc:89.96 | val loss:0.259 acc:90.24\n",
            "Epoch:0408 train loss:0.274 acc:89.94 | val loss:0.264 acc:90.06\n",
            "Epoch:0409 train loss:0.280 acc:89.81 | val loss:0.260 acc:90.29\n",
            "Epoch:0410 train loss:0.277 acc:89.82 | val loss:0.260 acc:90.29\n",
            "Epoch:0411 train loss:0.281 acc:89.76 | val loss:0.256 acc:90.35\n",
            "Epoch:0412 train loss:0.275 acc:89.99 | val loss:0.257 acc:90.41\n",
            "Epoch:0413 train loss:0.279 acc:89.75 | val loss:0.258 acc:90.35\n",
            "Epoch:0414 train loss:0.280 acc:89.82 | val loss:0.257 acc:90.36\n",
            "Epoch:0415 train loss:0.279 acc:89.60 | val loss:0.257 acc:90.41\n",
            "Epoch:0416 train loss:0.279 acc:90.20 | val loss:0.259 acc:90.33\n",
            "Epoch:0417 train loss:0.275 acc:89.89 | val loss:0.259 acc:90.41\n",
            "Epoch:0418 train loss:0.266 acc:90.27 | val loss:0.261 acc:90.29\n",
            "Epoch:0419 train loss:0.272 acc:89.97 | val loss:0.259 acc:90.25\n",
            "Epoch:0420 train loss:0.274 acc:89.98 | val loss:0.259 acc:90.44\n",
            "Epoch:0421 train loss:0.270 acc:90.07 | val loss:0.259 acc:90.36\n",
            "Epoch:0422 train loss:0.281 acc:89.80 | val loss:0.259 acc:90.40\n",
            "Epoch:0423 train loss:0.278 acc:89.74 | val loss:0.260 acc:90.24\n",
            "Epoch:0424 train loss:0.277 acc:89.95 | val loss:0.262 acc:90.10\n",
            "Epoch:0425 train loss:0.281 acc:89.80 | val loss:0.258 acc:90.43\n",
            "Epoch:0426 train loss:0.270 acc:89.81 | val loss:0.261 acc:90.49\n",
            "Epoch:0427 train loss:0.283 acc:89.72 | val loss:0.264 acc:90.14\n",
            "Epoch:0428 train loss:0.279 acc:89.63 | val loss:0.262 acc:90.29\n",
            "Epoch:0429 train loss:0.272 acc:89.61 | val loss:0.266 acc:90.17\n",
            "Epoch:0430 train loss:0.276 acc:89.73 | val loss:0.261 acc:90.22\n",
            "Epoch:0431 train loss:0.275 acc:90.02 | val loss:0.270 acc:89.97\n",
            "Epoch:0432 train loss:0.287 acc:89.39 | val loss:0.259 acc:90.41\n",
            "Epoch:0433 train loss:0.273 acc:89.76 | val loss:0.258 acc:90.48\n",
            "Epoch:0434 train loss:0.277 acc:89.58 | val loss:0.263 acc:90.08\n",
            "Epoch:0435 train loss:0.281 acc:89.83 | val loss:0.259 acc:90.19\n",
            "Epoch:0436 train loss:0.279 acc:89.51 | val loss:0.261 acc:90.52\n",
            "Epoch:0437 train loss:0.276 acc:89.73 | val loss:0.257 acc:90.48\n",
            "Epoch:0438 train loss:0.273 acc:90.11 | val loss:0.271 acc:89.84\n",
            "Epoch:0439 train loss:0.283 acc:89.63 | val loss:0.259 acc:90.27\n",
            "Epoch:0440 train loss:0.270 acc:90.09 | val loss:0.274 acc:90.02\n",
            "Epoch:0441 train loss:0.280 acc:89.73 | val loss:0.259 acc:90.33\n",
            "Epoch:0442 train loss:0.272 acc:90.24 | val loss:0.264 acc:90.16\n",
            "Epoch:0443 train loss:0.273 acc:89.89 | val loss:0.257 acc:90.41\n",
            "Epoch:0444 train loss:0.265 acc:89.74 | val loss:0.262 acc:90.48\n",
            "Epoch:0445 train loss:0.279 acc:89.27 | val loss:0.257 acc:90.43\n",
            "Epoch:0446 train loss:0.270 acc:90.37 | val loss:0.265 acc:90.06\n",
            "Epoch:0447 train loss:0.282 acc:89.34 | val loss:0.259 acc:90.21\n",
            "Epoch:0448 train loss:0.276 acc:89.94 | val loss:0.262 acc:90.32\n",
            "Epoch:0449 train loss:0.280 acc:89.77 | val loss:0.259 acc:90.41\n",
            "Epoch:0450 train loss:0.275 acc:90.01 | val loss:0.261 acc:90.13\n",
            "Epoch:0451 train loss:0.270 acc:90.39 | val loss:0.261 acc:90.13\n",
            "Epoch:0452 train loss:0.284 acc:89.63 | val loss:0.256 acc:90.52\n",
            "Epoch:0453 train loss:0.271 acc:90.15 | val loss:0.262 acc:90.60\n",
            "Epoch:0454 train loss:0.276 acc:89.55 | val loss:0.257 acc:90.46\n",
            "Epoch:0455 train loss:0.265 acc:90.15 | val loss:0.265 acc:90.14\n",
            "Epoch:0456 train loss:0.277 acc:89.93 | val loss:0.257 acc:90.48\n",
            "Epoch:0457 train loss:0.274 acc:90.36 | val loss:0.262 acc:90.14\n",
            "Epoch:0458 train loss:0.276 acc:89.78 | val loss:0.257 acc:90.36\n",
            "Epoch:0459 train loss:0.264 acc:90.52 | val loss:0.267 acc:90.05\n",
            "Epoch:0460 train loss:0.275 acc:89.78 | val loss:0.256 acc:90.46\n",
            "Epoch:0461 train loss:0.265 acc:90.36 | val loss:0.262 acc:90.22\n",
            "Epoch:0462 train loss:0.267 acc:90.29 | val loss:0.258 acc:90.38\n",
            "Epoch:0463 train loss:0.261 acc:90.28 | val loss:0.258 acc:90.40\n",
            "Epoch:0464 train loss:0.269 acc:90.08 | val loss:0.258 acc:90.29\n",
            "Epoch:0465 train loss:0.274 acc:90.03 | val loss:0.257 acc:90.44\n",
            "Epoch:0466 train loss:0.269 acc:90.14 | val loss:0.258 acc:90.32\n",
            "Epoch:0467 train loss:0.274 acc:89.57 | val loss:0.260 acc:90.19\n",
            "Epoch:0468 train loss:0.274 acc:89.87 | val loss:0.258 acc:90.27\n",
            "Epoch:0469 train loss:0.270 acc:89.97 | val loss:0.255 acc:90.41\n",
            "Epoch:0470 train loss:0.268 acc:90.35 | val loss:0.257 acc:90.38\n",
            "Epoch:0471 train loss:0.276 acc:89.95 | val loss:0.255 acc:90.44\n",
            "Epoch:0472 train loss:0.271 acc:89.56 | val loss:0.258 acc:90.29\n",
            "Epoch:0473 train loss:0.271 acc:90.25 | val loss:0.259 acc:90.29\n",
            "Epoch:0474 train loss:0.268 acc:89.94 | val loss:0.257 acc:90.27\n",
            "Epoch:0475 train loss:0.264 acc:89.93 | val loss:0.261 acc:90.32\n",
            "Epoch:0476 train loss:0.276 acc:89.83 | val loss:0.259 acc:90.41\n",
            "Epoch:0477 train loss:0.264 acc:90.39 | val loss:0.261 acc:90.40\n",
            "Epoch:0478 train loss:0.276 acc:89.89 | val loss:0.257 acc:90.41\n",
            "Epoch:0479 train loss:0.262 acc:90.48 | val loss:0.258 acc:90.36\n",
            "Epoch:0480 train loss:0.267 acc:90.09 | val loss:0.255 acc:90.55\n",
            "Epoch:0481 train loss:0.265 acc:90.12 | val loss:0.257 acc:90.40\n",
            "Epoch:0482 train loss:0.271 acc:90.01 | val loss:0.255 acc:90.52\n",
            "Epoch:0483 train loss:0.268 acc:90.02 | val loss:0.259 acc:90.38\n",
            "Epoch:0484 train loss:0.263 acc:90.61 | val loss:0.259 acc:90.29\n",
            "Epoch:0485 train loss:0.261 acc:90.71 | val loss:0.260 acc:90.35\n",
            "Epoch:0486 train loss:0.259 acc:90.34 | val loss:0.260 acc:90.41\n",
            "Epoch:0487 train loss:0.260 acc:90.47 | val loss:0.258 acc:90.46\n",
            "Epoch:0488 train loss:0.263 acc:90.44 | val loss:0.258 acc:90.32\n",
            "Epoch:0489 train loss:0.269 acc:90.07 | val loss:0.257 acc:90.46\n",
            "Epoch:0490 train loss:0.268 acc:90.28 | val loss:0.256 acc:90.48\n",
            "Epoch:0491 train loss:0.260 acc:90.55 | val loss:0.255 acc:90.48\n",
            "Epoch:0492 train loss:0.259 acc:90.54 | val loss:0.255 acc:90.48\n",
            "Epoch:0493 train loss:0.266 acc:90.26 | val loss:0.257 acc:90.36\n",
            "Epoch:0494 train loss:0.268 acc:90.13 | val loss:0.260 acc:90.14\n",
            "Epoch:0495 train loss:0.269 acc:90.13 | val loss:0.256 acc:90.46\n",
            "Epoch:0496 train loss:0.263 acc:90.33 | val loss:0.255 acc:90.51\n",
            "Epoch:0497 train loss:0.266 acc:90.46 | val loss:0.255 acc:90.46\n",
            "Epoch:0498 train loss:0.269 acc:90.35 | val loss:0.258 acc:90.43\n",
            "Epoch:0499 train loss:0.273 acc:89.84 | val loss:0.256 acc:90.49\n",
            "Epoch:0500 train loss:0.253 acc:90.67 | val loss:0.257 acc:90.44\n",
            "Epoch:0501 train loss:0.262 acc:90.44 | val loss:0.256 acc:90.59\n",
            "Epoch:0502 train loss:0.256 acc:90.58 | val loss:0.258 acc:90.59\n",
            "Epoch:0503 train loss:0.261 acc:90.27 | val loss:0.257 acc:90.51\n",
            "Epoch:0504 train loss:0.264 acc:90.29 | val loss:0.258 acc:90.44\n",
            "Epoch:0505 train loss:0.255 acc:90.66 | val loss:0.259 acc:90.38\n",
            "Epoch:0506 train loss:0.259 acc:90.52 | val loss:0.259 acc:90.52\n",
            "Epoch:0507 train loss:0.260 acc:90.67 | val loss:0.255 acc:90.51\n",
            "Epoch:0508 train loss:0.256 acc:90.65 | val loss:0.257 acc:90.57\n",
            "Epoch:0509 train loss:0.265 acc:89.94 | val loss:0.257 acc:90.36\n",
            "Epoch:0510 train loss:0.268 acc:90.35 | val loss:0.260 acc:90.38\n",
            "Epoch:0511 train loss:0.260 acc:90.18 | val loss:0.256 acc:90.51\n",
            "Epoch:0512 train loss:0.260 acc:90.48 | val loss:0.256 acc:90.49\n",
            "Epoch:0513 train loss:0.254 acc:90.46 | val loss:0.257 acc:90.48\n",
            "Epoch:0514 train loss:0.260 acc:90.59 | val loss:0.259 acc:90.38\n",
            "Epoch:0515 train loss:0.262 acc:90.18 | val loss:0.257 acc:90.52\n",
            "Epoch:0516 train loss:0.261 acc:90.21 | val loss:0.255 acc:90.54\n",
            "Epoch:0517 train loss:0.261 acc:90.49 | val loss:0.253 acc:90.55\n",
            "Epoch:0518 train loss:0.258 acc:90.50 | val loss:0.253 acc:90.67\n",
            "Epoch:0519 train loss:0.256 acc:90.87 | val loss:0.254 acc:90.51\n",
            "Epoch:0520 train loss:0.256 acc:90.87 | val loss:0.256 acc:90.49\n",
            "Epoch:0521 train loss:0.263 acc:90.28 | val loss:0.260 acc:90.52\n",
            "Epoch:0522 train loss:0.253 acc:90.75 | val loss:0.261 acc:90.36\n",
            "Epoch:0523 train loss:0.258 acc:90.69 | val loss:0.260 acc:90.52\n",
            "Epoch:0524 train loss:0.261 acc:90.54 | val loss:0.261 acc:90.59\n",
            "Epoch:0525 train loss:0.263 acc:90.06 | val loss:0.255 acc:90.46\n",
            "Epoch:0526 train loss:0.256 acc:90.61 | val loss:0.254 acc:90.44\n",
            "Epoch:0527 train loss:0.253 acc:90.39 | val loss:0.253 acc:90.60\n",
            "Epoch:0528 train loss:0.256 acc:90.45 | val loss:0.252 acc:90.62\n",
            "Epoch:0529 train loss:0.264 acc:90.43 | val loss:0.255 acc:90.57\n",
            "Epoch:0530 train loss:0.257 acc:90.95 | val loss:0.257 acc:90.43\n",
            "Epoch:0531 train loss:0.259 acc:90.37 | val loss:0.263 acc:90.46\n",
            "Epoch:0532 train loss:0.260 acc:90.54 | val loss:0.259 acc:90.43\n",
            "Epoch:0533 train loss:0.256 acc:90.68 | val loss:0.259 acc:90.33\n",
            "Epoch:0534 train loss:0.264 acc:90.40 | val loss:0.255 acc:90.49\n",
            "Epoch:0535 train loss:0.249 acc:90.64 | val loss:0.256 acc:90.55\n",
            "Epoch:0536 train loss:0.262 acc:90.39 | val loss:0.254 acc:90.62\n",
            "Epoch:0537 train loss:0.258 acc:90.52 | val loss:0.254 acc:90.46\n",
            "Epoch:0538 train loss:0.261 acc:90.70 | val loss:0.256 acc:90.35\n",
            "Epoch:0539 train loss:0.249 acc:90.80 | val loss:0.260 acc:90.33\n",
            "Epoch:0540 train loss:0.256 acc:90.46 | val loss:0.260 acc:90.25\n",
            "Epoch:0541 train loss:0.258 acc:90.61 | val loss:0.261 acc:90.41\n",
            "Epoch:0542 train loss:0.257 acc:90.73 | val loss:0.257 acc:90.54\n",
            "Epoch:0543 train loss:0.258 acc:90.35 | val loss:0.256 acc:90.62\n",
            "Epoch:0544 train loss:0.247 acc:91.12 | val loss:0.254 acc:90.63\n",
            "Epoch:0545 train loss:0.252 acc:91.12 | val loss:0.254 acc:90.63\n",
            "Epoch:0546 train loss:0.259 acc:90.27 | val loss:0.256 acc:90.36\n",
            "Epoch:0547 train loss:0.255 acc:90.68 | val loss:0.256 acc:90.29\n",
            "Epoch:0548 train loss:0.256 acc:90.69 | val loss:0.256 acc:90.71\n",
            "Epoch:0549 train loss:0.250 acc:91.04 | val loss:0.259 acc:90.62\n",
            "Epoch:0550 train loss:0.258 acc:90.69 | val loss:0.259 acc:90.46\n",
            "Epoch:0551 train loss:0.250 acc:90.79 | val loss:0.258 acc:90.32\n",
            "Epoch:0552 train loss:0.252 acc:90.79 | val loss:0.256 acc:90.30\n",
            "Epoch:0553 train loss:0.249 acc:90.95 | val loss:0.255 acc:90.52\n",
            "Epoch:0554 train loss:0.254 acc:91.03 | val loss:0.256 acc:90.52\n",
            "Epoch:0555 train loss:0.255 acc:90.44 | val loss:0.256 acc:90.65\n",
            "Epoch:0556 train loss:0.261 acc:90.39 | val loss:0.262 acc:90.35\n",
            "Epoch:0557 train loss:0.263 acc:90.14 | val loss:0.257 acc:90.38\n",
            "Epoch:0558 train loss:0.255 acc:90.90 | val loss:0.255 acc:90.55\n",
            "Epoch:0559 train loss:0.258 acc:90.49 | val loss:0.257 acc:90.63\n",
            "Epoch:0560 train loss:0.252 acc:90.93 | val loss:0.253 acc:90.40\n",
            "Epoch:0561 train loss:0.247 acc:91.02 | val loss:0.255 acc:90.33\n",
            "Epoch:0562 train loss:0.252 acc:90.73 | val loss:0.255 acc:90.54\n",
            "Epoch:0563 train loss:0.258 acc:90.95 | val loss:0.253 acc:90.59\n",
            "Epoch:0564 train loss:0.247 acc:91.03 | val loss:0.254 acc:90.54\n",
            "Epoch:0565 train loss:0.248 acc:91.12 | val loss:0.257 acc:90.48\n",
            "Epoch:0566 train loss:0.250 acc:91.08 | val loss:0.259 acc:90.40\n",
            "Epoch:0567 train loss:0.252 acc:90.61 | val loss:0.259 acc:90.35\n",
            "Epoch:0568 train loss:0.251 acc:90.90 | val loss:0.257 acc:90.65\n",
            "Epoch:0569 train loss:0.254 acc:90.86 | val loss:0.255 acc:90.84\n",
            "Epoch:0570 train loss:0.249 acc:91.11 | val loss:0.255 acc:90.70\n",
            "Epoch:0571 train loss:0.247 acc:90.81 | val loss:0.262 acc:90.21\n",
            "Epoch:0572 train loss:0.256 acc:90.69 | val loss:0.261 acc:90.21\n",
            "Epoch:0573 train loss:0.266 acc:90.26 | val loss:0.266 acc:90.63\n",
            "Epoch:0574 train loss:0.269 acc:89.81 | val loss:0.255 acc:90.60\n",
            "Epoch:0575 train loss:0.250 acc:90.54 | val loss:0.259 acc:90.48\n",
            "Epoch:0576 train loss:0.248 acc:90.99 | val loss:0.255 acc:90.59\n",
            "Epoch:0577 train loss:0.250 acc:90.90 | val loss:0.261 acc:90.43\n",
            "Epoch:0578 train loss:0.257 acc:90.51 | val loss:0.259 acc:90.35\n",
            "0 : 90.44\n",
            "Epoch:0001 train loss:1.085 acc:39.46 | val loss:1.075 acc:40.94\n",
            "Epoch:0002 train loss:1.078 acc:39.46 | val loss:1.068 acc:40.94\n",
            "Epoch:0003 train loss:1.071 acc:39.46 | val loss:1.058 acc:40.94\n",
            "Epoch:0004 train loss:1.063 acc:39.51 | val loss:1.047 acc:40.94\n",
            "Epoch:0005 train loss:1.053 acc:39.74 | val loss:1.035 acc:41.95\n",
            "Epoch:0006 train loss:1.044 acc:43.02 | val loss:1.027 acc:57.51\n",
            "Epoch:0007 train loss:1.036 acc:47.10 | val loss:1.016 acc:52.30\n",
            "Epoch:0008 train loss:1.026 acc:47.96 | val loss:1.001 acc:57.15\n",
            "Epoch:0009 train loss:1.010 acc:51.55 | val loss:0.985 acc:63.11\n",
            "Epoch:0010 train loss:0.996 acc:55.14 | val loss:0.965 acc:65.99\n",
            "Epoch:0011 train loss:0.976 acc:56.14 | val loss:0.941 acc:65.90\n",
            "Epoch:0012 train loss:0.954 acc:57.59 | val loss:0.910 acc:66.85\n",
            "Epoch:0013 train loss:0.927 acc:59.00 | val loss:0.872 acc:65.15\n",
            "Epoch:0014 train loss:0.891 acc:59.94 | val loss:0.836 acc:61.95\n",
            "Epoch:0015 train loss:0.867 acc:59.54 | val loss:0.797 acc:64.66\n",
            "Epoch:0016 train loss:0.827 acc:61.61 | val loss:0.760 acc:68.95\n",
            "Epoch:0017 train loss:0.797 acc:63.38 | val loss:0.721 acc:70.59\n",
            "Epoch:0018 train loss:0.758 acc:65.75 | val loss:0.677 acc:73.98\n",
            "Epoch:0019 train loss:0.725 acc:68.48 | val loss:0.634 acc:78.45\n",
            "Epoch:0020 train loss:0.696 acc:70.44 | val loss:0.613 acc:78.75\n",
            "Epoch:0021 train loss:0.678 acc:73.01 | val loss:0.587 acc:80.98\n",
            "Epoch:0022 train loss:0.646 acc:75.71 | val loss:0.559 acc:81.24\n",
            "Epoch:0023 train loss:0.622 acc:77.15 | val loss:0.553 acc:80.55\n",
            "Epoch:0024 train loss:0.615 acc:78.17 | val loss:0.527 acc:81.57\n",
            "Epoch:0025 train loss:0.594 acc:78.64 | val loss:0.509 acc:81.97\n",
            "Epoch:0026 train loss:0.573 acc:79.83 | val loss:0.519 acc:81.43\n",
            "Epoch:0027 train loss:0.599 acc:79.41 | val loss:0.501 acc:82.12\n",
            "Epoch:0028 train loss:0.574 acc:79.92 | val loss:0.488 acc:82.39\n",
            "Epoch:0029 train loss:0.555 acc:80.50 | val loss:0.500 acc:81.89\n",
            "Epoch:0030 train loss:0.565 acc:80.21 | val loss:0.474 acc:82.49\n",
            "Epoch:0031 train loss:0.547 acc:80.78 | val loss:0.477 acc:82.46\n",
            "Epoch:0032 train loss:0.550 acc:80.66 | val loss:0.459 acc:82.93\n",
            "Epoch:0033 train loss:0.523 acc:81.45 | val loss:0.461 acc:82.71\n",
            "Epoch:0034 train loss:0.534 acc:81.23 | val loss:0.455 acc:82.87\n",
            "Epoch:0035 train loss:0.518 acc:82.09 | val loss:0.442 acc:83.44\n",
            "Epoch:0036 train loss:0.508 acc:81.83 | val loss:0.445 acc:83.76\n",
            "Epoch:0037 train loss:0.508 acc:81.92 | val loss:0.438 acc:84.10\n",
            "Epoch:0038 train loss:0.505 acc:82.60 | val loss:0.431 acc:84.12\n",
            "Epoch:0039 train loss:0.495 acc:82.14 | val loss:0.432 acc:83.93\n",
            "Epoch:0040 train loss:0.501 acc:82.61 | val loss:0.426 acc:84.22\n",
            "Epoch:0041 train loss:0.489 acc:82.82 | val loss:0.421 acc:84.63\n",
            "Epoch:0042 train loss:0.485 acc:82.81 | val loss:0.418 acc:84.56\n",
            "Epoch:0043 train loss:0.480 acc:83.07 | val loss:0.411 acc:84.74\n",
            "Epoch:0044 train loss:0.479 acc:82.74 | val loss:0.407 acc:84.77\n",
            "Epoch:0045 train loss:0.469 acc:83.13 | val loss:0.403 acc:84.90\n",
            "Epoch:0046 train loss:0.478 acc:83.27 | val loss:0.399 acc:85.04\n",
            "Epoch:0047 train loss:0.463 acc:83.65 | val loss:0.399 acc:85.12\n",
            "Epoch:0048 train loss:0.459 acc:83.63 | val loss:0.394 acc:85.13\n",
            "Epoch:0049 train loss:0.453 acc:83.67 | val loss:0.387 acc:85.32\n",
            "Epoch:0050 train loss:0.451 acc:83.60 | val loss:0.385 acc:85.42\n",
            "Epoch:0051 train loss:0.447 acc:84.05 | val loss:0.380 acc:85.61\n",
            "Epoch:0052 train loss:0.444 acc:84.25 | val loss:0.378 acc:85.42\n",
            "Epoch:0053 train loss:0.444 acc:84.23 | val loss:0.375 acc:85.45\n",
            "Epoch:0054 train loss:0.441 acc:84.42 | val loss:0.373 acc:85.61\n",
            "Epoch:0055 train loss:0.433 acc:84.58 | val loss:0.372 acc:85.67\n",
            "Epoch:0056 train loss:0.441 acc:84.35 | val loss:0.368 acc:85.80\n",
            "Epoch:0057 train loss:0.420 acc:84.98 | val loss:0.366 acc:85.94\n",
            "Epoch:0058 train loss:0.430 acc:84.63 | val loss:0.363 acc:86.24\n",
            "Epoch:0059 train loss:0.426 acc:84.86 | val loss:0.360 acc:86.39\n",
            "Epoch:0060 train loss:0.422 acc:84.96 | val loss:0.358 acc:86.47\n",
            "Epoch:0061 train loss:0.418 acc:85.23 | val loss:0.357 acc:86.29\n",
            "Epoch:0062 train loss:0.409 acc:85.22 | val loss:0.355 acc:86.40\n",
            "Epoch:0063 train loss:0.419 acc:85.22 | val loss:0.353 acc:86.62\n",
            "Epoch:0064 train loss:0.413 acc:85.28 | val loss:0.350 acc:86.56\n",
            "Epoch:0065 train loss:0.407 acc:85.45 | val loss:0.348 acc:86.78\n",
            "Epoch:0066 train loss:0.409 acc:85.03 | val loss:0.346 acc:86.86\n",
            "Epoch:0067 train loss:0.405 acc:85.47 | val loss:0.344 acc:86.83\n",
            "Epoch:0068 train loss:0.405 acc:85.61 | val loss:0.343 acc:87.00\n",
            "Epoch:0069 train loss:0.414 acc:85.32 | val loss:0.342 acc:86.93\n",
            "Epoch:0070 train loss:0.398 acc:85.59 | val loss:0.341 acc:86.85\n",
            "Epoch:0071 train loss:0.400 acc:85.79 | val loss:0.340 acc:86.89\n",
            "Epoch:0072 train loss:0.400 acc:85.74 | val loss:0.337 acc:86.94\n",
            "Epoch:0073 train loss:0.395 acc:85.90 | val loss:0.335 acc:87.16\n",
            "Epoch:0074 train loss:0.399 acc:85.96 | val loss:0.334 acc:87.21\n",
            "Epoch:0075 train loss:0.393 acc:85.80 | val loss:0.333 acc:87.29\n",
            "Epoch:0076 train loss:0.403 acc:85.76 | val loss:0.332 acc:87.19\n",
            "Epoch:0077 train loss:0.389 acc:86.38 | val loss:0.334 acc:87.10\n",
            "Epoch:0078 train loss:0.397 acc:85.98 | val loss:0.331 acc:87.19\n",
            "Epoch:0079 train loss:0.382 acc:86.36 | val loss:0.330 acc:87.26\n",
            "Epoch:0080 train loss:0.393 acc:86.18 | val loss:0.328 acc:87.37\n",
            "Epoch:0081 train loss:0.388 acc:86.47 | val loss:0.326 acc:87.59\n",
            "Epoch:0082 train loss:0.391 acc:85.91 | val loss:0.328 acc:87.64\n",
            "Epoch:0083 train loss:0.390 acc:86.51 | val loss:0.325 acc:87.51\n",
            "Epoch:0084 train loss:0.390 acc:86.33 | val loss:0.328 acc:87.23\n",
            "Epoch:0085 train loss:0.389 acc:85.92 | val loss:0.326 acc:87.27\n",
            "Epoch:0086 train loss:0.383 acc:86.47 | val loss:0.323 acc:87.67\n",
            "Epoch:0087 train loss:0.373 acc:86.72 | val loss:0.323 acc:87.75\n",
            "Epoch:0088 train loss:0.386 acc:86.43 | val loss:0.320 acc:87.86\n",
            "Epoch:0089 train loss:0.372 acc:87.18 | val loss:0.325 acc:87.56\n",
            "Epoch:0090 train loss:0.388 acc:86.14 | val loss:0.320 acc:87.54\n",
            "Epoch:0091 train loss:0.378 acc:87.07 | val loss:0.322 acc:87.54\n",
            "Epoch:0092 train loss:0.378 acc:86.24 | val loss:0.319 acc:87.70\n",
            "Epoch:0093 train loss:0.371 acc:86.73 | val loss:0.318 acc:87.56\n",
            "Epoch:0094 train loss:0.378 acc:86.65 | val loss:0.318 acc:87.67\n",
            "Epoch:0095 train loss:0.371 acc:86.89 | val loss:0.315 acc:87.69\n",
            "Epoch:0096 train loss:0.368 acc:87.00 | val loss:0.316 acc:87.84\n",
            "Epoch:0097 train loss:0.380 acc:86.43 | val loss:0.315 acc:87.91\n",
            "Epoch:0098 train loss:0.370 acc:86.72 | val loss:0.316 acc:87.58\n",
            "Epoch:0099 train loss:0.365 acc:86.74 | val loss:0.316 acc:87.70\n",
            "Epoch:0100 train loss:0.367 acc:86.51 | val loss:0.312 acc:87.99\n",
            "Epoch:0101 train loss:0.364 acc:86.66 | val loss:0.312 acc:88.26\n",
            "Epoch:0102 train loss:0.361 acc:87.26 | val loss:0.311 acc:88.23\n",
            "Epoch:0103 train loss:0.362 acc:87.42 | val loss:0.311 acc:88.15\n",
            "Epoch:0104 train loss:0.367 acc:87.34 | val loss:0.314 acc:87.88\n",
            "Epoch:0105 train loss:0.358 acc:87.16 | val loss:0.311 acc:87.91\n",
            "Epoch:0106 train loss:0.365 acc:86.94 | val loss:0.312 acc:88.00\n",
            "Epoch:0107 train loss:0.366 acc:86.77 | val loss:0.309 acc:88.24\n",
            "Epoch:0108 train loss:0.362 acc:86.78 | val loss:0.308 acc:88.38\n",
            "Epoch:0109 train loss:0.362 acc:87.35 | val loss:0.308 acc:88.37\n",
            "Epoch:0110 train loss:0.355 acc:87.52 | val loss:0.306 acc:88.30\n",
            "Epoch:0111 train loss:0.362 acc:87.29 | val loss:0.308 acc:88.24\n",
            "Epoch:0112 train loss:0.363 acc:86.84 | val loss:0.307 acc:88.19\n",
            "Epoch:0113 train loss:0.356 acc:87.34 | val loss:0.307 acc:88.11\n",
            "Epoch:0114 train loss:0.360 acc:87.02 | val loss:0.304 acc:88.49\n",
            "Epoch:0115 train loss:0.354 acc:86.81 | val loss:0.303 acc:88.46\n",
            "Epoch:0116 train loss:0.355 acc:87.34 | val loss:0.302 acc:88.53\n",
            "Epoch:0117 train loss:0.351 acc:87.56 | val loss:0.302 acc:88.62\n",
            "Epoch:0118 train loss:0.354 acc:87.21 | val loss:0.302 acc:88.56\n",
            "Epoch:0119 train loss:0.359 acc:87.01 | val loss:0.302 acc:88.48\n",
            "Epoch:0120 train loss:0.350 acc:87.41 | val loss:0.301 acc:88.57\n",
            "Epoch:0121 train loss:0.351 acc:87.27 | val loss:0.302 acc:88.62\n",
            "Epoch:0122 train loss:0.351 acc:87.11 | val loss:0.302 acc:88.59\n",
            "Epoch:0123 train loss:0.356 acc:86.98 | val loss:0.300 acc:88.61\n",
            "Epoch:0124 train loss:0.355 acc:87.63 | val loss:0.301 acc:88.59\n",
            "Epoch:0125 train loss:0.353 acc:87.82 | val loss:0.299 acc:88.67\n",
            "Epoch:0126 train loss:0.348 acc:87.55 | val loss:0.300 acc:88.53\n",
            "Epoch:0127 train loss:0.352 acc:87.40 | val loss:0.297 acc:88.78\n",
            "Epoch:0128 train loss:0.356 acc:87.30 | val loss:0.297 acc:88.75\n",
            "Epoch:0129 train loss:0.341 acc:87.77 | val loss:0.297 acc:88.70\n",
            "Epoch:0130 train loss:0.344 acc:87.69 | val loss:0.296 acc:88.84\n",
            "Epoch:0131 train loss:0.348 acc:87.58 | val loss:0.298 acc:88.73\n",
            "Epoch:0132 train loss:0.351 acc:87.44 | val loss:0.295 acc:88.99\n",
            "Epoch:0133 train loss:0.357 acc:87.21 | val loss:0.297 acc:88.68\n",
            "Epoch:0134 train loss:0.357 acc:87.37 | val loss:0.296 acc:88.94\n",
            "Epoch:0135 train loss:0.349 acc:87.46 | val loss:0.295 acc:88.91\n",
            "Epoch:0136 train loss:0.339 acc:88.27 | val loss:0.295 acc:89.05\n",
            "Epoch:0137 train loss:0.343 acc:87.66 | val loss:0.295 acc:89.03\n",
            "Epoch:0138 train loss:0.347 acc:87.72 | val loss:0.294 acc:89.02\n",
            "Epoch:0139 train loss:0.343 acc:87.60 | val loss:0.294 acc:88.86\n",
            "Epoch:0140 train loss:0.337 acc:87.72 | val loss:0.295 acc:88.80\n",
            "Epoch:0141 train loss:0.353 acc:87.29 | val loss:0.294 acc:88.72\n",
            "Epoch:0142 train loss:0.343 acc:87.78 | val loss:0.293 acc:88.91\n",
            "Epoch:0143 train loss:0.344 acc:88.05 | val loss:0.292 acc:88.95\n",
            "Epoch:0144 train loss:0.342 acc:87.51 | val loss:0.293 acc:88.75\n",
            "Epoch:0145 train loss:0.339 acc:87.92 | val loss:0.294 acc:88.73\n",
            "Epoch:0146 train loss:0.344 acc:87.72 | val loss:0.291 acc:89.11\n",
            "Epoch:0147 train loss:0.344 acc:87.65 | val loss:0.290 acc:89.11\n",
            "Epoch:0148 train loss:0.341 acc:87.54 | val loss:0.292 acc:88.81\n",
            "Epoch:0149 train loss:0.339 acc:87.65 | val loss:0.293 acc:88.92\n",
            "Epoch:0150 train loss:0.336 acc:88.05 | val loss:0.290 acc:88.97\n",
            "Epoch:0151 train loss:0.337 acc:87.87 | val loss:0.289 acc:89.14\n",
            "Epoch:0152 train loss:0.345 acc:87.38 | val loss:0.289 acc:89.02\n",
            "Epoch:0153 train loss:0.335 acc:87.63 | val loss:0.291 acc:88.72\n",
            "Epoch:0154 train loss:0.339 acc:87.98 | val loss:0.290 acc:88.80\n",
            "Epoch:0155 train loss:0.338 acc:87.70 | val loss:0.288 acc:89.03\n",
            "Epoch:0156 train loss:0.339 acc:87.82 | val loss:0.287 acc:89.03\n",
            "Epoch:0157 train loss:0.341 acc:87.90 | val loss:0.290 acc:89.00\n",
            "Epoch:0158 train loss:0.336 acc:87.85 | val loss:0.286 acc:89.24\n",
            "Epoch:0159 train loss:0.338 acc:87.85 | val loss:0.287 acc:89.21\n",
            "Epoch:0160 train loss:0.340 acc:87.58 | val loss:0.285 acc:89.24\n",
            "Epoch:0161 train loss:0.339 acc:87.98 | val loss:0.286 acc:89.08\n",
            "Epoch:0162 train loss:0.335 acc:87.96 | val loss:0.284 acc:89.29\n",
            "Epoch:0163 train loss:0.335 acc:87.70 | val loss:0.286 acc:89.32\n",
            "Epoch:0164 train loss:0.335 acc:87.96 | val loss:0.284 acc:89.21\n",
            "Epoch:0165 train loss:0.334 acc:88.33 | val loss:0.288 acc:88.94\n",
            "Epoch:0166 train loss:0.334 acc:88.33 | val loss:0.285 acc:89.18\n",
            "Epoch:0167 train loss:0.335 acc:87.82 | val loss:0.284 acc:89.26\n",
            "Epoch:0168 train loss:0.335 acc:87.71 | val loss:0.284 acc:89.27\n",
            "Epoch:0169 train loss:0.334 acc:88.09 | val loss:0.283 acc:89.24\n",
            "Epoch:0170 train loss:0.335 acc:87.85 | val loss:0.284 acc:89.19\n",
            "Epoch:0171 train loss:0.323 acc:88.12 | val loss:0.283 acc:89.26\n",
            "Epoch:0172 train loss:0.323 acc:88.15 | val loss:0.282 acc:89.24\n",
            "Epoch:0173 train loss:0.326 acc:88.40 | val loss:0.283 acc:89.37\n",
            "Epoch:0174 train loss:0.338 acc:87.44 | val loss:0.284 acc:89.10\n",
            "Epoch:0175 train loss:0.335 acc:88.16 | val loss:0.284 acc:89.05\n",
            "Epoch:0176 train loss:0.337 acc:87.73 | val loss:0.282 acc:89.33\n",
            "Epoch:0177 train loss:0.334 acc:88.14 | val loss:0.281 acc:89.41\n",
            "Epoch:0178 train loss:0.330 acc:88.32 | val loss:0.284 acc:89.10\n",
            "Epoch:0179 train loss:0.324 acc:87.91 | val loss:0.281 acc:89.24\n",
            "Epoch:0180 train loss:0.337 acc:87.65 | val loss:0.283 acc:89.45\n",
            "Epoch:0181 train loss:0.334 acc:87.67 | val loss:0.280 acc:89.45\n",
            "Epoch:0182 train loss:0.325 acc:88.33 | val loss:0.283 acc:89.27\n",
            "Epoch:0183 train loss:0.329 acc:88.28 | val loss:0.280 acc:89.38\n",
            "Epoch:0184 train loss:0.326 acc:88.32 | val loss:0.282 acc:89.43\n",
            "Epoch:0185 train loss:0.334 acc:88.09 | val loss:0.281 acc:89.30\n",
            "Epoch:0186 train loss:0.328 acc:88.04 | val loss:0.282 acc:89.30\n",
            "Epoch:0187 train loss:0.327 acc:88.16 | val loss:0.280 acc:89.41\n",
            "Epoch:0188 train loss:0.325 acc:88.27 | val loss:0.279 acc:89.37\n",
            "Epoch:0189 train loss:0.332 acc:88.13 | val loss:0.278 acc:89.41\n",
            "Epoch:0190 train loss:0.320 acc:88.47 | val loss:0.279 acc:89.26\n",
            "Epoch:0191 train loss:0.331 acc:88.19 | val loss:0.278 acc:89.43\n",
            "Epoch:0192 train loss:0.325 acc:88.30 | val loss:0.278 acc:89.71\n",
            "Epoch:0193 train loss:0.322 acc:88.33 | val loss:0.279 acc:89.59\n",
            "Epoch:0194 train loss:0.324 acc:88.31 | val loss:0.280 acc:89.26\n",
            "Epoch:0195 train loss:0.325 acc:88.06 | val loss:0.277 acc:89.52\n",
            "Epoch:0196 train loss:0.322 acc:88.95 | val loss:0.281 acc:89.43\n",
            "Epoch:0197 train loss:0.332 acc:87.79 | val loss:0.278 acc:89.30\n",
            "Epoch:0198 train loss:0.325 acc:88.16 | val loss:0.283 acc:89.05\n",
            "Epoch:0199 train loss:0.326 acc:88.30 | val loss:0.278 acc:89.51\n",
            "Epoch:0200 train loss:0.325 acc:88.22 | val loss:0.275 acc:89.59\n",
            "Epoch:0201 train loss:0.321 acc:88.52 | val loss:0.281 acc:89.11\n",
            "Epoch:0202 train loss:0.334 acc:87.98 | val loss:0.275 acc:89.35\n",
            "Epoch:0203 train loss:0.323 acc:88.65 | val loss:0.282 acc:89.32\n",
            "Epoch:0204 train loss:0.341 acc:87.51 | val loss:0.275 acc:89.49\n",
            "Epoch:0205 train loss:0.325 acc:88.26 | val loss:0.280 acc:89.16\n",
            "Epoch:0206 train loss:0.323 acc:87.98 | val loss:0.274 acc:89.60\n",
            "Epoch:0207 train loss:0.326 acc:88.16 | val loss:0.281 acc:89.35\n",
            "Epoch:0208 train loss:0.332 acc:87.68 | val loss:0.275 acc:89.49\n",
            "Epoch:0209 train loss:0.319 acc:88.43 | val loss:0.284 acc:88.95\n",
            "Epoch:0210 train loss:0.336 acc:87.88 | val loss:0.274 acc:89.57\n",
            "Epoch:0211 train loss:0.314 acc:88.21 | val loss:0.277 acc:89.51\n",
            "Epoch:0212 train loss:0.329 acc:87.94 | val loss:0.274 acc:89.43\n",
            "Epoch:0213 train loss:0.316 acc:88.54 | val loss:0.278 acc:89.38\n",
            "Epoch:0214 train loss:0.329 acc:88.01 | val loss:0.274 acc:89.67\n",
            "Epoch:0215 train loss:0.318 acc:88.69 | val loss:0.275 acc:89.51\n",
            "Epoch:0216 train loss:0.321 acc:88.49 | val loss:0.272 acc:89.59\n",
            "Epoch:0217 train loss:0.325 acc:88.20 | val loss:0.274 acc:89.38\n",
            "Epoch:0218 train loss:0.319 acc:88.56 | val loss:0.274 acc:89.60\n",
            "Epoch:0219 train loss:0.321 acc:88.60 | val loss:0.278 acc:89.48\n",
            "Epoch:0220 train loss:0.327 acc:88.15 | val loss:0.275 acc:89.64\n",
            "Epoch:0221 train loss:0.315 acc:88.39 | val loss:0.272 acc:89.67\n",
            "Epoch:0222 train loss:0.318 acc:88.51 | val loss:0.271 acc:89.64\n",
            "Epoch:0223 train loss:0.314 acc:88.32 | val loss:0.271 acc:89.64\n",
            "Epoch:0224 train loss:0.313 acc:88.50 | val loss:0.270 acc:89.71\n",
            "Epoch:0225 train loss:0.315 acc:88.39 | val loss:0.271 acc:89.70\n",
            "Epoch:0226 train loss:0.315 acc:88.27 | val loss:0.270 acc:89.71\n",
            "Epoch:0227 train loss:0.309 acc:88.75 | val loss:0.270 acc:89.75\n",
            "Epoch:0228 train loss:0.318 acc:88.50 | val loss:0.269 acc:89.68\n",
            "Epoch:0229 train loss:0.312 acc:88.31 | val loss:0.269 acc:89.73\n",
            "Epoch:0230 train loss:0.309 acc:88.69 | val loss:0.270 acc:89.76\n",
            "Epoch:0231 train loss:0.316 acc:88.57 | val loss:0.270 acc:89.78\n",
            "Epoch:0232 train loss:0.315 acc:88.33 | val loss:0.268 acc:89.76\n",
            "Epoch:0233 train loss:0.315 acc:88.30 | val loss:0.268 acc:89.73\n",
            "Epoch:0234 train loss:0.311 acc:88.91 | val loss:0.268 acc:89.73\n",
            "Epoch:0235 train loss:0.315 acc:88.63 | val loss:0.270 acc:89.95\n",
            "Epoch:0236 train loss:0.315 acc:88.39 | val loss:0.269 acc:89.89\n",
            "Epoch:0237 train loss:0.311 acc:88.57 | val loss:0.269 acc:89.79\n",
            "Epoch:0238 train loss:0.311 acc:88.51 | val loss:0.267 acc:89.78\n",
            "Epoch:0239 train loss:0.315 acc:88.35 | val loss:0.269 acc:89.73\n",
            "Epoch:0240 train loss:0.314 acc:88.43 | val loss:0.268 acc:89.90\n",
            "Epoch:0241 train loss:0.313 acc:88.50 | val loss:0.273 acc:89.73\n",
            "Epoch:0242 train loss:0.319 acc:88.35 | val loss:0.267 acc:89.73\n",
            "Epoch:0243 train loss:0.321 acc:88.60 | val loss:0.268 acc:89.68\n",
            "Epoch:0244 train loss:0.313 acc:88.85 | val loss:0.268 acc:89.84\n",
            "Epoch:0245 train loss:0.314 acc:88.58 | val loss:0.270 acc:89.76\n",
            "Epoch:0246 train loss:0.317 acc:88.22 | val loss:0.266 acc:90.00\n",
            "Epoch:0247 train loss:0.317 acc:88.61 | val loss:0.264 acc:90.05\n",
            "Epoch:0248 train loss:0.312 acc:88.66 | val loss:0.264 acc:89.97\n",
            "Epoch:0249 train loss:0.311 acc:88.21 | val loss:0.264 acc:90.02\n",
            "Epoch:0250 train loss:0.309 acc:88.49 | val loss:0.266 acc:89.95\n",
            "Epoch:0251 train loss:0.316 acc:88.37 | val loss:0.268 acc:90.05\n",
            "Epoch:0252 train loss:0.314 acc:88.32 | val loss:0.270 acc:89.68\n",
            "Epoch:0253 train loss:0.313 acc:88.57 | val loss:0.266 acc:89.83\n",
            "Epoch:0254 train loss:0.310 acc:88.44 | val loss:0.265 acc:89.90\n",
            "Epoch:0255 train loss:0.313 acc:88.51 | val loss:0.266 acc:89.87\n",
            "Epoch:0256 train loss:0.315 acc:88.30 | val loss:0.265 acc:89.89\n",
            "Epoch:0257 train loss:0.313 acc:88.52 | val loss:0.264 acc:90.08\n",
            "Epoch:0258 train loss:0.316 acc:88.12 | val loss:0.263 acc:90.05\n",
            "Epoch:0259 train loss:0.310 acc:88.59 | val loss:0.267 acc:89.73\n",
            "Epoch:0260 train loss:0.311 acc:88.66 | val loss:0.264 acc:89.86\n",
            "Epoch:0261 train loss:0.308 acc:88.86 | val loss:0.266 acc:90.03\n",
            "Epoch:0262 train loss:0.305 acc:88.79 | val loss:0.265 acc:89.84\n",
            "Epoch:0263 train loss:0.306 acc:88.90 | val loss:0.267 acc:89.86\n",
            "Epoch:0264 train loss:0.316 acc:88.54 | val loss:0.263 acc:89.90\n",
            "Epoch:0265 train loss:0.308 acc:88.85 | val loss:0.263 acc:90.10\n",
            "Epoch:0266 train loss:0.303 acc:88.65 | val loss:0.264 acc:90.14\n",
            "Epoch:0267 train loss:0.305 acc:88.86 | val loss:0.263 acc:90.05\n",
            "Epoch:0268 train loss:0.313 acc:88.57 | val loss:0.263 acc:90.06\n",
            "Epoch:0269 train loss:0.308 acc:89.30 | val loss:0.264 acc:90.03\n",
            "Epoch:0270 train loss:0.305 acc:89.12 | val loss:0.263 acc:89.94\n",
            "Epoch:0271 train loss:0.306 acc:89.05 | val loss:0.262 acc:89.95\n",
            "Epoch:0272 train loss:0.311 acc:88.90 | val loss:0.266 acc:90.00\n",
            "Epoch:0273 train loss:0.304 acc:89.04 | val loss:0.269 acc:89.75\n",
            "Epoch:0274 train loss:0.306 acc:88.79 | val loss:0.263 acc:90.06\n",
            "Epoch:0275 train loss:0.305 acc:88.75 | val loss:0.263 acc:90.02\n",
            "Epoch:0276 train loss:0.302 acc:88.79 | val loss:0.261 acc:89.98\n",
            "Epoch:0277 train loss:0.311 acc:88.88 | val loss:0.265 acc:89.97\n",
            "Epoch:0278 train loss:0.307 acc:88.75 | val loss:0.266 acc:89.95\n",
            "Epoch:0279 train loss:0.308 acc:88.77 | val loss:0.262 acc:90.10\n",
            "Epoch:0280 train loss:0.309 acc:88.45 | val loss:0.262 acc:90.13\n",
            "Epoch:0281 train loss:0.300 acc:88.85 | val loss:0.263 acc:90.05\n",
            "Epoch:0282 train loss:0.298 acc:88.86 | val loss:0.263 acc:90.14\n",
            "Epoch:0283 train loss:0.305 acc:88.69 | val loss:0.264 acc:90.14\n",
            "Epoch:0284 train loss:0.310 acc:88.80 | val loss:0.266 acc:90.11\n",
            "Epoch:0285 train loss:0.310 acc:88.52 | val loss:0.260 acc:90.17\n",
            "Epoch:0286 train loss:0.303 acc:88.89 | val loss:0.260 acc:90.25\n",
            "Epoch:0287 train loss:0.301 acc:88.77 | val loss:0.260 acc:90.08\n",
            "Epoch:0288 train loss:0.302 acc:88.88 | val loss:0.261 acc:90.13\n",
            "Epoch:0289 train loss:0.298 acc:88.80 | val loss:0.262 acc:90.25\n",
            "Epoch:0290 train loss:0.301 acc:88.72 | val loss:0.262 acc:90.25\n",
            "Epoch:0291 train loss:0.300 acc:88.96 | val loss:0.262 acc:90.02\n",
            "Epoch:0292 train loss:0.299 acc:89.15 | val loss:0.262 acc:90.02\n",
            "Epoch:0293 train loss:0.305 acc:88.88 | val loss:0.261 acc:90.16\n",
            "Epoch:0294 train loss:0.302 acc:89.12 | val loss:0.260 acc:90.32\n",
            "Epoch:0295 train loss:0.301 acc:88.74 | val loss:0.263 acc:89.97\n",
            "Epoch:0296 train loss:0.305 acc:88.68 | val loss:0.259 acc:90.24\n",
            "Epoch:0297 train loss:0.296 acc:89.21 | val loss:0.261 acc:90.11\n",
            "Epoch:0298 train loss:0.301 acc:89.00 | val loss:0.268 acc:89.71\n",
            "Epoch:0299 train loss:0.313 acc:88.08 | val loss:0.260 acc:90.30\n",
            "Epoch:0300 train loss:0.298 acc:89.01 | val loss:0.266 acc:89.92\n",
            "Epoch:0301 train loss:0.315 acc:88.20 | val loss:0.265 acc:89.92\n",
            "Epoch:0302 train loss:0.308 acc:88.74 | val loss:0.265 acc:89.90\n",
            "Epoch:0303 train loss:0.308 acc:88.70 | val loss:0.260 acc:90.35\n",
            "Epoch:0304 train loss:0.302 acc:88.59 | val loss:0.260 acc:90.32\n",
            "Epoch:0305 train loss:0.303 acc:89.06 | val loss:0.263 acc:89.97\n",
            "Epoch:0306 train loss:0.304 acc:88.80 | val loss:0.263 acc:90.08\n",
            "Epoch:0307 train loss:0.303 acc:89.04 | val loss:0.261 acc:90.19\n",
            "Epoch:0308 train loss:0.304 acc:88.69 | val loss:0.261 acc:90.30\n",
            "Epoch:0309 train loss:0.298 acc:89.04 | val loss:0.263 acc:90.05\n",
            "Epoch:0310 train loss:0.299 acc:89.17 | val loss:0.260 acc:90.22\n",
            "Epoch:0311 train loss:0.291 acc:89.45 | val loss:0.261 acc:90.17\n",
            "Epoch:0312 train loss:0.303 acc:88.89 | val loss:0.260 acc:90.19\n",
            "Epoch:0313 train loss:0.295 acc:88.96 | val loss:0.263 acc:89.84\n",
            "Epoch:0314 train loss:0.299 acc:88.93 | val loss:0.258 acc:90.32\n",
            "Epoch:0315 train loss:0.295 acc:89.01 | val loss:0.258 acc:90.29\n",
            "Epoch:0316 train loss:0.301 acc:89.05 | val loss:0.258 acc:90.38\n",
            "Epoch:0317 train loss:0.296 acc:89.01 | val loss:0.260 acc:90.19\n",
            "Epoch:0318 train loss:0.296 acc:88.94 | val loss:0.260 acc:90.27\n",
            "Epoch:0319 train loss:0.299 acc:88.89 | val loss:0.259 acc:90.33\n",
            "Epoch:0320 train loss:0.297 acc:89.24 | val loss:0.258 acc:90.35\n",
            "Epoch:0321 train loss:0.292 acc:89.17 | val loss:0.258 acc:90.17\n",
            "Epoch:0322 train loss:0.297 acc:88.91 | val loss:0.257 acc:90.25\n",
            "Epoch:0323 train loss:0.292 acc:89.47 | val loss:0.259 acc:90.27\n",
            "Epoch:0324 train loss:0.296 acc:88.97 | val loss:0.258 acc:90.29\n",
            "Epoch:0325 train loss:0.300 acc:89.04 | val loss:0.257 acc:90.33\n",
            "Epoch:0326 train loss:0.295 acc:89.04 | val loss:0.258 acc:90.19\n",
            "Epoch:0327 train loss:0.297 acc:88.90 | val loss:0.258 acc:90.30\n",
            "Epoch:0328 train loss:0.293 acc:89.36 | val loss:0.262 acc:89.97\n",
            "Epoch:0329 train loss:0.297 acc:88.87 | val loss:0.260 acc:90.25\n",
            "Epoch:0330 train loss:0.299 acc:88.83 | val loss:0.258 acc:90.38\n",
            "Epoch:0331 train loss:0.300 acc:89.03 | val loss:0.258 acc:90.27\n",
            "Epoch:0332 train loss:0.293 acc:88.93 | val loss:0.259 acc:89.98\n",
            "Epoch:0333 train loss:0.294 acc:88.99 | val loss:0.258 acc:90.11\n",
            "Epoch:0334 train loss:0.291 acc:89.23 | val loss:0.257 acc:90.36\n",
            "Epoch:0335 train loss:0.291 acc:89.18 | val loss:0.262 acc:90.02\n",
            "Epoch:0336 train loss:0.293 acc:89.17 | val loss:0.257 acc:90.32\n",
            "Epoch:0337 train loss:0.292 acc:89.45 | val loss:0.257 acc:90.33\n",
            "Epoch:0338 train loss:0.297 acc:89.08 | val loss:0.257 acc:90.41\n",
            "Epoch:0339 train loss:0.296 acc:89.25 | val loss:0.257 acc:90.33\n",
            "Epoch:0340 train loss:0.292 acc:89.15 | val loss:0.256 acc:90.49\n",
            "Epoch:0341 train loss:0.289 acc:89.40 | val loss:0.256 acc:90.54\n",
            "Epoch:0342 train loss:0.289 acc:89.15 | val loss:0.256 acc:90.46\n",
            "Epoch:0343 train loss:0.291 acc:89.53 | val loss:0.256 acc:90.44\n",
            "Epoch:0344 train loss:0.294 acc:88.93 | val loss:0.257 acc:90.30\n",
            "Epoch:0345 train loss:0.293 acc:89.20 | val loss:0.257 acc:90.32\n",
            "Epoch:0346 train loss:0.287 acc:89.51 | val loss:0.258 acc:90.36\n",
            "Epoch:0347 train loss:0.286 acc:89.39 | val loss:0.255 acc:90.33\n",
            "Epoch:0348 train loss:0.288 acc:89.44 | val loss:0.257 acc:90.10\n",
            "Epoch:0349 train loss:0.297 acc:88.95 | val loss:0.259 acc:90.02\n",
            "Epoch:0350 train loss:0.294 acc:89.07 | val loss:0.259 acc:90.02\n",
            "Epoch:0351 train loss:0.288 acc:89.34 | val loss:0.258 acc:90.22\n",
            "Epoch:0352 train loss:0.291 acc:89.15 | val loss:0.257 acc:90.25\n",
            "Epoch:0353 train loss:0.286 acc:89.37 | val loss:0.260 acc:89.90\n",
            "Epoch:0354 train loss:0.294 acc:88.94 | val loss:0.256 acc:90.36\n",
            "Epoch:0355 train loss:0.291 acc:89.31 | val loss:0.257 acc:90.08\n",
            "Epoch:0356 train loss:0.293 acc:88.75 | val loss:0.258 acc:90.11\n",
            "Epoch:0357 train loss:0.289 acc:89.35 | val loss:0.255 acc:90.38\n",
            "Epoch:0358 train loss:0.290 acc:89.41 | val loss:0.257 acc:89.97\n",
            "Epoch:0359 train loss:0.295 acc:89.24 | val loss:0.255 acc:90.14\n",
            "Epoch:0360 train loss:0.288 acc:89.58 | val loss:0.257 acc:90.13\n",
            "Epoch:0361 train loss:0.305 acc:88.91 | val loss:0.255 acc:90.30\n",
            "Epoch:0362 train loss:0.293 acc:89.08 | val loss:0.255 acc:90.22\n",
            "Epoch:0363 train loss:0.285 acc:89.49 | val loss:0.255 acc:90.48\n",
            "Epoch:0364 train loss:0.285 acc:89.75 | val loss:0.257 acc:90.21\n",
            "Epoch:0365 train loss:0.285 acc:89.43 | val loss:0.255 acc:90.41\n",
            "Epoch:0366 train loss:0.288 acc:89.64 | val loss:0.257 acc:90.13\n",
            "Epoch:0367 train loss:0.287 acc:89.25 | val loss:0.254 acc:90.40\n",
            "Epoch:0368 train loss:0.283 acc:89.65 | val loss:0.255 acc:90.32\n",
            "Epoch:0369 train loss:0.292 acc:89.04 | val loss:0.254 acc:90.36\n",
            "Epoch:0370 train loss:0.286 acc:89.22 | val loss:0.254 acc:90.36\n",
            "Epoch:0371 train loss:0.290 acc:89.56 | val loss:0.256 acc:90.17\n",
            "Epoch:0372 train loss:0.290 acc:89.41 | val loss:0.254 acc:90.35\n",
            "Epoch:0373 train loss:0.287 acc:89.70 | val loss:0.255 acc:90.35\n",
            "Epoch:0374 train loss:0.284 acc:89.40 | val loss:0.258 acc:90.29\n",
            "Epoch:0375 train loss:0.283 acc:89.64 | val loss:0.259 acc:90.10\n",
            "Epoch:0376 train loss:0.293 acc:89.00 | val loss:0.259 acc:90.10\n",
            "Epoch:0377 train loss:0.297 acc:88.82 | val loss:0.257 acc:90.25\n",
            "Epoch:0378 train loss:0.290 acc:89.41 | val loss:0.253 acc:90.41\n",
            "Epoch:0379 train loss:0.284 acc:89.47 | val loss:0.252 acc:90.40\n",
            "Epoch:0380 train loss:0.282 acc:89.34 | val loss:0.252 acc:90.46\n",
            "Epoch:0381 train loss:0.283 acc:89.70 | val loss:0.255 acc:90.33\n",
            "Epoch:0382 train loss:0.285 acc:89.78 | val loss:0.254 acc:90.46\n",
            "Epoch:0383 train loss:0.283 acc:89.58 | val loss:0.260 acc:90.16\n",
            "Epoch:0384 train loss:0.291 acc:89.31 | val loss:0.266 acc:89.87\n",
            "Epoch:0385 train loss:0.287 acc:89.34 | val loss:0.264 acc:89.90\n",
            "Epoch:0386 train loss:0.287 acc:89.43 | val loss:0.253 acc:90.17\n",
            "Epoch:0387 train loss:0.285 acc:89.54 | val loss:0.255 acc:90.33\n",
            "Epoch:0388 train loss:0.292 acc:89.44 | val loss:0.255 acc:90.24\n",
            "Epoch:0389 train loss:0.286 acc:89.71 | val loss:0.255 acc:90.35\n",
            "Epoch:0390 train loss:0.282 acc:89.63 | val loss:0.255 acc:90.25\n",
            "Epoch:0391 train loss:0.293 acc:89.31 | val loss:0.253 acc:90.30\n",
            "Epoch:0392 train loss:0.284 acc:89.34 | val loss:0.256 acc:90.32\n",
            "Epoch:0393 train loss:0.293 acc:89.52 | val loss:0.253 acc:90.29\n",
            "Epoch:0394 train loss:0.274 acc:90.08 | val loss:0.252 acc:90.43\n",
            "Epoch:0395 train loss:0.285 acc:89.41 | val loss:0.253 acc:90.44\n",
            "Epoch:0396 train loss:0.283 acc:89.73 | val loss:0.254 acc:90.17\n",
            "Epoch:0397 train loss:0.283 acc:89.54 | val loss:0.252 acc:90.52\n",
            "Epoch:0398 train loss:0.289 acc:89.46 | val loss:0.250 acc:90.43\n",
            "Epoch:0399 train loss:0.277 acc:89.93 | val loss:0.252 acc:90.32\n",
            "Epoch:0400 train loss:0.278 acc:89.67 | val loss:0.254 acc:90.49\n",
            "Epoch:0401 train loss:0.284 acc:89.36 | val loss:0.253 acc:90.24\n",
            "Epoch:0402 train loss:0.281 acc:89.55 | val loss:0.252 acc:90.35\n",
            "Epoch:0403 train loss:0.282 acc:89.76 | val loss:0.256 acc:90.00\n",
            "Epoch:0404 train loss:0.286 acc:89.71 | val loss:0.252 acc:90.35\n",
            "Epoch:0405 train loss:0.286 acc:89.55 | val loss:0.253 acc:90.27\n",
            "Epoch:0406 train loss:0.283 acc:89.50 | val loss:0.252 acc:90.33\n",
            "Epoch:0407 train loss:0.282 acc:89.53 | val loss:0.253 acc:90.13\n",
            "Epoch:0408 train loss:0.280 acc:89.56 | val loss:0.250 acc:90.43\n",
            "Epoch:0409 train loss:0.279 acc:89.58 | val loss:0.252 acc:90.30\n",
            "Epoch:0410 train loss:0.283 acc:89.44 | val loss:0.254 acc:90.22\n",
            "Epoch:0411 train loss:0.279 acc:89.67 | val loss:0.254 acc:90.35\n",
            "Epoch:0412 train loss:0.279 acc:89.45 | val loss:0.252 acc:90.29\n",
            "Epoch:0413 train loss:0.287 acc:89.55 | val loss:0.251 acc:90.54\n",
            "Epoch:0414 train loss:0.283 acc:89.46 | val loss:0.254 acc:90.08\n",
            "Epoch:0415 train loss:0.281 acc:89.41 | val loss:0.250 acc:90.43\n",
            "Epoch:0416 train loss:0.280 acc:89.70 | val loss:0.253 acc:90.22\n",
            "Epoch:0417 train loss:0.291 acc:89.04 | val loss:0.253 acc:90.30\n",
            "Epoch:0418 train loss:0.279 acc:89.80 | val loss:0.255 acc:90.16\n",
            "Epoch:0419 train loss:0.283 acc:89.57 | val loss:0.253 acc:90.52\n",
            "Epoch:0420 train loss:0.281 acc:89.26 | val loss:0.251 acc:90.59\n",
            "Epoch:0421 train loss:0.278 acc:89.76 | val loss:0.256 acc:90.21\n",
            "Epoch:0422 train loss:0.282 acc:89.51 | val loss:0.252 acc:90.59\n",
            "Epoch:0423 train loss:0.276 acc:89.79 | val loss:0.251 acc:90.36\n",
            "Epoch:0424 train loss:0.281 acc:89.21 | val loss:0.249 acc:90.60\n",
            "Epoch:0425 train loss:0.275 acc:89.80 | val loss:0.256 acc:90.24\n",
            "Epoch:0426 train loss:0.287 acc:89.51 | val loss:0.250 acc:90.48\n",
            "Epoch:0427 train loss:0.276 acc:89.77 | val loss:0.255 acc:90.19\n",
            "Epoch:0428 train loss:0.284 acc:89.21 | val loss:0.257 acc:90.14\n",
            "Epoch:0429 train loss:0.287 acc:89.44 | val loss:0.254 acc:90.38\n",
            "Epoch:0430 train loss:0.287 acc:89.24 | val loss:0.252 acc:90.27\n",
            "Epoch:0431 train loss:0.289 acc:89.00 | val loss:0.249 acc:90.40\n",
            "Epoch:0432 train loss:0.282 acc:89.39 | val loss:0.255 acc:90.33\n",
            "Epoch:0433 train loss:0.281 acc:89.45 | val loss:0.252 acc:90.43\n",
            "Epoch:0434 train loss:0.277 acc:89.82 | val loss:0.250 acc:90.40\n",
            "Epoch:0435 train loss:0.281 acc:89.81 | val loss:0.249 acc:90.51\n",
            "Epoch:0436 train loss:0.273 acc:89.99 | val loss:0.253 acc:90.38\n",
            "Epoch:0437 train loss:0.280 acc:89.42 | val loss:0.253 acc:90.43\n",
            "Epoch:0438 train loss:0.278 acc:89.94 | val loss:0.253 acc:90.13\n",
            "Epoch:0439 train loss:0.280 acc:89.34 | val loss:0.249 acc:90.49\n",
            "Epoch:0440 train loss:0.278 acc:89.74 | val loss:0.251 acc:90.57\n",
            "Epoch:0441 train loss:0.287 acc:89.79 | val loss:0.249 acc:90.68\n",
            "Epoch:0442 train loss:0.274 acc:90.03 | val loss:0.250 acc:90.24\n",
            "Epoch:0443 train loss:0.279 acc:89.99 | val loss:0.251 acc:90.44\n",
            "Epoch:0444 train loss:0.280 acc:89.46 | val loss:0.253 acc:90.38\n",
            "Epoch:0445 train loss:0.273 acc:89.84 | val loss:0.252 acc:90.43\n",
            "Epoch:0446 train loss:0.284 acc:89.33 | val loss:0.251 acc:90.30\n",
            "Epoch:0447 train loss:0.279 acc:89.58 | val loss:0.253 acc:90.46\n",
            "Epoch:0448 train loss:0.278 acc:89.76 | val loss:0.251 acc:90.44\n",
            "Epoch:0449 train loss:0.272 acc:90.09 | val loss:0.251 acc:90.62\n",
            "Epoch:0450 train loss:0.277 acc:89.97 | val loss:0.250 acc:90.46\n",
            "Epoch:0451 train loss:0.280 acc:89.86 | val loss:0.251 acc:90.38\n",
            "Epoch:0452 train loss:0.276 acc:89.70 | val loss:0.252 acc:90.36\n",
            "Epoch:0453 train loss:0.271 acc:89.84 | val loss:0.248 acc:90.59\n",
            "Epoch:0454 train loss:0.272 acc:89.93 | val loss:0.249 acc:90.57\n",
            "Epoch:0455 train loss:0.267 acc:90.35 | val loss:0.249 acc:90.67\n",
            "Epoch:0456 train loss:0.269 acc:90.32 | val loss:0.254 acc:90.40\n",
            "Epoch:0457 train loss:0.283 acc:89.54 | val loss:0.252 acc:90.54\n",
            "Epoch:0458 train loss:0.273 acc:89.65 | val loss:0.250 acc:90.48\n",
            "Epoch:0459 train loss:0.277 acc:89.74 | val loss:0.250 acc:90.52\n",
            "Epoch:0460 train loss:0.272 acc:89.81 | val loss:0.252 acc:90.43\n",
            "Epoch:0461 train loss:0.279 acc:89.62 | val loss:0.250 acc:90.48\n",
            "Epoch:0462 train loss:0.275 acc:89.55 | val loss:0.253 acc:90.44\n",
            "Epoch:0463 train loss:0.273 acc:89.53 | val loss:0.250 acc:90.54\n",
            "Epoch:0464 train loss:0.272 acc:90.44 | val loss:0.250 acc:90.62\n",
            "Epoch:0465 train loss:0.271 acc:89.87 | val loss:0.249 acc:90.55\n",
            "Epoch:0466 train loss:0.266 acc:89.92 | val loss:0.251 acc:90.63\n",
            "Epoch:0467 train loss:0.262 acc:90.37 | val loss:0.253 acc:90.54\n",
            "Epoch:0468 train loss:0.266 acc:90.18 | val loss:0.250 acc:90.55\n",
            "Epoch:0469 train loss:0.273 acc:90.01 | val loss:0.250 acc:90.71\n",
            "Epoch:0470 train loss:0.268 acc:90.48 | val loss:0.249 acc:90.67\n",
            "Epoch:0471 train loss:0.276 acc:89.88 | val loss:0.250 acc:90.49\n",
            "Epoch:0472 train loss:0.279 acc:89.76 | val loss:0.249 acc:90.48\n",
            "Epoch:0473 train loss:0.266 acc:90.10 | val loss:0.248 acc:90.57\n",
            "Epoch:0474 train loss:0.272 acc:89.91 | val loss:0.250 acc:90.52\n",
            "Epoch:0475 train loss:0.275 acc:89.86 | val loss:0.249 acc:90.51\n",
            "Epoch:0476 train loss:0.271 acc:90.02 | val loss:0.252 acc:90.32\n",
            "Epoch:0477 train loss:0.273 acc:90.12 | val loss:0.252 acc:90.46\n",
            "Epoch:0478 train loss:0.272 acc:90.01 | val loss:0.255 acc:90.41\n",
            "Epoch:0479 train loss:0.273 acc:90.16 | val loss:0.251 acc:90.44\n",
            "Epoch:0480 train loss:0.276 acc:89.71 | val loss:0.249 acc:90.51\n",
            "Epoch:0481 train loss:0.274 acc:89.65 | val loss:0.255 acc:90.25\n",
            "Epoch:0482 train loss:0.280 acc:89.37 | val loss:0.247 acc:90.62\n",
            "Epoch:0483 train loss:0.269 acc:90.20 | val loss:0.249 acc:90.51\n",
            "Epoch:0484 train loss:0.279 acc:89.96 | val loss:0.255 acc:90.36\n",
            "Epoch:0485 train loss:0.283 acc:89.35 | val loss:0.249 acc:90.54\n",
            "Epoch:0486 train loss:0.268 acc:90.09 | val loss:0.259 acc:90.29\n",
            "Epoch:0487 train loss:0.289 acc:89.36 | val loss:0.256 acc:90.35\n",
            "Epoch:0488 train loss:0.276 acc:89.76 | val loss:0.256 acc:90.33\n",
            "Epoch:0489 train loss:0.283 acc:89.63 | val loss:0.256 acc:90.29\n",
            "Epoch:0490 train loss:0.283 acc:89.08 | val loss:0.249 acc:90.62\n",
            "Epoch:0491 train loss:0.270 acc:90.17 | val loss:0.259 acc:89.97\n",
            "Epoch:0492 train loss:0.284 acc:89.39 | val loss:0.254 acc:90.40\n",
            "Epoch:0493 train loss:0.276 acc:89.49 | val loss:0.254 acc:90.40\n",
            "Epoch:0494 train loss:0.278 acc:89.80 | val loss:0.255 acc:90.29\n",
            "Epoch:0495 train loss:0.282 acc:89.63 | val loss:0.262 acc:89.97\n",
            "Epoch:0496 train loss:0.282 acc:89.65 | val loss:0.265 acc:89.86\n",
            "Epoch:0497 train loss:0.293 acc:88.91 | val loss:0.249 acc:90.55\n",
            "Epoch:0498 train loss:0.278 acc:89.77 | val loss:0.257 acc:90.29\n",
            "Epoch:0499 train loss:0.287 acc:89.13 | val loss:0.247 acc:90.70\n",
            "Epoch:0500 train loss:0.280 acc:89.67 | val loss:0.259 acc:90.25\n",
            "Epoch:0501 train loss:0.288 acc:89.40 | val loss:0.250 acc:90.52\n",
            "Epoch:0502 train loss:0.270 acc:90.18 | val loss:0.252 acc:90.48\n",
            "Epoch:0503 train loss:0.280 acc:89.72 | val loss:0.249 acc:90.62\n",
            "Epoch:0504 train loss:0.267 acc:90.32 | val loss:0.252 acc:90.54\n",
            "Epoch:0505 train loss:0.272 acc:89.64 | val loss:0.252 acc:90.51\n",
            "Epoch:0506 train loss:0.269 acc:90.24 | val loss:0.251 acc:90.54\n",
            "Epoch:0507 train loss:0.271 acc:90.16 | val loss:0.253 acc:90.41\n",
            "Epoch:0508 train loss:0.284 acc:89.43 | val loss:0.248 acc:90.68\n",
            "Epoch:0509 train loss:0.274 acc:90.09 | val loss:0.251 acc:90.48\n",
            "Epoch:0510 train loss:0.273 acc:89.41 | val loss:0.245 acc:90.73\n",
            "Epoch:0511 train loss:0.271 acc:89.80 | val loss:0.247 acc:90.67\n",
            "Epoch:0512 train loss:0.269 acc:89.78 | val loss:0.249 acc:90.70\n",
            "Epoch:0513 train loss:0.270 acc:89.93 | val loss:0.251 acc:90.54\n",
            "Epoch:0514 train loss:0.270 acc:89.64 | val loss:0.254 acc:90.40\n",
            "Epoch:0515 train loss:0.271 acc:89.88 | val loss:0.249 acc:90.63\n",
            "Epoch:0516 train loss:0.261 acc:90.36 | val loss:0.251 acc:90.48\n",
            "Epoch:0517 train loss:0.273 acc:89.91 | val loss:0.247 acc:90.70\n",
            "Epoch:0518 train loss:0.266 acc:90.27 | val loss:0.251 acc:90.55\n",
            "Epoch:0519 train loss:0.271 acc:89.78 | val loss:0.248 acc:90.73\n",
            "Epoch:0520 train loss:0.265 acc:89.99 | val loss:0.249 acc:90.65\n",
            "Epoch:0521 train loss:0.271 acc:89.69 | val loss:0.248 acc:90.62\n",
            "Epoch:0522 train loss:0.268 acc:90.12 | val loss:0.250 acc:90.68\n",
            "Epoch:0523 train loss:0.268 acc:89.82 | val loss:0.252 acc:90.63\n",
            "Epoch:0524 train loss:0.275 acc:90.03 | val loss:0.251 acc:90.63\n",
            "Epoch:0525 train loss:0.269 acc:89.89 | val loss:0.252 acc:90.48\n",
            "Epoch:0526 train loss:0.261 acc:90.69 | val loss:0.251 acc:90.63\n",
            "Epoch:0527 train loss:0.267 acc:90.02 | val loss:0.251 acc:90.67\n",
            "Epoch:0528 train loss:0.266 acc:90.11 | val loss:0.247 acc:90.73\n",
            "Epoch:0529 train loss:0.262 acc:90.31 | val loss:0.247 acc:90.78\n",
            "Epoch:0530 train loss:0.267 acc:90.12 | val loss:0.247 acc:90.81\n",
            "Epoch:0531 train loss:0.266 acc:90.08 | val loss:0.248 acc:90.68\n",
            "Epoch:0532 train loss:0.262 acc:90.65 | val loss:0.249 acc:90.70\n",
            "Epoch:0533 train loss:0.267 acc:90.07 | val loss:0.250 acc:90.74\n",
            "Epoch:0534 train loss:0.265 acc:90.15 | val loss:0.250 acc:90.78\n",
            "Epoch:0535 train loss:0.265 acc:89.95 | val loss:0.251 acc:90.74\n",
            "Epoch:0536 train loss:0.263 acc:90.77 | val loss:0.251 acc:90.68\n",
            "Epoch:0537 train loss:0.264 acc:90.26 | val loss:0.250 acc:90.59\n",
            "Epoch:0538 train loss:0.264 acc:90.25 | val loss:0.249 acc:90.70\n",
            "Epoch:0539 train loss:0.258 acc:90.62 | val loss:0.248 acc:90.73\n",
            "Epoch:0540 train loss:0.259 acc:90.03 | val loss:0.247 acc:90.65\n",
            "Epoch:0541 train loss:0.261 acc:90.51 | val loss:0.247 acc:90.67\n",
            "Epoch:0542 train loss:0.255 acc:90.54 | val loss:0.248 acc:90.67\n",
            "Epoch:0543 train loss:0.262 acc:90.14 | val loss:0.251 acc:90.62\n",
            "Epoch:0544 train loss:0.265 acc:90.34 | val loss:0.251 acc:90.70\n",
            "Epoch:0545 train loss:0.256 acc:90.47 | val loss:0.250 acc:90.49\n",
            "Epoch:0546 train loss:0.270 acc:90.10 | val loss:0.250 acc:90.65\n",
            "Epoch:0547 train loss:0.265 acc:90.06 | val loss:0.252 acc:90.57\n",
            "Epoch:0548 train loss:0.271 acc:89.88 | val loss:0.249 acc:90.60\n",
            "Epoch:0549 train loss:0.258 acc:90.31 | val loss:0.247 acc:90.63\n",
            "Epoch:0550 train loss:0.263 acc:90.73 | val loss:0.250 acc:90.73\n",
            "Epoch:0551 train loss:0.263 acc:90.28 | val loss:0.250 acc:90.73\n",
            "Epoch:0552 train loss:0.260 acc:90.19 | val loss:0.249 acc:90.51\n",
            "Epoch:0553 train loss:0.262 acc:90.18 | val loss:0.249 acc:90.79\n",
            "Epoch:0554 train loss:0.258 acc:90.39 | val loss:0.252 acc:90.59\n",
            "Epoch:0555 train loss:0.265 acc:90.08 | val loss:0.249 acc:90.68\n",
            "Epoch:0556 train loss:0.258 acc:90.59 | val loss:0.252 acc:90.54\n",
            "Epoch:0557 train loss:0.269 acc:89.71 | val loss:0.252 acc:90.65\n",
            "Epoch:0558 train loss:0.262 acc:90.16 | val loss:0.251 acc:90.71\n",
            "Epoch:0559 train loss:0.259 acc:90.70 | val loss:0.248 acc:90.62\n",
            "Epoch:0560 train loss:0.259 acc:90.49 | val loss:0.248 acc:90.52\n",
            "1 : 90.64\n",
            "Epoch:0001 train loss:1.096 acc:38.93 | val loss:1.087 acc:39.76\n",
            "Epoch:0002 train loss:1.088 acc:38.92 | val loss:1.078 acc:39.76\n",
            "Epoch:0003 train loss:1.078 acc:39.02 | val loss:1.066 acc:39.84\n",
            "Epoch:0004 train loss:1.068 acc:39.58 | val loss:1.054 acc:42.58\n",
            "Epoch:0005 train loss:1.056 acc:41.93 | val loss:1.045 acc:43.20\n",
            "Epoch:0006 train loss:1.048 acc:43.50 | val loss:1.042 acc:51.33\n",
            "Epoch:0007 train loss:1.046 acc:42.59 | val loss:1.034 acc:54.82\n",
            "Epoch:0008 train loss:1.040 acc:44.58 | val loss:1.023 acc:56.04\n",
            "Epoch:0009 train loss:1.030 acc:45.74 | val loss:1.013 acc:56.88\n",
            "Epoch:0010 train loss:1.018 acc:48.39 | val loss:1.002 acc:57.15\n",
            "Epoch:0011 train loss:1.009 acc:50.13 | val loss:0.991 acc:57.81\n",
            "Epoch:0012 train loss:0.995 acc:53.36 | val loss:0.977 acc:59.40\n",
            "Epoch:0013 train loss:0.984 acc:55.13 | val loss:0.960 acc:60.71\n",
            "Epoch:0014 train loss:0.966 acc:56.68 | val loss:0.938 acc:62.60\n",
            "Epoch:0015 train loss:0.945 acc:58.27 | val loss:0.911 acc:63.19\n",
            "Epoch:0016 train loss:0.920 acc:59.39 | val loss:0.881 acc:63.11\n",
            "Epoch:0017 train loss:0.896 acc:59.06 | val loss:0.849 acc:62.81\n",
            "Epoch:0018 train loss:0.867 acc:60.15 | val loss:0.816 acc:62.93\n",
            "Epoch:0019 train loss:0.839 acc:60.11 | val loss:0.784 acc:64.18\n",
            "Epoch:0020 train loss:0.805 acc:61.05 | val loss:0.750 acc:64.36\n",
            "Epoch:0021 train loss:0.775 acc:62.11 | val loss:0.719 acc:63.82\n",
            "Epoch:0022 train loss:0.750 acc:63.30 | val loss:0.693 acc:65.85\n",
            "Epoch:0023 train loss:0.729 acc:63.68 | val loss:0.662 acc:66.56\n",
            "Epoch:0024 train loss:0.699 acc:66.37 | val loss:0.636 acc:68.00\n",
            "Epoch:0025 train loss:0.680 acc:68.11 | val loss:0.610 acc:73.11\n",
            "Epoch:0026 train loss:0.654 acc:70.85 | val loss:0.589 acc:78.05\n",
            "Epoch:0027 train loss:0.637 acc:73.55 | val loss:0.592 acc:80.08\n",
            "Epoch:0028 train loss:0.643 acc:76.24 | val loss:0.594 acc:79.79\n",
            "Epoch:0029 train loss:0.653 acc:75.68 | val loss:0.546 acc:81.49\n",
            "Epoch:0030 train loss:0.596 acc:79.29 | val loss:0.565 acc:80.71\n",
            "Epoch:0031 train loss:0.604 acc:79.19 | val loss:0.527 acc:81.62\n",
            "Epoch:0032 train loss:0.567 acc:80.60 | val loss:0.522 acc:81.81\n",
            "Epoch:0033 train loss:0.572 acc:80.34 | val loss:0.517 acc:82.08\n",
            "Epoch:0034 train loss:0.567 acc:80.62 | val loss:0.495 acc:82.47\n",
            "Epoch:0035 train loss:0.538 acc:81.69 | val loss:0.500 acc:82.22\n",
            "Epoch:0036 train loss:0.542 acc:81.43 | val loss:0.490 acc:82.19\n",
            "Epoch:0037 train loss:0.546 acc:80.81 | val loss:0.472 acc:82.77\n",
            "Epoch:0038 train loss:0.524 acc:82.13 | val loss:0.471 acc:83.15\n",
            "Epoch:0039 train loss:0.525 acc:81.65 | val loss:0.463 acc:83.39\n",
            "Epoch:0040 train loss:0.522 acc:81.68 | val loss:0.450 acc:83.72\n",
            "Epoch:0041 train loss:0.499 acc:82.16 | val loss:0.450 acc:83.77\n",
            "Epoch:0042 train loss:0.511 acc:81.96 | val loss:0.446 acc:83.82\n",
            "Epoch:0043 train loss:0.490 acc:82.87 | val loss:0.433 acc:84.55\n",
            "Epoch:0044 train loss:0.491 acc:82.49 | val loss:0.431 acc:84.22\n",
            "Epoch:0045 train loss:0.482 acc:82.49 | val loss:0.430 acc:84.17\n",
            "Epoch:0046 train loss:0.496 acc:82.48 | val loss:0.421 acc:84.69\n",
            "Epoch:0047 train loss:0.471 acc:83.49 | val loss:0.422 acc:84.80\n",
            "Epoch:0048 train loss:0.474 acc:83.48 | val loss:0.420 acc:84.79\n",
            "Epoch:0049 train loss:0.475 acc:83.23 | val loss:0.411 acc:85.04\n",
            "Epoch:0050 train loss:0.463 acc:83.51 | val loss:0.409 acc:85.36\n",
            "Epoch:0051 train loss:0.452 acc:83.92 | val loss:0.406 acc:85.37\n",
            "Epoch:0052 train loss:0.453 acc:84.14 | val loss:0.403 acc:85.20\n",
            "Epoch:0053 train loss:0.449 acc:83.90 | val loss:0.403 acc:85.13\n",
            "Epoch:0054 train loss:0.441 acc:84.19 | val loss:0.400 acc:85.29\n",
            "Epoch:0055 train loss:0.449 acc:83.67 | val loss:0.396 acc:85.66\n",
            "Epoch:0056 train loss:0.448 acc:84.32 | val loss:0.394 acc:85.93\n",
            "Epoch:0057 train loss:0.442 acc:84.13 | val loss:0.391 acc:86.12\n",
            "Epoch:0058 train loss:0.435 acc:84.67 | val loss:0.389 acc:85.93\n",
            "Epoch:0059 train loss:0.422 acc:84.90 | val loss:0.387 acc:85.75\n",
            "Epoch:0060 train loss:0.420 acc:85.18 | val loss:0.385 acc:85.91\n",
            "Epoch:0061 train loss:0.420 acc:85.28 | val loss:0.383 acc:85.99\n",
            "Epoch:0062 train loss:0.425 acc:84.75 | val loss:0.381 acc:86.20\n",
            "Epoch:0063 train loss:0.419 acc:84.92 | val loss:0.379 acc:86.28\n",
            "Epoch:0064 train loss:0.419 acc:85.36 | val loss:0.377 acc:86.26\n",
            "Epoch:0065 train loss:0.413 acc:85.63 | val loss:0.377 acc:86.26\n",
            "Epoch:0066 train loss:0.412 acc:85.18 | val loss:0.375 acc:86.28\n",
            "Epoch:0067 train loss:0.413 acc:85.07 | val loss:0.373 acc:86.34\n",
            "Epoch:0068 train loss:0.405 acc:85.90 | val loss:0.372 acc:86.43\n",
            "Epoch:0069 train loss:0.408 acc:85.51 | val loss:0.370 acc:86.37\n",
            "Epoch:0070 train loss:0.397 acc:86.16 | val loss:0.369 acc:86.51\n",
            "Epoch:0071 train loss:0.410 acc:85.99 | val loss:0.368 acc:86.59\n",
            "Epoch:0072 train loss:0.397 acc:85.61 | val loss:0.366 acc:86.53\n",
            "Epoch:0073 train loss:0.397 acc:85.97 | val loss:0.364 acc:86.56\n",
            "Epoch:0074 train loss:0.393 acc:86.03 | val loss:0.363 acc:86.69\n",
            "Epoch:0075 train loss:0.394 acc:86.15 | val loss:0.361 acc:86.70\n",
            "Epoch:0076 train loss:0.390 acc:86.18 | val loss:0.360 acc:86.85\n",
            "Epoch:0077 train loss:0.389 acc:86.15 | val loss:0.359 acc:86.93\n",
            "Epoch:0078 train loss:0.379 acc:86.62 | val loss:0.357 acc:86.86\n",
            "Epoch:0079 train loss:0.390 acc:86.10 | val loss:0.356 acc:86.88\n",
            "Epoch:0080 train loss:0.387 acc:86.35 | val loss:0.355 acc:86.89\n",
            "Epoch:0081 train loss:0.390 acc:86.04 | val loss:0.354 acc:87.02\n",
            "Epoch:0082 train loss:0.377 acc:86.43 | val loss:0.353 acc:87.04\n",
            "Epoch:0083 train loss:0.374 acc:86.55 | val loss:0.352 acc:87.12\n",
            "Epoch:0084 train loss:0.376 acc:86.38 | val loss:0.351 acc:87.10\n",
            "Epoch:0085 train loss:0.376 acc:86.64 | val loss:0.351 acc:87.04\n",
            "Epoch:0086 train loss:0.379 acc:86.60 | val loss:0.349 acc:87.07\n",
            "Epoch:0087 train loss:0.373 acc:86.91 | val loss:0.348 acc:87.31\n",
            "Epoch:0088 train loss:0.373 acc:86.90 | val loss:0.348 acc:87.31\n",
            "Epoch:0089 train loss:0.374 acc:86.79 | val loss:0.347 acc:87.31\n",
            "Epoch:0090 train loss:0.369 acc:86.76 | val loss:0.347 acc:87.32\n",
            "Epoch:0091 train loss:0.370 acc:86.64 | val loss:0.345 acc:87.34\n",
            "Epoch:0092 train loss:0.368 acc:86.68 | val loss:0.346 acc:87.46\n",
            "Epoch:0093 train loss:0.367 acc:86.90 | val loss:0.343 acc:87.46\n",
            "Epoch:0094 train loss:0.369 acc:86.88 | val loss:0.343 acc:87.50\n",
            "Epoch:0095 train loss:0.370 acc:86.71 | val loss:0.343 acc:87.48\n",
            "Epoch:0096 train loss:0.359 acc:87.03 | val loss:0.341 acc:87.54\n",
            "Epoch:0097 train loss:0.364 acc:87.20 | val loss:0.342 acc:87.53\n",
            "Epoch:0098 train loss:0.371 acc:86.67 | val loss:0.340 acc:87.54\n",
            "Epoch:0099 train loss:0.363 acc:87.12 | val loss:0.339 acc:87.48\n",
            "Epoch:0100 train loss:0.363 acc:87.01 | val loss:0.339 acc:87.58\n",
            "Epoch:0101 train loss:0.359 acc:87.07 | val loss:0.337 acc:87.67\n",
            "Epoch:0102 train loss:0.360 acc:87.29 | val loss:0.337 acc:87.54\n",
            "Epoch:0103 train loss:0.365 acc:86.65 | val loss:0.336 acc:87.69\n",
            "Epoch:0104 train loss:0.359 acc:87.64 | val loss:0.336 acc:87.69\n",
            "Epoch:0105 train loss:0.361 acc:86.97 | val loss:0.335 acc:87.75\n",
            "Epoch:0106 train loss:0.359 acc:87.15 | val loss:0.335 acc:87.81\n",
            "Epoch:0107 train loss:0.354 acc:87.49 | val loss:0.334 acc:87.80\n",
            "Epoch:0108 train loss:0.354 acc:87.38 | val loss:0.333 acc:87.77\n",
            "Epoch:0109 train loss:0.355 acc:86.84 | val loss:0.332 acc:87.78\n",
            "Epoch:0110 train loss:0.351 acc:87.36 | val loss:0.332 acc:87.94\n",
            "Epoch:0111 train loss:0.349 acc:87.66 | val loss:0.332 acc:87.84\n",
            "Epoch:0112 train loss:0.354 acc:87.70 | val loss:0.332 acc:87.97\n",
            "Epoch:0113 train loss:0.350 acc:87.69 | val loss:0.331 acc:87.99\n",
            "Epoch:0114 train loss:0.352 acc:87.46 | val loss:0.331 acc:87.91\n",
            "Epoch:0115 train loss:0.350 acc:87.23 | val loss:0.330 acc:87.89\n",
            "Epoch:0116 train loss:0.348 acc:87.33 | val loss:0.331 acc:87.99\n",
            "Epoch:0117 train loss:0.344 acc:87.75 | val loss:0.330 acc:88.03\n",
            "Epoch:0118 train loss:0.351 acc:87.35 | val loss:0.329 acc:88.10\n",
            "Epoch:0119 train loss:0.348 acc:87.70 | val loss:0.327 acc:88.05\n",
            "Epoch:0120 train loss:0.351 acc:87.56 | val loss:0.327 acc:88.00\n",
            "Epoch:0121 train loss:0.355 acc:87.69 | val loss:0.326 acc:88.05\n",
            "Epoch:0122 train loss:0.345 acc:87.45 | val loss:0.326 acc:88.23\n",
            "Epoch:0123 train loss:0.340 acc:87.88 | val loss:0.325 acc:88.13\n",
            "Epoch:0124 train loss:0.344 acc:87.64 | val loss:0.325 acc:88.10\n",
            "Epoch:0125 train loss:0.346 acc:87.89 | val loss:0.324 acc:88.07\n",
            "Epoch:0126 train loss:0.343 acc:88.11 | val loss:0.323 acc:88.15\n",
            "Epoch:0127 train loss:0.346 acc:87.53 | val loss:0.323 acc:88.16\n",
            "Epoch:0128 train loss:0.340 acc:87.91 | val loss:0.322 acc:88.19\n",
            "Epoch:0129 train loss:0.339 acc:87.55 | val loss:0.322 acc:88.10\n",
            "Epoch:0130 train loss:0.345 acc:87.31 | val loss:0.322 acc:88.15\n",
            "Epoch:0131 train loss:0.338 acc:87.93 | val loss:0.322 acc:88.13\n",
            "Epoch:0132 train loss:0.343 acc:87.50 | val loss:0.321 acc:88.19\n",
            "Epoch:0133 train loss:0.339 acc:88.00 | val loss:0.321 acc:88.15\n",
            "Epoch:0134 train loss:0.337 acc:87.98 | val loss:0.320 acc:88.10\n",
            "Epoch:0135 train loss:0.338 acc:87.98 | val loss:0.319 acc:88.21\n",
            "Epoch:0136 train loss:0.337 acc:88.12 | val loss:0.319 acc:88.24\n",
            "Epoch:0137 train loss:0.338 acc:87.73 | val loss:0.318 acc:88.24\n",
            "Epoch:0138 train loss:0.336 acc:88.11 | val loss:0.319 acc:88.27\n",
            "Epoch:0139 train loss:0.333 acc:87.71 | val loss:0.319 acc:88.27\n",
            "Epoch:0140 train loss:0.331 acc:88.51 | val loss:0.319 acc:88.32\n",
            "Epoch:0141 train loss:0.329 acc:88.05 | val loss:0.318 acc:88.29\n",
            "Epoch:0142 train loss:0.332 acc:88.13 | val loss:0.319 acc:88.43\n",
            "Epoch:0143 train loss:0.340 acc:87.65 | val loss:0.318 acc:88.30\n",
            "Epoch:0144 train loss:0.335 acc:88.00 | val loss:0.319 acc:88.16\n",
            "Epoch:0145 train loss:0.340 acc:87.76 | val loss:0.317 acc:88.37\n",
            "Epoch:0146 train loss:0.333 acc:88.13 | val loss:0.316 acc:88.43\n",
            "Epoch:0147 train loss:0.334 acc:88.10 | val loss:0.315 acc:88.42\n",
            "Epoch:0148 train loss:0.326 acc:88.37 | val loss:0.315 acc:88.42\n",
            "Epoch:0149 train loss:0.339 acc:88.14 | val loss:0.315 acc:88.48\n",
            "Epoch:0150 train loss:0.333 acc:88.31 | val loss:0.314 acc:88.40\n",
            "Epoch:0151 train loss:0.327 acc:88.53 | val loss:0.314 acc:88.42\n",
            "Epoch:0152 train loss:0.332 acc:88.25 | val loss:0.313 acc:88.48\n",
            "Epoch:0153 train loss:0.331 acc:87.84 | val loss:0.312 acc:88.34\n",
            "Epoch:0154 train loss:0.334 acc:88.13 | val loss:0.312 acc:88.29\n",
            "Epoch:0155 train loss:0.336 acc:88.13 | val loss:0.313 acc:88.46\n",
            "Epoch:0156 train loss:0.331 acc:87.96 | val loss:0.313 acc:88.45\n",
            "Epoch:0157 train loss:0.328 acc:88.31 | val loss:0.312 acc:88.37\n",
            "Epoch:0158 train loss:0.331 acc:87.83 | val loss:0.312 acc:88.46\n",
            "Epoch:0159 train loss:0.330 acc:87.82 | val loss:0.313 acc:88.49\n",
            "Epoch:0160 train loss:0.333 acc:87.91 | val loss:0.312 acc:88.45\n",
            "Epoch:0161 train loss:0.327 acc:88.48 | val loss:0.312 acc:88.54\n",
            "Epoch:0162 train loss:0.326 acc:88.09 | val loss:0.311 acc:88.49\n",
            "Epoch:0163 train loss:0.324 acc:88.20 | val loss:0.311 acc:88.54\n",
            "Epoch:0164 train loss:0.323 acc:88.63 | val loss:0.310 acc:88.40\n",
            "Epoch:0165 train loss:0.326 acc:88.21 | val loss:0.309 acc:88.72\n",
            "Epoch:0166 train loss:0.322 acc:88.31 | val loss:0.309 acc:88.91\n",
            "Epoch:0167 train loss:0.327 acc:88.14 | val loss:0.309 acc:88.54\n",
            "Epoch:0168 train loss:0.323 acc:88.56 | val loss:0.310 acc:88.48\n",
            "Epoch:0169 train loss:0.323 acc:88.19 | val loss:0.310 acc:88.62\n",
            "Epoch:0170 train loss:0.324 acc:88.16 | val loss:0.308 acc:88.81\n",
            "Epoch:0171 train loss:0.326 acc:88.44 | val loss:0.312 acc:88.49\n",
            "Epoch:0172 train loss:0.326 acc:88.54 | val loss:0.308 acc:88.48\n",
            "Epoch:0173 train loss:0.330 acc:88.01 | val loss:0.311 acc:88.53\n",
            "Epoch:0174 train loss:0.328 acc:88.30 | val loss:0.307 acc:88.76\n",
            "Epoch:0175 train loss:0.326 acc:88.29 | val loss:0.311 acc:88.38\n",
            "Epoch:0176 train loss:0.327 acc:87.87 | val loss:0.306 acc:88.57\n",
            "Epoch:0177 train loss:0.324 acc:88.43 | val loss:0.311 acc:88.68\n",
            "Epoch:0178 train loss:0.330 acc:88.15 | val loss:0.306 acc:88.65\n",
            "Epoch:0179 train loss:0.318 acc:88.52 | val loss:0.310 acc:88.51\n",
            "Epoch:0180 train loss:0.324 acc:88.43 | val loss:0.307 acc:88.59\n",
            "Epoch:0181 train loss:0.324 acc:88.19 | val loss:0.308 acc:88.75\n",
            "Epoch:0182 train loss:0.325 acc:88.11 | val loss:0.306 acc:88.70\n",
            "Epoch:0183 train loss:0.325 acc:88.15 | val loss:0.306 acc:88.68\n",
            "Epoch:0184 train loss:0.327 acc:87.68 | val loss:0.305 acc:88.78\n",
            "Epoch:0185 train loss:0.322 acc:88.35 | val loss:0.305 acc:88.72\n",
            "Epoch:0186 train loss:0.319 acc:88.32 | val loss:0.304 acc:88.65\n",
            "Epoch:0187 train loss:0.321 acc:88.60 | val loss:0.304 acc:88.67\n",
            "Epoch:0188 train loss:0.310 acc:88.50 | val loss:0.303 acc:88.92\n",
            "Epoch:0189 train loss:0.312 acc:88.79 | val loss:0.303 acc:88.75\n",
            "Epoch:0190 train loss:0.319 acc:88.68 | val loss:0.303 acc:88.83\n",
            "Epoch:0191 train loss:0.308 acc:89.24 | val loss:0.304 acc:88.83\n",
            "Epoch:0192 train loss:0.315 acc:88.76 | val loss:0.306 acc:88.81\n",
            "Epoch:0193 train loss:0.322 acc:88.30 | val loss:0.305 acc:88.80\n",
            "Epoch:0194 train loss:0.316 acc:88.85 | val loss:0.304 acc:88.75\n",
            "Epoch:0195 train loss:0.316 acc:88.81 | val loss:0.302 acc:88.97\n",
            "Epoch:0196 train loss:0.317 acc:88.26 | val loss:0.301 acc:88.97\n",
            "Epoch:0197 train loss:0.317 acc:88.14 | val loss:0.301 acc:88.94\n",
            "Epoch:0198 train loss:0.312 acc:88.65 | val loss:0.301 acc:88.94\n",
            "Epoch:0199 train loss:0.304 acc:88.80 | val loss:0.302 acc:88.81\n",
            "Epoch:0200 train loss:0.315 acc:88.79 | val loss:0.300 acc:88.86\n",
            "Epoch:0201 train loss:0.312 acc:88.75 | val loss:0.300 acc:88.97\n",
            "Epoch:0202 train loss:0.312 acc:88.93 | val loss:0.299 acc:88.95\n",
            "Epoch:0203 train loss:0.311 acc:88.72 | val loss:0.299 acc:88.89\n",
            "Epoch:0204 train loss:0.317 acc:88.59 | val loss:0.299 acc:88.87\n",
            "Epoch:0205 train loss:0.310 acc:88.53 | val loss:0.298 acc:88.86\n",
            "Epoch:0206 train loss:0.309 acc:88.75 | val loss:0.298 acc:88.91\n",
            "Epoch:0207 train loss:0.310 acc:88.84 | val loss:0.298 acc:89.03\n",
            "Epoch:0208 train loss:0.312 acc:88.83 | val loss:0.298 acc:89.00\n",
            "Epoch:0209 train loss:0.307 acc:88.71 | val loss:0.299 acc:89.00\n",
            "Epoch:0210 train loss:0.311 acc:88.68 | val loss:0.299 acc:89.06\n",
            "Epoch:0211 train loss:0.306 acc:88.65 | val loss:0.303 acc:88.73\n",
            "Epoch:0212 train loss:0.310 acc:88.52 | val loss:0.298 acc:88.94\n",
            "Epoch:0213 train loss:0.312 acc:88.45 | val loss:0.303 acc:88.62\n",
            "Epoch:0214 train loss:0.323 acc:88.20 | val loss:0.298 acc:89.00\n",
            "Epoch:0215 train loss:0.318 acc:88.14 | val loss:0.301 acc:88.81\n",
            "Epoch:0216 train loss:0.318 acc:88.38 | val loss:0.297 acc:88.94\n",
            "Epoch:0217 train loss:0.306 acc:88.80 | val loss:0.299 acc:88.81\n",
            "Epoch:0218 train loss:0.320 acc:88.16 | val loss:0.297 acc:89.11\n",
            "Epoch:0219 train loss:0.313 acc:88.59 | val loss:0.300 acc:88.94\n",
            "Epoch:0220 train loss:0.313 acc:88.59 | val loss:0.295 acc:89.13\n",
            "Epoch:0221 train loss:0.305 acc:88.91 | val loss:0.300 acc:88.70\n",
            "Epoch:0222 train loss:0.313 acc:88.57 | val loss:0.296 acc:89.06\n",
            "Epoch:0223 train loss:0.307 acc:88.75 | val loss:0.298 acc:89.19\n",
            "Epoch:0224 train loss:0.303 acc:89.13 | val loss:0.297 acc:89.11\n",
            "Epoch:0225 train loss:0.316 acc:88.52 | val loss:0.299 acc:88.78\n",
            "Epoch:0226 train loss:0.311 acc:88.93 | val loss:0.297 acc:89.19\n",
            "Epoch:0227 train loss:0.304 acc:88.71 | val loss:0.297 acc:89.08\n",
            "Epoch:0228 train loss:0.300 acc:89.00 | val loss:0.296 acc:89.06\n",
            "Epoch:0229 train loss:0.306 acc:88.35 | val loss:0.294 acc:89.18\n",
            "Epoch:0230 train loss:0.296 acc:89.37 | val loss:0.293 acc:89.30\n",
            "Epoch:0231 train loss:0.306 acc:88.89 | val loss:0.294 acc:89.29\n",
            "Epoch:0232 train loss:0.304 acc:88.69 | val loss:0.293 acc:89.21\n",
            "Epoch:0233 train loss:0.303 acc:89.18 | val loss:0.295 acc:89.02\n",
            "Epoch:0234 train loss:0.303 acc:89.28 | val loss:0.293 acc:89.21\n",
            "Epoch:0235 train loss:0.297 acc:89.25 | val loss:0.292 acc:89.24\n",
            "Epoch:0236 train loss:0.303 acc:88.96 | val loss:0.293 acc:89.27\n",
            "Epoch:0237 train loss:0.303 acc:88.98 | val loss:0.294 acc:89.11\n",
            "Epoch:0238 train loss:0.308 acc:88.93 | val loss:0.293 acc:89.18\n",
            "Epoch:0239 train loss:0.295 acc:89.00 | val loss:0.293 acc:89.26\n",
            "Epoch:0240 train loss:0.300 acc:89.13 | val loss:0.293 acc:89.24\n",
            "Epoch:0241 train loss:0.309 acc:88.59 | val loss:0.293 acc:89.27\n",
            "Epoch:0242 train loss:0.300 acc:89.09 | val loss:0.295 acc:89.19\n",
            "Epoch:0243 train loss:0.299 acc:88.96 | val loss:0.295 acc:89.02\n",
            "Epoch:0244 train loss:0.306 acc:88.64 | val loss:0.292 acc:89.26\n",
            "Epoch:0245 train loss:0.300 acc:89.21 | val loss:0.291 acc:89.37\n",
            "Epoch:0246 train loss:0.297 acc:88.85 | val loss:0.291 acc:89.33\n",
            "Epoch:0247 train loss:0.300 acc:89.00 | val loss:0.291 acc:89.30\n",
            "Epoch:0248 train loss:0.300 acc:89.18 | val loss:0.293 acc:89.11\n",
            "Epoch:0249 train loss:0.297 acc:89.20 | val loss:0.291 acc:89.43\n",
            "Epoch:0250 train loss:0.302 acc:88.71 | val loss:0.291 acc:89.41\n",
            "Epoch:0251 train loss:0.301 acc:89.20 | val loss:0.292 acc:89.26\n",
            "Epoch:0252 train loss:0.303 acc:88.75 | val loss:0.290 acc:89.41\n",
            "Epoch:0253 train loss:0.294 acc:89.40 | val loss:0.298 acc:88.95\n",
            "Epoch:0254 train loss:0.302 acc:88.61 | val loss:0.292 acc:89.24\n",
            "Epoch:0255 train loss:0.295 acc:89.15 | val loss:0.294 acc:89.00\n",
            "Epoch:0256 train loss:0.300 acc:88.87 | val loss:0.290 acc:89.48\n",
            "Epoch:0257 train loss:0.304 acc:88.65 | val loss:0.291 acc:89.35\n",
            "Epoch:0258 train loss:0.299 acc:89.04 | val loss:0.290 acc:89.30\n",
            "Epoch:0259 train loss:0.299 acc:88.86 | val loss:0.296 acc:89.13\n",
            "Epoch:0260 train loss:0.307 acc:88.56 | val loss:0.290 acc:89.32\n",
            "Epoch:0261 train loss:0.293 acc:89.33 | val loss:0.291 acc:89.52\n",
            "Epoch:0262 train loss:0.298 acc:89.04 | val loss:0.289 acc:89.46\n",
            "Epoch:0263 train loss:0.298 acc:88.86 | val loss:0.288 acc:89.38\n",
            "Epoch:0264 train loss:0.299 acc:89.12 | val loss:0.288 acc:89.43\n",
            "Epoch:0265 train loss:0.295 acc:89.09 | val loss:0.288 acc:89.33\n",
            "Epoch:0266 train loss:0.298 acc:89.17 | val loss:0.288 acc:89.27\n",
            "Epoch:0267 train loss:0.290 acc:89.31 | val loss:0.289 acc:89.48\n",
            "Epoch:0268 train loss:0.298 acc:88.74 | val loss:0.289 acc:89.57\n",
            "Epoch:0269 train loss:0.304 acc:89.04 | val loss:0.290 acc:89.27\n",
            "Epoch:0270 train loss:0.300 acc:89.06 | val loss:0.290 acc:89.45\n",
            "Epoch:0271 train loss:0.302 acc:88.79 | val loss:0.291 acc:89.40\n",
            "Epoch:0272 train loss:0.290 acc:89.33 | val loss:0.288 acc:89.29\n",
            "Epoch:0273 train loss:0.291 acc:89.59 | val loss:0.292 acc:88.89\n",
            "Epoch:0274 train loss:0.306 acc:88.81 | val loss:0.288 acc:89.54\n",
            "Epoch:0275 train loss:0.290 acc:89.31 | val loss:0.293 acc:89.18\n",
            "Epoch:0276 train loss:0.307 acc:88.60 | val loss:0.288 acc:89.16\n",
            "Epoch:0277 train loss:0.296 acc:89.26 | val loss:0.289 acc:89.19\n",
            "Epoch:0278 train loss:0.297 acc:89.32 | val loss:0.289 acc:89.48\n",
            "Epoch:0279 train loss:0.294 acc:89.13 | val loss:0.294 acc:89.06\n",
            "Epoch:0280 train loss:0.303 acc:88.65 | val loss:0.288 acc:89.33\n",
            "Epoch:0281 train loss:0.297 acc:88.96 | val loss:0.292 acc:89.03\n",
            "Epoch:0282 train loss:0.305 acc:88.71 | val loss:0.288 acc:89.56\n",
            "Epoch:0283 train loss:0.293 acc:89.25 | val loss:0.293 acc:89.02\n",
            "Epoch:0284 train loss:0.304 acc:89.02 | val loss:0.287 acc:89.60\n",
            "Epoch:0285 train loss:0.292 acc:89.50 | val loss:0.291 acc:89.21\n",
            "Epoch:0286 train loss:0.294 acc:89.16 | val loss:0.286 acc:89.46\n",
            "Epoch:0287 train loss:0.288 acc:89.63 | val loss:0.290 acc:89.32\n",
            "Epoch:0288 train loss:0.301 acc:89.01 | val loss:0.287 acc:89.70\n",
            "Epoch:0289 train loss:0.287 acc:89.42 | val loss:0.290 acc:89.16\n",
            "Epoch:0290 train loss:0.294 acc:89.25 | val loss:0.289 acc:89.22\n",
            "Epoch:0291 train loss:0.289 acc:89.44 | val loss:0.290 acc:89.51\n",
            "Epoch:0292 train loss:0.294 acc:88.88 | val loss:0.288 acc:89.64\n",
            "Epoch:0293 train loss:0.287 acc:89.41 | val loss:0.287 acc:89.51\n",
            "Epoch:0294 train loss:0.286 acc:89.53 | val loss:0.287 acc:89.26\n",
            "Epoch:0295 train loss:0.287 acc:89.24 | val loss:0.286 acc:89.57\n",
            "Epoch:0296 train loss:0.292 acc:89.10 | val loss:0.287 acc:89.51\n",
            "Epoch:0297 train loss:0.295 acc:89.33 | val loss:0.284 acc:89.60\n",
            "Epoch:0298 train loss:0.291 acc:89.63 | val loss:0.286 acc:89.48\n",
            "Epoch:0299 train loss:0.284 acc:89.44 | val loss:0.285 acc:89.60\n",
            "Epoch:0300 train loss:0.291 acc:89.08 | val loss:0.288 acc:89.46\n",
            "Epoch:0301 train loss:0.291 acc:89.08 | val loss:0.287 acc:89.64\n",
            "Epoch:0302 train loss:0.287 acc:89.25 | val loss:0.288 acc:89.33\n",
            "Epoch:0303 train loss:0.292 acc:89.72 | val loss:0.286 acc:89.46\n",
            "Epoch:0304 train loss:0.285 acc:89.65 | val loss:0.286 acc:89.60\n",
            "Epoch:0305 train loss:0.287 acc:89.67 | val loss:0.286 acc:89.68\n",
            "Epoch:0306 train loss:0.283 acc:89.65 | val loss:0.286 acc:89.60\n",
            "Epoch:0307 train loss:0.283 acc:89.30 | val loss:0.285 acc:89.62\n",
            "Epoch:0308 train loss:0.286 acc:89.23 | val loss:0.285 acc:89.59\n",
            "Epoch:0309 train loss:0.292 acc:89.62 | val loss:0.285 acc:89.70\n",
            "Epoch:0310 train loss:0.292 acc:89.08 | val loss:0.286 acc:89.64\n",
            "Epoch:0311 train loss:0.289 acc:89.59 | val loss:0.285 acc:89.43\n",
            "Epoch:0312 train loss:0.290 acc:89.21 | val loss:0.285 acc:89.59\n",
            "Epoch:0313 train loss:0.288 acc:89.49 | val loss:0.284 acc:89.67\n",
            "Epoch:0314 train loss:0.290 acc:89.50 | val loss:0.286 acc:89.65\n",
            "Epoch:0315 train loss:0.289 acc:89.24 | val loss:0.286 acc:89.62\n",
            "Epoch:0316 train loss:0.284 acc:89.54 | val loss:0.287 acc:89.52\n",
            "Epoch:0317 train loss:0.286 acc:89.32 | val loss:0.287 acc:89.60\n",
            "Epoch:0318 train loss:0.287 acc:89.60 | val loss:0.286 acc:89.52\n",
            "Epoch:0319 train loss:0.286 acc:89.46 | val loss:0.284 acc:89.70\n",
            "Epoch:0320 train loss:0.289 acc:89.38 | val loss:0.284 acc:89.59\n",
            "Epoch:0321 train loss:0.289 acc:89.45 | val loss:0.286 acc:89.49\n",
            "Epoch:0322 train loss:0.292 acc:89.03 | val loss:0.283 acc:89.57\n",
            "Epoch:0323 train loss:0.288 acc:89.57 | val loss:0.281 acc:89.65\n",
            "Epoch:0324 train loss:0.288 acc:89.25 | val loss:0.282 acc:89.57\n",
            "Epoch:0325 train loss:0.285 acc:89.47 | val loss:0.286 acc:89.54\n",
            "Epoch:0326 train loss:0.297 acc:88.93 | val loss:0.285 acc:89.64\n",
            "Epoch:0327 train loss:0.290 acc:89.23 | val loss:0.285 acc:89.57\n",
            "Epoch:0328 train loss:0.292 acc:89.13 | val loss:0.283 acc:89.64\n",
            "Epoch:0329 train loss:0.285 acc:89.57 | val loss:0.291 acc:89.24\n",
            "Epoch:0330 train loss:0.286 acc:89.50 | val loss:0.290 acc:89.43\n",
            "Epoch:0331 train loss:0.289 acc:89.44 | val loss:0.292 acc:89.24\n",
            "Epoch:0332 train loss:0.290 acc:89.45 | val loss:0.285 acc:89.71\n",
            "Epoch:0333 train loss:0.280 acc:89.54 | val loss:0.287 acc:89.57\n",
            "Epoch:0334 train loss:0.292 acc:89.02 | val loss:0.285 acc:89.64\n",
            "Epoch:0335 train loss:0.286 acc:89.53 | val loss:0.286 acc:89.59\n",
            "Epoch:0336 train loss:0.285 acc:89.52 | val loss:0.286 acc:89.64\n",
            "Epoch:0337 train loss:0.286 acc:89.35 | val loss:0.282 acc:89.92\n",
            "Epoch:0338 train loss:0.285 acc:89.64 | val loss:0.282 acc:89.79\n",
            "Epoch:0339 train loss:0.284 acc:89.25 | val loss:0.282 acc:89.83\n",
            "Epoch:0340 train loss:0.286 acc:89.52 | val loss:0.283 acc:89.78\n",
            "Epoch:0341 train loss:0.284 acc:89.49 | val loss:0.286 acc:89.78\n",
            "Epoch:0342 train loss:0.286 acc:89.46 | val loss:0.285 acc:89.73\n",
            "Epoch:0343 train loss:0.287 acc:89.44 | val loss:0.283 acc:89.75\n",
            "Epoch:0344 train loss:0.278 acc:89.92 | val loss:0.283 acc:89.79\n",
            "Epoch:0345 train loss:0.282 acc:89.57 | val loss:0.283 acc:89.87\n",
            "Epoch:0346 train loss:0.278 acc:89.62 | val loss:0.283 acc:89.75\n",
            "Epoch:0347 train loss:0.284 acc:89.22 | val loss:0.283 acc:89.59\n",
            "Epoch:0348 train loss:0.278 acc:89.64 | val loss:0.281 acc:89.73\n",
            "Epoch:0349 train loss:0.271 acc:90.17 | val loss:0.282 acc:89.83\n",
            "Epoch:0350 train loss:0.283 acc:89.50 | val loss:0.281 acc:89.76\n",
            "Epoch:0351 train loss:0.275 acc:89.73 | val loss:0.282 acc:89.81\n",
            "Epoch:0352 train loss:0.273 acc:90.05 | val loss:0.284 acc:89.76\n",
            "Epoch:0353 train loss:0.280 acc:89.56 | val loss:0.284 acc:89.83\n",
            "Epoch:0354 train loss:0.278 acc:89.90 | val loss:0.283 acc:89.70\n",
            "Epoch:0355 train loss:0.291 acc:89.23 | val loss:0.282 acc:89.79\n",
            "Epoch:0356 train loss:0.280 acc:89.74 | val loss:0.283 acc:89.90\n",
            "Epoch:0357 train loss:0.274 acc:89.77 | val loss:0.281 acc:89.87\n",
            "Epoch:0358 train loss:0.280 acc:89.55 | val loss:0.280 acc:89.81\n",
            "Epoch:0359 train loss:0.279 acc:89.73 | val loss:0.280 acc:89.87\n",
            "Epoch:0360 train loss:0.284 acc:89.72 | val loss:0.280 acc:89.90\n",
            "Epoch:0361 train loss:0.274 acc:89.95 | val loss:0.281 acc:89.81\n",
            "Epoch:0362 train loss:0.272 acc:90.13 | val loss:0.283 acc:89.70\n",
            "Epoch:0363 train loss:0.273 acc:89.87 | val loss:0.283 acc:89.62\n",
            "Epoch:0364 train loss:0.279 acc:89.74 | val loss:0.284 acc:89.75\n",
            "Epoch:0365 train loss:0.283 acc:89.67 | val loss:0.284 acc:89.78\n",
            "Epoch:0366 train loss:0.278 acc:89.76 | val loss:0.284 acc:89.67\n",
            "Epoch:0367 train loss:0.282 acc:89.56 | val loss:0.283 acc:89.71\n",
            "Epoch:0368 train loss:0.279 acc:89.25 | val loss:0.280 acc:89.89\n",
            "Epoch:0369 train loss:0.283 acc:89.59 | val loss:0.278 acc:89.94\n",
            "Epoch:0370 train loss:0.281 acc:89.77 | val loss:0.278 acc:89.83\n",
            "Epoch:0371 train loss:0.280 acc:89.45 | val loss:0.279 acc:89.81\n",
            "Epoch:0372 train loss:0.275 acc:90.08 | val loss:0.285 acc:89.49\n",
            "Epoch:0373 train loss:0.277 acc:89.65 | val loss:0.280 acc:89.76\n",
            "Epoch:0374 train loss:0.275 acc:89.60 | val loss:0.282 acc:89.78\n",
            "Epoch:0375 train loss:0.272 acc:89.52 | val loss:0.282 acc:89.78\n",
            "Epoch:0376 train loss:0.281 acc:89.69 | val loss:0.282 acc:89.86\n",
            "Epoch:0377 train loss:0.278 acc:89.81 | val loss:0.282 acc:89.76\n",
            "Epoch:0378 train loss:0.282 acc:89.70 | val loss:0.282 acc:89.76\n",
            "Epoch:0379 train loss:0.274 acc:89.62 | val loss:0.282 acc:89.64\n",
            "Epoch:0380 train loss:0.285 acc:89.45 | val loss:0.280 acc:89.81\n",
            "Epoch:0381 train loss:0.276 acc:90.03 | val loss:0.281 acc:89.81\n",
            "Epoch:0382 train loss:0.279 acc:90.01 | val loss:0.280 acc:89.81\n",
            "Epoch:0383 train loss:0.275 acc:90.12 | val loss:0.286 acc:89.29\n",
            "Epoch:0384 train loss:0.281 acc:89.31 | val loss:0.280 acc:89.70\n",
            "Epoch:0385 train loss:0.280 acc:89.56 | val loss:0.282 acc:89.78\n",
            "Epoch:0386 train loss:0.279 acc:89.53 | val loss:0.280 acc:89.79\n",
            "Epoch:0387 train loss:0.280 acc:89.63 | val loss:0.284 acc:89.68\n",
            "Epoch:0388 train loss:0.283 acc:89.59 | val loss:0.282 acc:89.76\n",
            "Epoch:0389 train loss:0.274 acc:89.71 | val loss:0.282 acc:89.73\n",
            "Epoch:0390 train loss:0.278 acc:89.70 | val loss:0.279 acc:89.75\n",
            "Epoch:0391 train loss:0.276 acc:89.59 | val loss:0.280 acc:89.76\n",
            "Epoch:0392 train loss:0.275 acc:89.62 | val loss:0.281 acc:89.64\n",
            "Epoch:0393 train loss:0.275 acc:89.89 | val loss:0.281 acc:89.70\n",
            "Epoch:0394 train loss:0.272 acc:89.72 | val loss:0.282 acc:89.73\n",
            "Epoch:0395 train loss:0.277 acc:89.51 | val loss:0.282 acc:89.71\n",
            "Epoch:0396 train loss:0.271 acc:89.95 | val loss:0.284 acc:89.71\n",
            "Epoch:0397 train loss:0.276 acc:89.53 | val loss:0.281 acc:89.68\n",
            "Epoch:0398 train loss:0.269 acc:89.95 | val loss:0.283 acc:89.67\n",
            "Epoch:0399 train loss:0.281 acc:89.63 | val loss:0.285 acc:89.54\n",
            "Epoch:0400 train loss:0.272 acc:90.19 | val loss:0.285 acc:89.49\n",
            "Epoch:0401 train loss:0.275 acc:89.82 | val loss:0.278 acc:89.75\n",
            "Epoch:0402 train loss:0.269 acc:90.14 | val loss:0.286 acc:89.57\n",
            "Epoch:0403 train loss:0.288 acc:89.18 | val loss:0.278 acc:89.86\n",
            "Epoch:0404 train loss:0.270 acc:90.14 | val loss:0.287 acc:89.26\n",
            "Epoch:0405 train loss:0.286 acc:89.02 | val loss:0.281 acc:89.75\n",
            "Epoch:0406 train loss:0.268 acc:90.17 | val loss:0.286 acc:89.45\n",
            "Epoch:0407 train loss:0.281 acc:89.28 | val loss:0.280 acc:89.90\n",
            "Epoch:0408 train loss:0.270 acc:90.01 | val loss:0.287 acc:89.40\n",
            "Epoch:0409 train loss:0.286 acc:89.28 | val loss:0.279 acc:89.78\n",
            "Epoch:0410 train loss:0.272 acc:89.94 | val loss:0.286 acc:89.56\n",
            "Epoch:0411 train loss:0.279 acc:89.63 | val loss:0.282 acc:89.81\n",
            "Epoch:0412 train loss:0.272 acc:90.35 | val loss:0.286 acc:89.54\n",
            "Epoch:0413 train loss:0.275 acc:89.71 | val loss:0.281 acc:89.84\n",
            "Epoch:0414 train loss:0.269 acc:90.19 | val loss:0.282 acc:89.70\n",
            "Epoch:0415 train loss:0.278 acc:89.72 | val loss:0.281 acc:89.73\n",
            "Epoch:0416 train loss:0.279 acc:89.64 | val loss:0.283 acc:89.64\n",
            "Epoch:0417 train loss:0.278 acc:89.63 | val loss:0.279 acc:89.84\n",
            "Epoch:0418 train loss:0.278 acc:89.89 | val loss:0.281 acc:89.70\n",
            "Epoch:0419 train loss:0.283 acc:89.55 | val loss:0.277 acc:89.95\n",
            "Epoch:0420 train loss:0.267 acc:90.10 | val loss:0.280 acc:89.76\n",
            "Epoch:0421 train loss:0.272 acc:89.69 | val loss:0.280 acc:89.78\n",
            "Epoch:0422 train loss:0.270 acc:90.14 | val loss:0.288 acc:89.38\n",
            "Epoch:0423 train loss:0.282 acc:89.74 | val loss:0.281 acc:89.73\n",
            "Epoch:0424 train loss:0.267 acc:90.15 | val loss:0.284 acc:89.71\n",
            "Epoch:0425 train loss:0.272 acc:90.11 | val loss:0.279 acc:89.98\n",
            "Epoch:0426 train loss:0.268 acc:90.34 | val loss:0.281 acc:89.64\n",
            "Epoch:0427 train loss:0.274 acc:89.99 | val loss:0.279 acc:89.87\n",
            "Epoch:0428 train loss:0.273 acc:89.93 | val loss:0.283 acc:89.48\n",
            "Epoch:0429 train loss:0.274 acc:89.74 | val loss:0.277 acc:89.95\n",
            "Epoch:0430 train loss:0.274 acc:89.83 | val loss:0.277 acc:89.95\n",
            "Epoch:0431 train loss:0.270 acc:89.83 | val loss:0.277 acc:89.84\n",
            "Epoch:0432 train loss:0.268 acc:90.12 | val loss:0.279 acc:89.86\n",
            "Epoch:0433 train loss:0.260 acc:90.31 | val loss:0.285 acc:89.73\n",
            "Epoch:0434 train loss:0.269 acc:89.84 | val loss:0.283 acc:89.79\n",
            "Epoch:0435 train loss:0.271 acc:90.06 | val loss:0.282 acc:89.67\n",
            "Epoch:0436 train loss:0.270 acc:89.75 | val loss:0.279 acc:89.79\n",
            "Epoch:0437 train loss:0.267 acc:89.82 | val loss:0.280 acc:89.95\n",
            "Epoch:0438 train loss:0.272 acc:89.65 | val loss:0.278 acc:89.98\n",
            "Epoch:0439 train loss:0.265 acc:90.26 | val loss:0.280 acc:89.73\n",
            "Epoch:0440 train loss:0.276 acc:89.80 | val loss:0.279 acc:89.95\n",
            "Epoch:0441 train loss:0.271 acc:90.13 | val loss:0.279 acc:89.84\n",
            "Epoch:0442 train loss:0.269 acc:89.88 | val loss:0.275 acc:90.05\n",
            "Epoch:0443 train loss:0.263 acc:90.26 | val loss:0.276 acc:90.00\n",
            "Epoch:0444 train loss:0.271 acc:90.11 | val loss:0.276 acc:90.03\n",
            "Epoch:0445 train loss:0.271 acc:89.65 | val loss:0.279 acc:89.90\n",
            "Epoch:0446 train loss:0.276 acc:90.14 | val loss:0.281 acc:89.76\n",
            "Epoch:0447 train loss:0.267 acc:90.09 | val loss:0.277 acc:89.90\n",
            "Epoch:0448 train loss:0.262 acc:90.42 | val loss:0.278 acc:89.94\n",
            "Epoch:0449 train loss:0.274 acc:89.79 | val loss:0.277 acc:90.00\n",
            "Epoch:0450 train loss:0.261 acc:90.14 | val loss:0.279 acc:89.89\n",
            "Epoch:0451 train loss:0.262 acc:90.37 | val loss:0.280 acc:89.89\n",
            "Epoch:0452 train loss:0.269 acc:89.81 | val loss:0.278 acc:89.86\n",
            "Epoch:0453 train loss:0.260 acc:90.47 | val loss:0.276 acc:89.86\n",
            "Epoch:0454 train loss:0.261 acc:90.38 | val loss:0.276 acc:89.95\n",
            "Epoch:0455 train loss:0.261 acc:90.35 | val loss:0.278 acc:89.81\n",
            "Epoch:0456 train loss:0.268 acc:90.11 | val loss:0.278 acc:89.84\n",
            "Epoch:0457 train loss:0.262 acc:90.18 | val loss:0.279 acc:89.79\n",
            "Epoch:0458 train loss:0.261 acc:90.42 | val loss:0.278 acc:89.84\n",
            "Epoch:0459 train loss:0.266 acc:90.11 | val loss:0.277 acc:89.95\n",
            "Epoch:0460 train loss:0.261 acc:90.36 | val loss:0.278 acc:89.84\n",
            "Epoch:0461 train loss:0.267 acc:89.84 | val loss:0.278 acc:89.83\n",
            "Epoch:0462 train loss:0.267 acc:90.30 | val loss:0.284 acc:89.71\n",
            "Epoch:0463 train loss:0.272 acc:89.97 | val loss:0.280 acc:89.86\n",
            "Epoch:0464 train loss:0.265 acc:90.51 | val loss:0.278 acc:89.84\n",
            "Epoch:0465 train loss:0.262 acc:90.17 | val loss:0.276 acc:89.95\n",
            "Epoch:0466 train loss:0.263 acc:89.97 | val loss:0.277 acc:90.02\n",
            "Epoch:0467 train loss:0.258 acc:90.42 | val loss:0.278 acc:89.92\n",
            "Epoch:0468 train loss:0.263 acc:90.31 | val loss:0.278 acc:89.87\n",
            "Epoch:0469 train loss:0.257 acc:90.61 | val loss:0.279 acc:89.89\n",
            "Epoch:0470 train loss:0.261 acc:90.02 | val loss:0.279 acc:89.84\n",
            "Epoch:0471 train loss:0.259 acc:90.61 | val loss:0.280 acc:89.83\n",
            "Epoch:0472 train loss:0.259 acc:90.46 | val loss:0.281 acc:89.89\n",
            "Epoch:0473 train loss:0.260 acc:90.27 | val loss:0.279 acc:89.97\n",
            "Epoch:0474 train loss:0.259 acc:90.53 | val loss:0.277 acc:89.95\n",
            "Epoch:0475 train loss:0.263 acc:90.15 | val loss:0.276 acc:89.95\n",
            "Epoch:0476 train loss:0.257 acc:90.55 | val loss:0.277 acc:90.06\n",
            "Epoch:0477 train loss:0.259 acc:90.53 | val loss:0.279 acc:90.02\n",
            "Epoch:0478 train loss:0.261 acc:90.38 | val loss:0.277 acc:90.00\n",
            "Epoch:0479 train loss:0.257 acc:90.23 | val loss:0.277 acc:89.89\n",
            "Epoch:0480 train loss:0.259 acc:90.27 | val loss:0.278 acc:90.08\n",
            "Epoch:0481 train loss:0.270 acc:90.00 | val loss:0.280 acc:89.95\n",
            "Epoch:0482 train loss:0.269 acc:89.95 | val loss:0.279 acc:89.98\n",
            "Epoch:0483 train loss:0.264 acc:90.40 | val loss:0.278 acc:89.97\n",
            "Epoch:0484 train loss:0.255 acc:90.63 | val loss:0.277 acc:90.08\n",
            "Epoch:0485 train loss:0.262 acc:90.44 | val loss:0.277 acc:90.13\n",
            "Epoch:0486 train loss:0.265 acc:90.28 | val loss:0.278 acc:90.05\n",
            "Epoch:0487 train loss:0.257 acc:90.74 | val loss:0.277 acc:90.08\n",
            "Epoch:0488 train loss:0.262 acc:90.35 | val loss:0.277 acc:89.98\n",
            "Epoch:0489 train loss:0.260 acc:90.46 | val loss:0.277 acc:90.05\n",
            "Epoch:0490 train loss:0.263 acc:90.39 | val loss:0.276 acc:90.05\n",
            "Epoch:0491 train loss:0.264 acc:90.01 | val loss:0.276 acc:89.97\n",
            "Epoch:0492 train loss:0.259 acc:90.54 | val loss:0.278 acc:90.00\n",
            "2 : 89.81\n",
            "Epoch:0001 train loss:1.095 acc:38.76 | val loss:1.085 acc:38.84\n",
            "Epoch:0002 train loss:1.085 acc:38.75 | val loss:1.074 acc:38.86\n",
            "Epoch:0003 train loss:1.073 acc:38.93 | val loss:1.060 acc:39.40\n",
            "Epoch:0004 train loss:1.059 acc:39.36 | val loss:1.049 acc:41.30\n",
            "Epoch:0005 train loss:1.047 acc:40.92 | val loss:1.049 acc:47.08\n",
            "Epoch:0006 train loss:1.047 acc:40.81 | val loss:1.036 acc:50.10\n",
            "Epoch:0007 train loss:1.035 acc:43.55 | val loss:1.022 acc:50.68\n",
            "Epoch:0008 train loss:1.023 acc:43.94 | val loss:1.012 acc:54.87\n",
            "Epoch:0009 train loss:1.012 acc:47.46 | val loss:1.000 acc:58.64\n",
            "Epoch:0010 train loss:1.000 acc:50.04 | val loss:0.984 acc:61.54\n",
            "Epoch:0011 train loss:0.985 acc:52.33 | val loss:0.964 acc:62.44\n",
            "Epoch:0012 train loss:0.966 acc:54.59 | val loss:0.941 acc:62.98\n",
            "Epoch:0013 train loss:0.944 acc:55.43 | val loss:0.916 acc:62.47\n",
            "Epoch:0014 train loss:0.922 acc:56.02 | val loss:0.890 acc:62.52\n",
            "Epoch:0015 train loss:0.896 acc:57.81 | val loss:0.862 acc:63.41\n",
            "Epoch:0016 train loss:0.874 acc:58.11 | val loss:0.831 acc:63.90\n",
            "Epoch:0017 train loss:0.844 acc:59.98 | val loss:0.799 acc:63.85\n",
            "Epoch:0018 train loss:0.813 acc:61.63 | val loss:0.764 acc:64.01\n",
            "Epoch:0019 train loss:0.781 acc:63.28 | val loss:0.724 acc:64.80\n",
            "Epoch:0020 train loss:0.747 acc:64.14 | val loss:0.684 acc:66.24\n",
            "Epoch:0021 train loss:0.709 acc:65.19 | val loss:0.648 acc:66.64\n",
            "Epoch:0022 train loss:0.682 acc:66.94 | val loss:0.641 acc:65.17\n",
            "Epoch:0023 train loss:0.668 acc:66.64 | val loss:0.622 acc:68.83\n",
            "Epoch:0024 train loss:0.645 acc:71.26 | val loss:0.592 acc:76.89\n",
            "Epoch:0025 train loss:0.625 acc:73.27 | val loss:0.587 acc:79.48\n",
            "Epoch:0026 train loss:0.620 acc:74.18 | val loss:0.560 acc:81.13\n",
            "Epoch:0027 train loss:0.596 acc:76.58 | val loss:0.550 acc:81.62\n",
            "Epoch:0028 train loss:0.578 acc:78.97 | val loss:0.533 acc:82.16\n",
            "Epoch:0029 train loss:0.562 acc:80.27 | val loss:0.529 acc:82.35\n",
            "Epoch:0030 train loss:0.566 acc:80.13 | val loss:0.516 acc:82.76\n",
            "Epoch:0031 train loss:0.549 acc:81.39 | val loss:0.505 acc:83.33\n",
            "Epoch:0032 train loss:0.533 acc:82.14 | val loss:0.495 acc:83.69\n",
            "Epoch:0033 train loss:0.527 acc:82.48 | val loss:0.486 acc:84.06\n",
            "Epoch:0034 train loss:0.523 acc:82.19 | val loss:0.477 acc:84.18\n",
            "Epoch:0035 train loss:0.517 acc:82.97 | val loss:0.468 acc:84.55\n",
            "Epoch:0036 train loss:0.505 acc:82.97 | val loss:0.461 acc:84.55\n",
            "Epoch:0037 train loss:0.493 acc:83.17 | val loss:0.452 acc:84.77\n",
            "Epoch:0038 train loss:0.489 acc:82.94 | val loss:0.443 acc:85.09\n",
            "Epoch:0039 train loss:0.483 acc:84.11 | val loss:0.434 acc:84.90\n",
            "Epoch:0040 train loss:0.482 acc:83.61 | val loss:0.427 acc:84.94\n",
            "Epoch:0041 train loss:0.470 acc:83.62 | val loss:0.420 acc:85.13\n",
            "Epoch:0042 train loss:0.474 acc:83.11 | val loss:0.415 acc:85.26\n",
            "Epoch:0043 train loss:0.462 acc:84.33 | val loss:0.410 acc:85.63\n",
            "Epoch:0044 train loss:0.466 acc:84.17 | val loss:0.406 acc:85.56\n",
            "Epoch:0045 train loss:0.453 acc:83.87 | val loss:0.400 acc:85.52\n",
            "Epoch:0046 train loss:0.449 acc:84.11 | val loss:0.395 acc:85.72\n",
            "Epoch:0047 train loss:0.449 acc:83.73 | val loss:0.391 acc:85.86\n",
            "Epoch:0048 train loss:0.441 acc:84.56 | val loss:0.389 acc:85.91\n",
            "Epoch:0049 train loss:0.432 acc:84.79 | val loss:0.386 acc:86.01\n",
            "Epoch:0050 train loss:0.434 acc:84.69 | val loss:0.381 acc:85.99\n",
            "Epoch:0051 train loss:0.429 acc:84.84 | val loss:0.379 acc:85.93\n",
            "Epoch:0052 train loss:0.426 acc:85.07 | val loss:0.375 acc:86.23\n",
            "Epoch:0053 train loss:0.422 acc:85.19 | val loss:0.372 acc:86.32\n",
            "Epoch:0054 train loss:0.420 acc:85.41 | val loss:0.372 acc:86.50\n",
            "Epoch:0055 train loss:0.418 acc:85.39 | val loss:0.368 acc:86.50\n",
            "Epoch:0056 train loss:0.405 acc:85.79 | val loss:0.366 acc:86.51\n",
            "Epoch:0057 train loss:0.409 acc:85.53 | val loss:0.362 acc:86.66\n",
            "Epoch:0058 train loss:0.405 acc:85.51 | val loss:0.361 acc:86.70\n",
            "Epoch:0059 train loss:0.401 acc:86.15 | val loss:0.358 acc:86.83\n",
            "Epoch:0060 train loss:0.406 acc:85.60 | val loss:0.357 acc:86.72\n",
            "Epoch:0061 train loss:0.401 acc:86.04 | val loss:0.355 acc:86.99\n",
            "Epoch:0062 train loss:0.391 acc:86.30 | val loss:0.353 acc:86.97\n",
            "Epoch:0063 train loss:0.394 acc:86.14 | val loss:0.352 acc:87.08\n",
            "Epoch:0064 train loss:0.393 acc:86.30 | val loss:0.348 acc:87.15\n",
            "Epoch:0065 train loss:0.387 acc:86.37 | val loss:0.350 acc:86.85\n",
            "Epoch:0066 train loss:0.399 acc:86.11 | val loss:0.346 acc:87.37\n",
            "Epoch:0067 train loss:0.391 acc:86.06 | val loss:0.346 acc:87.58\n",
            "Epoch:0068 train loss:0.381 acc:86.84 | val loss:0.342 acc:87.54\n",
            "Epoch:0069 train loss:0.389 acc:87.10 | val loss:0.343 acc:87.21\n",
            "Epoch:0070 train loss:0.386 acc:86.52 | val loss:0.340 acc:87.65\n",
            "Epoch:0071 train loss:0.382 acc:86.43 | val loss:0.341 acc:87.54\n",
            "Epoch:0072 train loss:0.381 acc:87.13 | val loss:0.339 acc:87.80\n",
            "Epoch:0073 train loss:0.374 acc:87.08 | val loss:0.337 acc:87.69\n",
            "Epoch:0074 train loss:0.375 acc:86.97 | val loss:0.335 acc:87.73\n",
            "Epoch:0075 train loss:0.367 acc:87.09 | val loss:0.334 acc:87.75\n",
            "Epoch:0076 train loss:0.372 acc:87.14 | val loss:0.333 acc:87.97\n",
            "Epoch:0077 train loss:0.367 acc:87.00 | val loss:0.332 acc:87.99\n",
            "Epoch:0078 train loss:0.368 acc:87.23 | val loss:0.331 acc:88.13\n",
            "Epoch:0079 train loss:0.367 acc:86.89 | val loss:0.330 acc:88.05\n",
            "Epoch:0080 train loss:0.367 acc:87.03 | val loss:0.328 acc:88.13\n",
            "Epoch:0081 train loss:0.367 acc:86.78 | val loss:0.328 acc:88.23\n",
            "Epoch:0082 train loss:0.374 acc:86.70 | val loss:0.327 acc:88.15\n",
            "Epoch:0083 train loss:0.368 acc:86.93 | val loss:0.326 acc:88.16\n",
            "Epoch:0084 train loss:0.362 acc:87.04 | val loss:0.325 acc:88.21\n",
            "Epoch:0085 train loss:0.361 acc:87.18 | val loss:0.326 acc:88.27\n",
            "Epoch:0086 train loss:0.361 acc:87.10 | val loss:0.324 acc:88.43\n",
            "Epoch:0087 train loss:0.359 acc:87.13 | val loss:0.325 acc:88.13\n",
            "Epoch:0088 train loss:0.357 acc:87.39 | val loss:0.322 acc:88.37\n",
            "Epoch:0089 train loss:0.353 acc:87.51 | val loss:0.325 acc:88.34\n",
            "Epoch:0090 train loss:0.363 acc:86.81 | val loss:0.321 acc:88.46\n",
            "Epoch:0091 train loss:0.356 acc:87.44 | val loss:0.322 acc:88.37\n",
            "Epoch:0092 train loss:0.360 acc:87.01 | val loss:0.319 acc:88.45\n",
            "Epoch:0093 train loss:0.354 acc:87.44 | val loss:0.319 acc:88.57\n",
            "Epoch:0094 train loss:0.357 acc:87.65 | val loss:0.318 acc:88.53\n",
            "Epoch:0095 train loss:0.355 acc:87.76 | val loss:0.317 acc:88.48\n",
            "Epoch:0096 train loss:0.349 acc:87.42 | val loss:0.317 acc:88.43\n",
            "Epoch:0097 train loss:0.355 acc:87.50 | val loss:0.315 acc:88.54\n",
            "Epoch:0098 train loss:0.348 acc:87.48 | val loss:0.316 acc:88.53\n",
            "Epoch:0099 train loss:0.349 acc:87.41 | val loss:0.315 acc:88.62\n",
            "Epoch:0100 train loss:0.349 acc:87.55 | val loss:0.315 acc:88.54\n",
            "Epoch:0101 train loss:0.352 acc:87.60 | val loss:0.313 acc:88.68\n",
            "Epoch:0102 train loss:0.347 acc:87.84 | val loss:0.315 acc:88.65\n",
            "Epoch:0103 train loss:0.343 acc:88.17 | val loss:0.312 acc:88.75\n",
            "Epoch:0104 train loss:0.343 acc:87.81 | val loss:0.313 acc:88.51\n",
            "Epoch:0105 train loss:0.352 acc:87.49 | val loss:0.312 acc:88.57\n",
            "Epoch:0106 train loss:0.341 acc:87.81 | val loss:0.316 acc:88.51\n",
            "Epoch:0107 train loss:0.346 acc:87.73 | val loss:0.315 acc:88.65\n",
            "Epoch:0108 train loss:0.352 acc:87.45 | val loss:0.310 acc:88.84\n",
            "Epoch:0109 train loss:0.343 acc:87.89 | val loss:0.313 acc:88.65\n",
            "Epoch:0110 train loss:0.344 acc:87.68 | val loss:0.310 acc:88.86\n",
            "Epoch:0111 train loss:0.350 acc:87.38 | val loss:0.316 acc:88.30\n",
            "Epoch:0112 train loss:0.350 acc:87.09 | val loss:0.308 acc:88.72\n",
            "Epoch:0113 train loss:0.339 acc:88.37 | val loss:0.312 acc:88.86\n",
            "Epoch:0114 train loss:0.351 acc:87.84 | val loss:0.308 acc:88.86\n",
            "Epoch:0115 train loss:0.337 acc:88.21 | val loss:0.310 acc:88.70\n",
            "Epoch:0116 train loss:0.339 acc:87.95 | val loss:0.306 acc:88.81\n",
            "Epoch:0117 train loss:0.336 acc:88.22 | val loss:0.307 acc:88.72\n",
            "Epoch:0118 train loss:0.338 acc:87.94 | val loss:0.306 acc:88.84\n",
            "Epoch:0119 train loss:0.340 acc:87.93 | val loss:0.309 acc:88.95\n",
            "Epoch:0120 train loss:0.337 acc:88.06 | val loss:0.308 acc:88.92\n",
            "Epoch:0121 train loss:0.335 acc:88.25 | val loss:0.308 acc:89.06\n",
            "Epoch:0122 train loss:0.329 acc:88.11 | val loss:0.306 acc:88.83\n",
            "Epoch:0123 train loss:0.337 acc:88.15 | val loss:0.305 acc:88.86\n",
            "Epoch:0124 train loss:0.334 acc:88.20 | val loss:0.307 acc:88.80\n",
            "Epoch:0125 train loss:0.341 acc:87.98 | val loss:0.304 acc:88.89\n",
            "Epoch:0126 train loss:0.342 acc:87.78 | val loss:0.306 acc:89.02\n",
            "Epoch:0127 train loss:0.336 acc:88.21 | val loss:0.305 acc:89.05\n",
            "Epoch:0128 train loss:0.332 acc:88.24 | val loss:0.305 acc:88.92\n",
            "Epoch:0129 train loss:0.337 acc:87.79 | val loss:0.304 acc:88.94\n",
            "Epoch:0130 train loss:0.337 acc:88.20 | val loss:0.303 acc:89.00\n",
            "Epoch:0131 train loss:0.338 acc:88.31 | val loss:0.303 acc:89.13\n",
            "Epoch:0132 train loss:0.336 acc:88.08 | val loss:0.304 acc:88.97\n",
            "Epoch:0133 train loss:0.326 acc:88.41 | val loss:0.306 acc:88.89\n",
            "Epoch:0134 train loss:0.336 acc:88.17 | val loss:0.302 acc:89.03\n",
            "Epoch:0135 train loss:0.330 acc:87.66 | val loss:0.303 acc:89.02\n",
            "Epoch:0136 train loss:0.329 acc:88.30 | val loss:0.303 acc:88.97\n",
            "Epoch:0137 train loss:0.330 acc:88.14 | val loss:0.305 acc:88.78\n",
            "Epoch:0138 train loss:0.332 acc:87.87 | val loss:0.300 acc:89.05\n",
            "Epoch:0139 train loss:0.333 acc:88.07 | val loss:0.302 acc:88.89\n",
            "Epoch:0140 train loss:0.330 acc:88.08 | val loss:0.301 acc:89.10\n",
            "Epoch:0141 train loss:0.330 acc:88.07 | val loss:0.303 acc:88.78\n",
            "Epoch:0142 train loss:0.334 acc:88.14 | val loss:0.299 acc:89.11\n",
            "Epoch:0143 train loss:0.329 acc:88.42 | val loss:0.299 acc:88.92\n",
            "Epoch:0144 train loss:0.330 acc:88.02 | val loss:0.298 acc:89.13\n",
            "Epoch:0145 train loss:0.323 acc:88.28 | val loss:0.299 acc:89.06\n",
            "Epoch:0146 train loss:0.325 acc:88.04 | val loss:0.299 acc:89.10\n",
            "Epoch:0147 train loss:0.324 acc:88.26 | val loss:0.299 acc:89.16\n",
            "Epoch:0148 train loss:0.324 acc:88.58 | val loss:0.298 acc:89.02\n",
            "Epoch:0149 train loss:0.327 acc:87.97 | val loss:0.298 acc:89.02\n",
            "Epoch:0150 train loss:0.327 acc:88.23 | val loss:0.299 acc:89.08\n",
            "Epoch:0151 train loss:0.328 acc:88.13 | val loss:0.297 acc:89.14\n",
            "Epoch:0152 train loss:0.323 acc:88.44 | val loss:0.298 acc:89.00\n",
            "Epoch:0153 train loss:0.320 acc:88.67 | val loss:0.297 acc:89.10\n",
            "Epoch:0154 train loss:0.326 acc:88.41 | val loss:0.299 acc:89.05\n",
            "Epoch:0155 train loss:0.321 acc:88.51 | val loss:0.296 acc:89.08\n",
            "Epoch:0156 train loss:0.320 acc:88.06 | val loss:0.297 acc:89.05\n",
            "Epoch:0157 train loss:0.325 acc:88.30 | val loss:0.295 acc:88.99\n",
            "Epoch:0158 train loss:0.317 acc:88.42 | val loss:0.296 acc:89.14\n",
            "Epoch:0159 train loss:0.323 acc:88.47 | val loss:0.296 acc:89.00\n",
            "Epoch:0160 train loss:0.325 acc:88.37 | val loss:0.295 acc:89.19\n",
            "Epoch:0161 train loss:0.318 acc:88.63 | val loss:0.294 acc:89.11\n",
            "Epoch:0162 train loss:0.319 acc:88.62 | val loss:0.296 acc:89.13\n",
            "Epoch:0163 train loss:0.316 acc:88.38 | val loss:0.295 acc:89.14\n",
            "Epoch:0164 train loss:0.320 acc:88.13 | val loss:0.294 acc:89.14\n",
            "Epoch:0165 train loss:0.314 acc:88.65 | val loss:0.294 acc:89.22\n",
            "Epoch:0166 train loss:0.326 acc:88.26 | val loss:0.293 acc:89.16\n",
            "Epoch:0167 train loss:0.313 acc:88.65 | val loss:0.293 acc:89.05\n",
            "Epoch:0168 train loss:0.326 acc:88.30 | val loss:0.292 acc:89.13\n",
            "Epoch:0169 train loss:0.318 acc:88.42 | val loss:0.292 acc:89.22\n",
            "Epoch:0170 train loss:0.318 acc:88.24 | val loss:0.292 acc:89.30\n",
            "Epoch:0171 train loss:0.315 acc:89.01 | val loss:0.291 acc:89.29\n",
            "Epoch:0172 train loss:0.319 acc:88.62 | val loss:0.291 acc:89.32\n",
            "Epoch:0173 train loss:0.315 acc:88.38 | val loss:0.291 acc:89.21\n",
            "Epoch:0174 train loss:0.316 acc:88.47 | val loss:0.291 acc:89.30\n",
            "Epoch:0175 train loss:0.315 acc:88.82 | val loss:0.291 acc:89.30\n",
            "Epoch:0176 train loss:0.312 acc:88.76 | val loss:0.290 acc:89.21\n",
            "Epoch:0177 train loss:0.310 acc:88.91 | val loss:0.295 acc:89.10\n",
            "Epoch:0178 train loss:0.322 acc:88.38 | val loss:0.290 acc:89.27\n",
            "Epoch:0179 train loss:0.320 acc:88.32 | val loss:0.291 acc:89.26\n",
            "Epoch:0180 train loss:0.315 acc:88.60 | val loss:0.290 acc:89.33\n",
            "Epoch:0181 train loss:0.318 acc:88.32 | val loss:0.290 acc:89.32\n",
            "Epoch:0182 train loss:0.318 acc:88.72 | val loss:0.289 acc:89.38\n",
            "Epoch:0183 train loss:0.318 acc:88.60 | val loss:0.289 acc:89.26\n",
            "Epoch:0184 train loss:0.317 acc:88.81 | val loss:0.289 acc:89.33\n",
            "Epoch:0185 train loss:0.319 acc:88.34 | val loss:0.289 acc:89.35\n",
            "Epoch:0186 train loss:0.316 acc:88.75 | val loss:0.288 acc:89.30\n",
            "Epoch:0187 train loss:0.314 acc:88.72 | val loss:0.289 acc:89.38\n",
            "Epoch:0188 train loss:0.320 acc:88.11 | val loss:0.288 acc:89.33\n",
            "Epoch:0189 train loss:0.314 acc:88.51 | val loss:0.289 acc:89.35\n",
            "Epoch:0190 train loss:0.322 acc:88.45 | val loss:0.289 acc:89.32\n",
            "Epoch:0191 train loss:0.310 acc:88.80 | val loss:0.289 acc:89.27\n",
            "Epoch:0192 train loss:0.315 acc:88.58 | val loss:0.288 acc:89.38\n",
            "Epoch:0193 train loss:0.315 acc:88.45 | val loss:0.288 acc:89.40\n",
            "Epoch:0194 train loss:0.307 acc:88.83 | val loss:0.288 acc:89.26\n",
            "Epoch:0195 train loss:0.315 acc:88.48 | val loss:0.288 acc:89.40\n",
            "Epoch:0196 train loss:0.312 acc:88.77 | val loss:0.288 acc:89.38\n",
            "Epoch:0197 train loss:0.311 acc:88.90 | val loss:0.287 acc:89.38\n",
            "Epoch:0198 train loss:0.311 acc:88.77 | val loss:0.287 acc:89.48\n",
            "Epoch:0199 train loss:0.313 acc:88.67 | val loss:0.289 acc:89.27\n",
            "Epoch:0200 train loss:0.308 acc:88.79 | val loss:0.286 acc:89.48\n",
            "Epoch:0201 train loss:0.304 acc:88.67 | val loss:0.287 acc:89.57\n",
            "Epoch:0202 train loss:0.303 acc:89.23 | val loss:0.290 acc:89.21\n",
            "Epoch:0203 train loss:0.312 acc:88.54 | val loss:0.286 acc:89.46\n",
            "Epoch:0204 train loss:0.309 acc:88.86 | val loss:0.286 acc:89.62\n",
            "Epoch:0205 train loss:0.308 acc:88.97 | val loss:0.287 acc:89.41\n",
            "Epoch:0206 train loss:0.311 acc:88.97 | val loss:0.287 acc:89.30\n",
            "Epoch:0207 train loss:0.312 acc:88.75 | val loss:0.286 acc:89.62\n",
            "Epoch:0208 train loss:0.304 acc:89.09 | val loss:0.286 acc:89.59\n",
            "Epoch:0209 train loss:0.298 acc:89.27 | val loss:0.285 acc:89.49\n",
            "Epoch:0210 train loss:0.307 acc:88.38 | val loss:0.286 acc:89.52\n",
            "Epoch:0211 train loss:0.303 acc:89.43 | val loss:0.288 acc:89.29\n",
            "Epoch:0212 train loss:0.310 acc:88.51 | val loss:0.285 acc:89.59\n",
            "Epoch:0213 train loss:0.305 acc:88.86 | val loss:0.285 acc:89.46\n",
            "Epoch:0214 train loss:0.303 acc:89.05 | val loss:0.285 acc:89.51\n",
            "Epoch:0215 train loss:0.304 acc:88.69 | val loss:0.285 acc:89.51\n",
            "Epoch:0216 train loss:0.300 acc:88.97 | val loss:0.285 acc:89.45\n",
            "Epoch:0217 train loss:0.300 acc:88.91 | val loss:0.287 acc:89.52\n",
            "Epoch:0218 train loss:0.303 acc:88.91 | val loss:0.288 acc:89.27\n",
            "Epoch:0219 train loss:0.304 acc:88.86 | val loss:0.286 acc:89.29\n",
            "Epoch:0220 train loss:0.302 acc:89.02 | val loss:0.293 acc:89.48\n",
            "Epoch:0221 train loss:0.312 acc:88.42 | val loss:0.315 acc:87.94\n",
            "Epoch:0222 train loss:0.334 acc:87.68 | val loss:0.287 acc:89.30\n",
            "Epoch:0223 train loss:0.308 acc:88.77 | val loss:0.305 acc:89.06\n",
            "Epoch:0224 train loss:0.337 acc:87.42 | val loss:0.285 acc:89.43\n",
            "Epoch:0225 train loss:0.311 acc:88.87 | val loss:0.299 acc:88.56\n",
            "Epoch:0226 train loss:0.328 acc:88.06 | val loss:0.284 acc:89.62\n",
            "Epoch:0227 train loss:0.309 acc:88.53 | val loss:0.296 acc:89.29\n",
            "Epoch:0228 train loss:0.318 acc:88.33 | val loss:0.284 acc:89.67\n",
            "Epoch:0229 train loss:0.311 acc:88.60 | val loss:0.295 acc:88.78\n",
            "Epoch:0230 train loss:0.323 acc:87.95 | val loss:0.291 acc:89.21\n",
            "Epoch:0231 train loss:0.316 acc:88.45 | val loss:0.289 acc:89.57\n",
            "Epoch:0232 train loss:0.311 acc:88.41 | val loss:0.291 acc:89.54\n",
            "Epoch:0233 train loss:0.306 acc:88.85 | val loss:0.289 acc:89.32\n",
            "Epoch:0234 train loss:0.307 acc:88.78 | val loss:0.293 acc:88.92\n",
            "Epoch:0235 train loss:0.309 acc:88.61 | val loss:0.284 acc:89.51\n",
            "Epoch:0236 train loss:0.308 acc:88.99 | val loss:0.289 acc:89.45\n",
            "Epoch:0237 train loss:0.312 acc:88.90 | val loss:0.284 acc:89.56\n",
            "Epoch:0238 train loss:0.303 acc:88.95 | val loss:0.291 acc:88.95\n",
            "Epoch:0239 train loss:0.306 acc:88.74 | val loss:0.285 acc:89.51\n",
            "Epoch:0240 train loss:0.307 acc:88.54 | val loss:0.284 acc:89.65\n",
            "Epoch:0241 train loss:0.300 acc:88.95 | val loss:0.285 acc:89.71\n",
            "Epoch:0242 train loss:0.307 acc:88.98 | val loss:0.286 acc:89.29\n",
            "Epoch:0243 train loss:0.304 acc:88.93 | val loss:0.291 acc:89.06\n",
            "Epoch:0244 train loss:0.310 acc:88.58 | val loss:0.282 acc:89.51\n",
            "Epoch:0245 train loss:0.300 acc:89.10 | val loss:0.285 acc:89.64\n",
            "Epoch:0246 train loss:0.306 acc:88.64 | val loss:0.282 acc:89.57\n",
            "Epoch:0247 train loss:0.296 acc:89.06 | val loss:0.284 acc:89.52\n",
            "Epoch:0248 train loss:0.292 acc:89.57 | val loss:0.285 acc:89.49\n",
            "Epoch:0249 train loss:0.305 acc:88.84 | val loss:0.282 acc:89.54\n",
            "Epoch:0250 train loss:0.307 acc:88.67 | val loss:0.282 acc:89.73\n",
            "Epoch:0251 train loss:0.301 acc:88.94 | val loss:0.282 acc:89.59\n",
            "Epoch:0252 train loss:0.303 acc:88.89 | val loss:0.282 acc:89.54\n",
            "Epoch:0253 train loss:0.307 acc:88.68 | val loss:0.281 acc:89.65\n",
            "Epoch:0254 train loss:0.298 acc:89.06 | val loss:0.281 acc:89.73\n",
            "Epoch:0255 train loss:0.299 acc:88.98 | val loss:0.280 acc:89.67\n",
            "Epoch:0256 train loss:0.301 acc:88.75 | val loss:0.281 acc:89.57\n",
            "Epoch:0257 train loss:0.292 acc:89.62 | val loss:0.281 acc:89.60\n",
            "Epoch:0258 train loss:0.303 acc:88.72 | val loss:0.280 acc:89.75\n",
            "Epoch:0259 train loss:0.298 acc:89.00 | val loss:0.280 acc:89.67\n",
            "Epoch:0260 train loss:0.298 acc:88.96 | val loss:0.280 acc:89.60\n",
            "Epoch:0261 train loss:0.293 acc:89.00 | val loss:0.280 acc:89.57\n",
            "Epoch:0262 train loss:0.293 acc:89.41 | val loss:0.279 acc:89.64\n",
            "Epoch:0263 train loss:0.298 acc:88.95 | val loss:0.279 acc:89.67\n",
            "Epoch:0264 train loss:0.301 acc:89.10 | val loss:0.278 acc:89.70\n",
            "Epoch:0265 train loss:0.296 acc:89.24 | val loss:0.279 acc:89.73\n",
            "Epoch:0266 train loss:0.296 acc:88.97 | val loss:0.279 acc:89.68\n",
            "Epoch:0267 train loss:0.293 acc:89.12 | val loss:0.278 acc:89.78\n",
            "Epoch:0268 train loss:0.302 acc:88.61 | val loss:0.278 acc:89.70\n",
            "Epoch:0269 train loss:0.294 acc:89.09 | val loss:0.282 acc:89.49\n",
            "Epoch:0270 train loss:0.298 acc:89.06 | val loss:0.281 acc:89.59\n",
            "Epoch:0271 train loss:0.298 acc:89.05 | val loss:0.282 acc:89.78\n",
            "Epoch:0272 train loss:0.298 acc:88.80 | val loss:0.280 acc:89.86\n",
            "Epoch:0273 train loss:0.294 acc:89.21 | val loss:0.279 acc:89.70\n",
            "Epoch:0274 train loss:0.304 acc:88.54 | val loss:0.278 acc:89.57\n",
            "Epoch:0275 train loss:0.296 acc:89.16 | val loss:0.278 acc:89.81\n",
            "Epoch:0276 train loss:0.294 acc:89.19 | val loss:0.279 acc:89.62\n",
            "Epoch:0277 train loss:0.288 acc:89.05 | val loss:0.283 acc:89.48\n",
            "Epoch:0278 train loss:0.299 acc:89.10 | val loss:0.278 acc:89.71\n",
            "Epoch:0279 train loss:0.298 acc:89.03 | val loss:0.278 acc:89.79\n",
            "Epoch:0280 train loss:0.296 acc:89.19 | val loss:0.278 acc:89.71\n",
            "Epoch:0281 train loss:0.288 acc:88.96 | val loss:0.279 acc:89.67\n",
            "Epoch:0282 train loss:0.288 acc:89.30 | val loss:0.278 acc:89.73\n",
            "Epoch:0283 train loss:0.297 acc:89.36 | val loss:0.277 acc:89.87\n",
            "Epoch:0284 train loss:0.290 acc:89.21 | val loss:0.277 acc:89.65\n",
            "Epoch:0285 train loss:0.292 acc:89.42 | val loss:0.277 acc:89.76\n",
            "Epoch:0286 train loss:0.293 acc:89.26 | val loss:0.277 acc:89.89\n",
            "Epoch:0287 train loss:0.293 acc:89.22 | val loss:0.279 acc:89.76\n",
            "Epoch:0288 train loss:0.297 acc:89.03 | val loss:0.282 acc:89.59\n",
            "Epoch:0289 train loss:0.292 acc:89.15 | val loss:0.277 acc:89.67\n",
            "Epoch:0290 train loss:0.290 acc:89.09 | val loss:0.279 acc:89.60\n",
            "Epoch:0291 train loss:0.295 acc:88.77 | val loss:0.277 acc:89.78\n",
            "Epoch:0292 train loss:0.282 acc:89.67 | val loss:0.281 acc:89.64\n",
            "Epoch:0293 train loss:0.289 acc:89.25 | val loss:0.278 acc:89.83\n",
            "Epoch:0294 train loss:0.284 acc:89.44 | val loss:0.277 acc:89.97\n",
            "Epoch:0295 train loss:0.291 acc:89.08 | val loss:0.280 acc:89.41\n",
            "Epoch:0296 train loss:0.290 acc:89.31 | val loss:0.279 acc:89.59\n",
            "Epoch:0297 train loss:0.293 acc:88.93 | val loss:0.278 acc:89.95\n",
            "Epoch:0298 train loss:0.292 acc:89.25 | val loss:0.275 acc:89.89\n",
            "Epoch:0299 train loss:0.295 acc:89.40 | val loss:0.281 acc:89.46\n",
            "Epoch:0300 train loss:0.290 acc:89.53 | val loss:0.278 acc:89.46\n",
            "Epoch:0301 train loss:0.286 acc:89.50 | val loss:0.275 acc:90.11\n",
            "Epoch:0302 train loss:0.286 acc:89.58 | val loss:0.275 acc:89.95\n",
            "Epoch:0303 train loss:0.286 acc:89.57 | val loss:0.277 acc:89.89\n",
            "Epoch:0304 train loss:0.280 acc:89.60 | val loss:0.281 acc:89.60\n",
            "Epoch:0305 train loss:0.288 acc:89.53 | val loss:0.276 acc:89.90\n",
            "Epoch:0306 train loss:0.289 acc:89.23 | val loss:0.276 acc:90.02\n",
            "Epoch:0307 train loss:0.288 acc:89.15 | val loss:0.280 acc:89.62\n",
            "Epoch:0308 train loss:0.296 acc:88.84 | val loss:0.277 acc:89.73\n",
            "Epoch:0309 train loss:0.291 acc:89.37 | val loss:0.275 acc:90.08\n",
            "Epoch:0310 train loss:0.294 acc:89.15 | val loss:0.275 acc:89.98\n",
            "Epoch:0311 train loss:0.287 acc:89.30 | val loss:0.279 acc:89.68\n",
            "Epoch:0312 train loss:0.284 acc:89.21 | val loss:0.278 acc:89.81\n",
            "Epoch:0313 train loss:0.300 acc:89.02 | val loss:0.278 acc:89.86\n",
            "Epoch:0314 train loss:0.287 acc:89.51 | val loss:0.277 acc:89.79\n",
            "Epoch:0315 train loss:0.286 acc:89.28 | val loss:0.280 acc:89.73\n",
            "Epoch:0316 train loss:0.289 acc:89.35 | val loss:0.279 acc:89.68\n",
            "Epoch:0317 train loss:0.290 acc:89.36 | val loss:0.276 acc:89.87\n",
            "Epoch:0318 train loss:0.287 acc:89.10 | val loss:0.275 acc:89.83\n",
            "Epoch:0319 train loss:0.286 acc:89.41 | val loss:0.276 acc:89.70\n",
            "Epoch:0320 train loss:0.291 acc:88.98 | val loss:0.275 acc:89.89\n",
            "Epoch:0321 train loss:0.286 acc:89.08 | val loss:0.275 acc:89.94\n",
            "Epoch:0322 train loss:0.289 acc:89.04 | val loss:0.274 acc:90.08\n",
            "Epoch:0323 train loss:0.278 acc:89.51 | val loss:0.277 acc:89.81\n",
            "Epoch:0324 train loss:0.281 acc:89.76 | val loss:0.275 acc:89.98\n",
            "Epoch:0325 train loss:0.290 acc:89.57 | val loss:0.275 acc:90.00\n",
            "Epoch:0326 train loss:0.279 acc:89.74 | val loss:0.275 acc:90.10\n",
            "Epoch:0327 train loss:0.289 acc:89.06 | val loss:0.276 acc:90.06\n",
            "Epoch:0328 train loss:0.279 acc:89.38 | val loss:0.273 acc:90.06\n",
            "Epoch:0329 train loss:0.281 acc:89.49 | val loss:0.274 acc:90.11\n",
            "Epoch:0330 train loss:0.286 acc:89.25 | val loss:0.274 acc:90.14\n",
            "Epoch:0331 train loss:0.288 acc:89.43 | val loss:0.280 acc:89.75\n",
            "Epoch:0332 train loss:0.284 acc:89.50 | val loss:0.274 acc:90.02\n",
            "Epoch:0333 train loss:0.287 acc:89.65 | val loss:0.277 acc:90.10\n",
            "Epoch:0334 train loss:0.284 acc:89.46 | val loss:0.274 acc:90.00\n",
            "Epoch:0335 train loss:0.282 acc:89.74 | val loss:0.280 acc:89.52\n",
            "Epoch:0336 train loss:0.284 acc:89.38 | val loss:0.273 acc:90.00\n",
            "Epoch:0337 train loss:0.283 acc:89.56 | val loss:0.274 acc:90.06\n",
            "Epoch:0338 train loss:0.285 acc:89.55 | val loss:0.274 acc:90.11\n",
            "Epoch:0339 train loss:0.284 acc:89.24 | val loss:0.283 acc:89.19\n",
            "Epoch:0340 train loss:0.285 acc:89.58 | val loss:0.276 acc:89.71\n",
            "Epoch:0341 train loss:0.287 acc:89.50 | val loss:0.278 acc:90.10\n",
            "Epoch:0342 train loss:0.284 acc:89.18 | val loss:0.274 acc:90.02\n",
            "Epoch:0343 train loss:0.281 acc:89.60 | val loss:0.278 acc:89.73\n",
            "Epoch:0344 train loss:0.285 acc:89.52 | val loss:0.272 acc:90.05\n",
            "Epoch:0345 train loss:0.283 acc:89.46 | val loss:0.273 acc:90.06\n",
            "Epoch:0346 train loss:0.281 acc:89.62 | val loss:0.274 acc:89.95\n",
            "Epoch:0347 train loss:0.278 acc:89.67 | val loss:0.278 acc:89.83\n",
            "Epoch:0348 train loss:0.287 acc:89.55 | val loss:0.277 acc:89.86\n",
            "Epoch:0349 train loss:0.273 acc:89.80 | val loss:0.275 acc:89.78\n",
            "Epoch:0350 train loss:0.279 acc:89.83 | val loss:0.274 acc:89.89\n",
            "Epoch:0351 train loss:0.279 acc:89.32 | val loss:0.274 acc:90.00\n",
            "Epoch:0352 train loss:0.272 acc:89.71 | val loss:0.275 acc:89.86\n",
            "Epoch:0353 train loss:0.278 acc:89.55 | val loss:0.272 acc:90.13\n",
            "Epoch:0354 train loss:0.282 acc:89.37 | val loss:0.272 acc:89.95\n",
            "Epoch:0355 train loss:0.278 acc:89.76 | val loss:0.274 acc:89.79\n",
            "Epoch:0356 train loss:0.283 acc:89.34 | val loss:0.275 acc:89.90\n",
            "Epoch:0357 train loss:0.284 acc:89.51 | val loss:0.273 acc:90.00\n",
            "Epoch:0358 train loss:0.273 acc:89.91 | val loss:0.272 acc:90.14\n",
            "Epoch:0359 train loss:0.273 acc:89.73 | val loss:0.272 acc:90.05\n",
            "Epoch:0360 train loss:0.272 acc:89.77 | val loss:0.272 acc:90.00\n",
            "Epoch:0361 train loss:0.272 acc:90.13 | val loss:0.271 acc:90.08\n",
            "Epoch:0362 train loss:0.277 acc:89.53 | val loss:0.272 acc:90.25\n",
            "Epoch:0363 train loss:0.273 acc:89.96 | val loss:0.275 acc:90.08\n",
            "Epoch:0364 train loss:0.276 acc:89.70 | val loss:0.274 acc:90.08\n",
            "Epoch:0365 train loss:0.275 acc:89.40 | val loss:0.271 acc:90.22\n",
            "Epoch:0366 train loss:0.274 acc:89.68 | val loss:0.271 acc:89.79\n",
            "Epoch:0367 train loss:0.277 acc:89.67 | val loss:0.270 acc:90.00\n",
            "Epoch:0368 train loss:0.277 acc:89.67 | val loss:0.270 acc:90.13\n",
            "Epoch:0369 train loss:0.272 acc:90.12 | val loss:0.272 acc:90.08\n",
            "Epoch:0370 train loss:0.280 acc:89.97 | val loss:0.275 acc:89.87\n",
            "Epoch:0371 train loss:0.266 acc:90.27 | val loss:0.274 acc:90.00\n",
            "Epoch:0372 train loss:0.276 acc:89.86 | val loss:0.273 acc:90.11\n",
            "Epoch:0373 train loss:0.273 acc:89.61 | val loss:0.273 acc:89.83\n",
            "Epoch:0374 train loss:0.268 acc:90.16 | val loss:0.275 acc:89.97\n",
            "Epoch:0375 train loss:0.279 acc:89.51 | val loss:0.270 acc:90.27\n",
            "Epoch:0376 train loss:0.270 acc:90.02 | val loss:0.269 acc:90.27\n",
            "Epoch:0377 train loss:0.275 acc:89.76 | val loss:0.272 acc:89.97\n",
            "Epoch:0378 train loss:0.272 acc:89.71 | val loss:0.272 acc:89.94\n",
            "Epoch:0379 train loss:0.268 acc:90.15 | val loss:0.272 acc:90.21\n",
            "Epoch:0380 train loss:0.266 acc:90.18 | val loss:0.273 acc:90.10\n",
            "Epoch:0381 train loss:0.271 acc:89.68 | val loss:0.274 acc:90.00\n",
            "Epoch:0382 train loss:0.274 acc:89.79 | val loss:0.271 acc:90.22\n",
            "Epoch:0383 train loss:0.271 acc:89.67 | val loss:0.270 acc:90.25\n",
            "Epoch:0384 train loss:0.277 acc:89.99 | val loss:0.276 acc:89.81\n",
            "Epoch:0385 train loss:0.283 acc:89.36 | val loss:0.270 acc:90.22\n",
            "Epoch:0386 train loss:0.271 acc:90.01 | val loss:0.272 acc:90.25\n",
            "Epoch:0387 train loss:0.277 acc:89.49 | val loss:0.270 acc:90.17\n",
            "Epoch:0388 train loss:0.267 acc:89.78 | val loss:0.278 acc:89.78\n",
            "Epoch:0389 train loss:0.269 acc:89.98 | val loss:0.271 acc:90.19\n",
            "Epoch:0390 train loss:0.266 acc:89.95 | val loss:0.272 acc:90.32\n",
            "Epoch:0391 train loss:0.270 acc:89.94 | val loss:0.272 acc:90.22\n",
            "Epoch:0392 train loss:0.268 acc:90.09 | val loss:0.274 acc:89.94\n",
            "Epoch:0393 train loss:0.268 acc:89.92 | val loss:0.270 acc:90.25\n",
            "Epoch:0394 train loss:0.270 acc:90.06 | val loss:0.270 acc:90.19\n",
            "Epoch:0395 train loss:0.267 acc:89.74 | val loss:0.272 acc:90.21\n",
            "Epoch:0396 train loss:0.264 acc:90.13 | val loss:0.273 acc:90.02\n",
            "Epoch:0397 train loss:0.270 acc:90.02 | val loss:0.270 acc:90.11\n",
            "Epoch:0398 train loss:0.261 acc:90.21 | val loss:0.271 acc:90.13\n",
            "Epoch:0399 train loss:0.272 acc:89.84 | val loss:0.273 acc:90.03\n",
            "Epoch:0400 train loss:0.270 acc:89.89 | val loss:0.270 acc:90.13\n",
            "Epoch:0401 train loss:0.270 acc:89.98 | val loss:0.269 acc:90.24\n",
            "Epoch:0402 train loss:0.267 acc:89.74 | val loss:0.269 acc:90.29\n",
            "Epoch:0403 train loss:0.263 acc:90.31 | val loss:0.270 acc:90.14\n",
            "Epoch:0404 train loss:0.274 acc:89.70 | val loss:0.270 acc:90.22\n",
            "Epoch:0405 train loss:0.270 acc:89.77 | val loss:0.270 acc:90.24\n",
            "Epoch:0406 train loss:0.260 acc:90.30 | val loss:0.271 acc:90.21\n",
            "Epoch:0407 train loss:0.267 acc:90.10 | val loss:0.273 acc:90.10\n",
            "Epoch:0408 train loss:0.268 acc:90.05 | val loss:0.270 acc:90.19\n",
            "Epoch:0409 train loss:0.265 acc:90.21 | val loss:0.271 acc:89.90\n",
            "Epoch:0410 train loss:0.271 acc:90.08 | val loss:0.271 acc:89.95\n",
            "Epoch:0411 train loss:0.274 acc:89.78 | val loss:0.271 acc:90.16\n",
            "Epoch:0412 train loss:0.263 acc:89.82 | val loss:0.272 acc:90.22\n",
            "Epoch:0413 train loss:0.268 acc:90.11 | val loss:0.272 acc:90.05\n",
            "Epoch:0414 train loss:0.268 acc:90.39 | val loss:0.271 acc:90.14\n",
            "Epoch:0415 train loss:0.268 acc:90.18 | val loss:0.269 acc:90.36\n",
            "Epoch:0416 train loss:0.264 acc:89.99 | val loss:0.271 acc:90.13\n",
            "Epoch:0417 train loss:0.261 acc:90.57 | val loss:0.271 acc:90.08\n",
            "Epoch:0418 train loss:0.268 acc:90.19 | val loss:0.270 acc:90.27\n",
            "Epoch:0419 train loss:0.261 acc:90.35 | val loss:0.270 acc:90.19\n",
            "Epoch:0420 train loss:0.263 acc:90.13 | val loss:0.272 acc:90.05\n",
            "Epoch:0421 train loss:0.262 acc:90.35 | val loss:0.273 acc:90.13\n",
            "Epoch:0422 train loss:0.263 acc:90.15 | val loss:0.272 acc:90.05\n",
            "Epoch:0423 train loss:0.263 acc:90.26 | val loss:0.270 acc:90.21\n",
            "Epoch:0424 train loss:0.259 acc:90.56 | val loss:0.269 acc:90.30\n",
            "Epoch:0425 train loss:0.264 acc:90.14 | val loss:0.274 acc:89.94\n",
            "Epoch:0426 train loss:0.268 acc:90.08 | val loss:0.269 acc:90.27\n",
            "Epoch:0427 train loss:0.261 acc:90.31 | val loss:0.269 acc:90.16\n",
            "Epoch:0428 train loss:0.261 acc:90.21 | val loss:0.269 acc:90.24\n",
            "Epoch:0429 train loss:0.258 acc:90.05 | val loss:0.270 acc:90.22\n",
            "Epoch:0430 train loss:0.260 acc:90.53 | val loss:0.273 acc:90.08\n",
            "Epoch:0431 train loss:0.257 acc:90.13 | val loss:0.272 acc:90.17\n",
            "Epoch:0432 train loss:0.265 acc:89.94 | val loss:0.271 acc:90.11\n",
            "Epoch:0433 train loss:0.257 acc:90.50 | val loss:0.270 acc:90.17\n",
            "Epoch:0434 train loss:0.255 acc:90.54 | val loss:0.274 acc:90.10\n",
            "Epoch:0435 train loss:0.256 acc:90.26 | val loss:0.270 acc:90.10\n",
            "Epoch:0436 train loss:0.254 acc:90.45 | val loss:0.268 acc:90.25\n",
            "Epoch:0437 train loss:0.255 acc:90.63 | val loss:0.270 acc:90.14\n",
            "Epoch:0438 train loss:0.269 acc:90.19 | val loss:0.269 acc:90.14\n",
            "Epoch:0439 train loss:0.263 acc:90.23 | val loss:0.269 acc:90.06\n",
            "Epoch:0440 train loss:0.261 acc:90.19 | val loss:0.269 acc:90.16\n",
            "Epoch:0441 train loss:0.257 acc:90.26 | val loss:0.269 acc:90.25\n",
            "Epoch:0442 train loss:0.259 acc:90.52 | val loss:0.270 acc:90.16\n",
            "Epoch:0443 train loss:0.262 acc:90.31 | val loss:0.272 acc:90.13\n",
            "Epoch:0444 train loss:0.265 acc:90.02 | val loss:0.271 acc:90.29\n",
            "Epoch:0445 train loss:0.270 acc:90.10 | val loss:0.270 acc:90.21\n",
            "Epoch:0446 train loss:0.254 acc:90.80 | val loss:0.274 acc:89.98\n",
            "Epoch:0447 train loss:0.264 acc:89.93 | val loss:0.272 acc:90.32\n",
            "Epoch:0448 train loss:0.262 acc:90.29 | val loss:0.269 acc:90.16\n",
            "Epoch:0449 train loss:0.260 acc:90.28 | val loss:0.271 acc:90.05\n",
            "Epoch:0450 train loss:0.265 acc:90.31 | val loss:0.268 acc:90.25\n",
            "Epoch:0451 train loss:0.260 acc:90.19 | val loss:0.269 acc:90.17\n",
            "Epoch:0452 train loss:0.258 acc:90.19 | val loss:0.271 acc:90.24\n",
            "Epoch:0453 train loss:0.256 acc:90.54 | val loss:0.269 acc:90.36\n",
            "Epoch:0454 train loss:0.262 acc:90.03 | val loss:0.270 acc:90.19\n",
            "Epoch:0455 train loss:0.256 acc:90.52 | val loss:0.272 acc:90.11\n",
            "Epoch:0456 train loss:0.253 acc:90.43 | val loss:0.269 acc:90.19\n",
            "Epoch:0457 train loss:0.259 acc:90.45 | val loss:0.270 acc:90.24\n",
            "Epoch:0458 train loss:0.255 acc:90.38 | val loss:0.267 acc:90.35\n",
            "Epoch:0459 train loss:0.257 acc:90.24 | val loss:0.267 acc:90.44\n",
            "Epoch:0460 train loss:0.256 acc:90.39 | val loss:0.269 acc:90.24\n",
            "Epoch:0461 train loss:0.253 acc:90.36 | val loss:0.271 acc:90.06\n",
            "Epoch:0462 train loss:0.258 acc:90.34 | val loss:0.269 acc:90.19\n",
            "Epoch:0463 train loss:0.260 acc:90.17 | val loss:0.268 acc:90.24\n",
            "Epoch:0464 train loss:0.261 acc:90.19 | val loss:0.268 acc:90.21\n",
            "Epoch:0465 train loss:0.255 acc:90.35 | val loss:0.267 acc:90.27\n",
            "Epoch:0466 train loss:0.256 acc:90.53 | val loss:0.269 acc:90.33\n",
            "Epoch:0467 train loss:0.251 acc:90.43 | val loss:0.272 acc:90.24\n",
            "Epoch:0468 train loss:0.258 acc:90.65 | val loss:0.268 acc:90.06\n",
            "Epoch:0469 train loss:0.255 acc:90.61 | val loss:0.268 acc:90.19\n",
            "Epoch:0470 train loss:0.248 acc:90.63 | val loss:0.273 acc:90.13\n",
            "Epoch:0471 train loss:0.256 acc:90.34 | val loss:0.270 acc:90.33\n",
            "Epoch:0472 train loss:0.262 acc:90.21 | val loss:0.268 acc:90.24\n",
            "Epoch:0473 train loss:0.257 acc:90.45 | val loss:0.274 acc:90.13\n",
            "Epoch:0474 train loss:0.259 acc:90.47 | val loss:0.267 acc:90.22\n",
            "Epoch:0475 train loss:0.257 acc:90.14 | val loss:0.269 acc:90.30\n",
            "Epoch:0476 train loss:0.258 acc:90.14 | val loss:0.280 acc:89.86\n",
            "Epoch:0477 train loss:0.258 acc:90.23 | val loss:0.267 acc:90.27\n",
            "Epoch:0478 train loss:0.254 acc:90.62 | val loss:0.270 acc:90.40\n",
            "Epoch:0479 train loss:0.261 acc:90.19 | val loss:0.281 acc:89.92\n",
            "Epoch:0480 train loss:0.270 acc:89.97 | val loss:0.267 acc:90.32\n",
            "Epoch:0481 train loss:0.252 acc:90.29 | val loss:0.270 acc:90.32\n",
            "Epoch:0482 train loss:0.266 acc:89.88 | val loss:0.275 acc:90.03\n",
            "Epoch:0483 train loss:0.259 acc:90.26 | val loss:0.270 acc:90.22\n",
            "Epoch:0484 train loss:0.257 acc:90.45 | val loss:0.271 acc:90.38\n",
            "Epoch:0485 train loss:0.258 acc:90.54 | val loss:0.271 acc:90.08\n",
            "Epoch:0486 train loss:0.260 acc:90.38 | val loss:0.280 acc:89.76\n",
            "Epoch:0487 train loss:0.263 acc:90.20 | val loss:0.268 acc:90.10\n",
            "Epoch:0488 train loss:0.255 acc:90.47 | val loss:0.275 acc:90.41\n",
            "Epoch:0489 train loss:0.275 acc:89.81 | val loss:0.276 acc:89.92\n",
            "Epoch:0490 train loss:0.267 acc:89.97 | val loss:0.271 acc:90.17\n",
            "Epoch:0491 train loss:0.254 acc:90.69 | val loss:0.270 acc:90.27\n",
            "Epoch:0492 train loss:0.255 acc:90.49 | val loss:0.266 acc:90.24\n",
            "Epoch:0493 train loss:0.255 acc:90.42 | val loss:0.274 acc:89.98\n",
            "Epoch:0494 train loss:0.262 acc:90.46 | val loss:0.269 acc:90.30\n",
            "Epoch:0495 train loss:0.256 acc:90.69 | val loss:0.276 acc:90.11\n",
            "Epoch:0496 train loss:0.261 acc:90.07 | val loss:0.271 acc:90.00\n",
            "Epoch:0497 train loss:0.250 acc:90.98 | val loss:0.282 acc:89.46\n",
            "Epoch:0498 train loss:0.271 acc:89.79 | val loss:0.266 acc:90.14\n",
            "Epoch:0499 train loss:0.245 acc:91.03 | val loss:0.269 acc:90.33\n",
            "Epoch:0500 train loss:0.255 acc:90.47 | val loss:0.269 acc:90.16\n",
            "Epoch:0501 train loss:0.256 acc:90.24 | val loss:0.278 acc:89.84\n",
            "Epoch:0502 train loss:0.266 acc:90.00 | val loss:0.269 acc:90.16\n",
            "Epoch:0503 train loss:0.248 acc:90.99 | val loss:0.273 acc:90.21\n",
            "Epoch:0504 train loss:0.256 acc:90.42 | val loss:0.270 acc:90.17\n",
            "Epoch:0505 train loss:0.252 acc:90.46 | val loss:0.281 acc:89.67\n",
            "Epoch:0506 train loss:0.261 acc:90.13 | val loss:0.272 acc:90.03\n",
            "Epoch:0507 train loss:0.250 acc:90.73 | val loss:0.273 acc:90.24\n",
            "Epoch:0508 train loss:0.265 acc:90.56 | val loss:0.267 acc:90.27\n",
            "Epoch:0509 train loss:0.246 acc:90.81 | val loss:0.275 acc:89.94\n",
            "Epoch:0510 train loss:0.255 acc:90.34 | val loss:0.269 acc:90.08\n",
            "Epoch:0511 train loss:0.254 acc:90.66 | val loss:0.267 acc:90.32\n",
            "Epoch:0512 train loss:0.250 acc:90.61 | val loss:0.267 acc:90.25\n",
            "Epoch:0513 train loss:0.249 acc:90.88 | val loss:0.270 acc:90.13\n",
            "Epoch:0514 train loss:0.250 acc:90.90 | val loss:0.268 acc:90.17\n",
            "Epoch:0515 train loss:0.251 acc:90.65 | val loss:0.268 acc:90.17\n",
            "Epoch:0516 train loss:0.247 acc:91.08 | val loss:0.269 acc:90.21\n",
            "Epoch:0517 train loss:0.243 acc:90.96 | val loss:0.271 acc:90.16\n",
            "Epoch:0518 train loss:0.246 acc:90.84 | val loss:0.271 acc:90.11\n",
            "Epoch:0519 train loss:0.244 acc:91.04 | val loss:0.269 acc:90.17\n",
            "Epoch:0520 train loss:0.243 acc:90.95 | val loss:0.269 acc:90.22\n",
            "Epoch:0521 train loss:0.250 acc:90.99 | val loss:0.267 acc:90.29\n",
            "Epoch:0522 train loss:0.246 acc:90.95 | val loss:0.267 acc:90.24\n",
            "Epoch:0523 train loss:0.244 acc:90.88 | val loss:0.267 acc:90.22\n",
            "Epoch:0524 train loss:0.252 acc:90.45 | val loss:0.268 acc:90.16\n",
            "Epoch:0525 train loss:0.244 acc:90.99 | val loss:0.267 acc:90.30\n",
            "Epoch:0526 train loss:0.244 acc:90.95 | val loss:0.267 acc:90.22\n",
            "Epoch:0527 train loss:0.242 acc:90.92 | val loss:0.269 acc:90.22\n",
            "Epoch:0528 train loss:0.242 acc:91.11 | val loss:0.269 acc:90.14\n",
            "Epoch:0529 train loss:0.237 acc:91.14 | val loss:0.268 acc:90.16\n",
            "Epoch:0530 train loss:0.236 acc:90.91 | val loss:0.266 acc:90.40\n",
            "Epoch:0531 train loss:0.247 acc:90.47 | val loss:0.266 acc:90.38\n",
            "Epoch:0532 train loss:0.240 acc:91.13 | val loss:0.267 acc:90.13\n",
            "Epoch:0533 train loss:0.244 acc:91.04 | val loss:0.268 acc:90.13\n",
            "Epoch:0534 train loss:0.237 acc:91.18 | val loss:0.266 acc:90.22\n",
            "Epoch:0535 train loss:0.247 acc:90.70 | val loss:0.270 acc:90.16\n",
            "Epoch:0536 train loss:0.242 acc:91.12 | val loss:0.268 acc:90.25\n",
            "Epoch:0537 train loss:0.248 acc:90.56 | val loss:0.266 acc:90.25\n",
            "Epoch:0538 train loss:0.240 acc:91.08 | val loss:0.267 acc:90.30\n",
            "Epoch:0539 train loss:0.242 acc:90.94 | val loss:0.269 acc:90.19\n",
            "Epoch:0540 train loss:0.240 acc:90.84 | val loss:0.267 acc:90.36\n",
            "Epoch:0541 train loss:0.242 acc:91.02 | val loss:0.267 acc:90.43\n",
            "Epoch:0542 train loss:0.244 acc:90.96 | val loss:0.267 acc:90.48\n",
            "3 : 89.88\n",
            "Epoch:0001 train loss:1.103 acc:20.93 | val loss:1.094 acc:45.29\n",
            "Epoch:0002 train loss:1.094 acc:44.05 | val loss:1.084 acc:56.64\n",
            "Epoch:0003 train loss:1.084 acc:44.07 | val loss:1.071 acc:54.41\n",
            "Epoch:0004 train loss:1.071 acc:45.04 | val loss:1.056 acc:44.53\n",
            "Epoch:0005 train loss:1.057 acc:43.80 | val loss:1.044 acc:40.63\n",
            "Epoch:0006 train loss:1.047 acc:43.93 | val loss:1.042 acc:65.12\n",
            "Epoch:0007 train loss:1.048 acc:44.70 | val loss:1.032 acc:50.92\n",
            "Epoch:0008 train loss:1.035 acc:45.07 | val loss:1.019 acc:51.49\n",
            "Epoch:0009 train loss:1.025 acc:47.55 | val loss:1.008 acc:57.00\n",
            "Epoch:0010 train loss:1.012 acc:50.76 | val loss:0.997 acc:61.05\n",
            "Epoch:0011 train loss:1.000 acc:55.41 | val loss:0.983 acc:64.25\n",
            "Epoch:0012 train loss:0.987 acc:56.66 | val loss:0.966 acc:65.75\n",
            "Epoch:0013 train loss:0.973 acc:57.38 | val loss:0.944 acc:65.78\n",
            "Epoch:0014 train loss:0.951 acc:59.56 | val loss:0.918 acc:65.47\n",
            "Epoch:0015 train loss:0.929 acc:60.63 | val loss:0.888 acc:64.80\n",
            "Epoch:0016 train loss:0.902 acc:61.16 | val loss:0.856 acc:64.23\n",
            "Epoch:0017 train loss:0.871 acc:61.68 | val loss:0.822 acc:65.39\n",
            "Epoch:0018 train loss:0.844 acc:62.98 | val loss:0.787 acc:66.48\n",
            "Epoch:0019 train loss:0.815 acc:64.35 | val loss:0.753 acc:67.45\n",
            "Epoch:0020 train loss:0.782 acc:65.21 | val loss:0.720 acc:67.89\n",
            "Epoch:0021 train loss:0.748 acc:66.58 | val loss:0.692 acc:68.21\n",
            "Epoch:0022 train loss:0.717 acc:67.39 | val loss:0.670 acc:68.86\n",
            "Epoch:0023 train loss:0.698 acc:68.18 | val loss:0.649 acc:69.13\n",
            "Epoch:0024 train loss:0.685 acc:68.57 | val loss:0.635 acc:69.67\n",
            "Epoch:0025 train loss:0.670 acc:68.96 | val loss:0.620 acc:70.22\n",
            "Epoch:0026 train loss:0.659 acc:69.12 | val loss:0.611 acc:70.41\n",
            "Epoch:0027 train loss:0.638 acc:69.24 | val loss:0.619 acc:70.35\n",
            "Epoch:0028 train loss:0.651 acc:69.70 | val loss:0.604 acc:71.28\n",
            "Epoch:0029 train loss:0.637 acc:70.13 | val loss:0.594 acc:72.98\n",
            "Epoch:0030 train loss:0.627 acc:71.63 | val loss:0.602 acc:74.82\n",
            "Epoch:0031 train loss:0.630 acc:72.39 | val loss:0.583 acc:76.16\n",
            "Epoch:0032 train loss:0.619 acc:74.35 | val loss:0.577 acc:77.46\n",
            "Epoch:0033 train loss:0.614 acc:75.67 | val loss:0.568 acc:78.81\n",
            "Epoch:0034 train loss:0.603 acc:76.46 | val loss:0.566 acc:79.67\n",
            "Epoch:0035 train loss:0.603 acc:77.44 | val loss:0.554 acc:80.49\n",
            "Epoch:0036 train loss:0.588 acc:77.87 | val loss:0.548 acc:81.17\n",
            "Epoch:0037 train loss:0.580 acc:77.77 | val loss:0.542 acc:81.79\n",
            "Epoch:0038 train loss:0.565 acc:79.36 | val loss:0.539 acc:81.82\n",
            "Epoch:0039 train loss:0.573 acc:80.07 | val loss:0.527 acc:82.60\n",
            "Epoch:0040 train loss:0.566 acc:80.66 | val loss:0.525 acc:82.88\n",
            "Epoch:0041 train loss:0.565 acc:80.93 | val loss:0.513 acc:83.68\n",
            "Epoch:0042 train loss:0.547 acc:82.01 | val loss:0.513 acc:83.52\n",
            "Epoch:0043 train loss:0.555 acc:82.28 | val loss:0.502 acc:84.72\n",
            "Epoch:0044 train loss:0.539 acc:83.09 | val loss:0.494 acc:85.15\n",
            "Epoch:0045 train loss:0.538 acc:83.07 | val loss:0.486 acc:85.29\n",
            "Epoch:0046 train loss:0.528 acc:82.87 | val loss:0.477 acc:85.45\n",
            "Epoch:0047 train loss:0.520 acc:83.09 | val loss:0.472 acc:85.40\n",
            "Epoch:0048 train loss:0.517 acc:83.44 | val loss:0.460 acc:86.02\n",
            "Epoch:0049 train loss:0.509 acc:83.24 | val loss:0.452 acc:85.99\n",
            "Epoch:0050 train loss:0.500 acc:84.19 | val loss:0.445 acc:85.80\n",
            "Epoch:0051 train loss:0.491 acc:84.16 | val loss:0.439 acc:85.93\n",
            "Epoch:0052 train loss:0.486 acc:83.92 | val loss:0.433 acc:85.96\n",
            "Epoch:0053 train loss:0.478 acc:84.20 | val loss:0.424 acc:85.71\n",
            "Epoch:0054 train loss:0.472 acc:84.31 | val loss:0.417 acc:85.75\n",
            "Epoch:0055 train loss:0.473 acc:83.98 | val loss:0.415 acc:85.90\n",
            "Epoch:0056 train loss:0.463 acc:84.38 | val loss:0.408 acc:85.85\n",
            "Epoch:0057 train loss:0.461 acc:84.55 | val loss:0.401 acc:85.80\n",
            "Epoch:0058 train loss:0.454 acc:84.34 | val loss:0.396 acc:85.82\n",
            "Epoch:0059 train loss:0.442 acc:84.89 | val loss:0.393 acc:86.02\n",
            "Epoch:0060 train loss:0.444 acc:84.78 | val loss:0.390 acc:86.04\n",
            "Epoch:0061 train loss:0.442 acc:84.46 | val loss:0.383 acc:86.21\n",
            "Epoch:0062 train loss:0.436 acc:84.99 | val loss:0.383 acc:85.88\n",
            "Epoch:0063 train loss:0.441 acc:84.91 | val loss:0.377 acc:86.28\n",
            "Epoch:0064 train loss:0.437 acc:85.37 | val loss:0.381 acc:85.96\n",
            "Epoch:0065 train loss:0.431 acc:84.65 | val loss:0.376 acc:86.20\n",
            "Epoch:0066 train loss:0.427 acc:84.97 | val loss:0.371 acc:86.35\n",
            "Epoch:0067 train loss:0.418 acc:85.53 | val loss:0.370 acc:86.61\n",
            "Epoch:0068 train loss:0.414 acc:85.62 | val loss:0.367 acc:86.72\n",
            "Epoch:0069 train loss:0.422 acc:85.53 | val loss:0.367 acc:86.58\n",
            "Epoch:0070 train loss:0.417 acc:85.19 | val loss:0.363 acc:86.75\n",
            "Epoch:0071 train loss:0.413 acc:86.02 | val loss:0.360 acc:86.58\n",
            "Epoch:0072 train loss:0.415 acc:85.63 | val loss:0.358 acc:86.83\n",
            "Epoch:0073 train loss:0.410 acc:85.82 | val loss:0.356 acc:86.81\n",
            "Epoch:0074 train loss:0.406 acc:86.26 | val loss:0.357 acc:86.99\n",
            "Epoch:0075 train loss:0.404 acc:85.99 | val loss:0.353 acc:86.96\n",
            "Epoch:0076 train loss:0.403 acc:86.53 | val loss:0.351 acc:87.18\n",
            "Epoch:0077 train loss:0.394 acc:86.28 | val loss:0.349 acc:87.13\n",
            "Epoch:0078 train loss:0.395 acc:86.16 | val loss:0.348 acc:87.07\n",
            "Epoch:0079 train loss:0.398 acc:86.20 | val loss:0.347 acc:87.21\n",
            "Epoch:0080 train loss:0.396 acc:86.25 | val loss:0.345 acc:87.31\n",
            "Epoch:0081 train loss:0.389 acc:86.57 | val loss:0.344 acc:87.31\n",
            "Epoch:0082 train loss:0.394 acc:86.38 | val loss:0.342 acc:87.40\n",
            "Epoch:0083 train loss:0.386 acc:86.53 | val loss:0.342 acc:87.35\n",
            "Epoch:0084 train loss:0.394 acc:86.14 | val loss:0.341 acc:87.37\n",
            "Epoch:0085 train loss:0.382 acc:86.65 | val loss:0.339 acc:87.40\n",
            "Epoch:0086 train loss:0.383 acc:86.27 | val loss:0.338 acc:87.59\n",
            "Epoch:0087 train loss:0.388 acc:86.61 | val loss:0.338 acc:87.69\n",
            "Epoch:0088 train loss:0.376 acc:86.41 | val loss:0.338 acc:87.69\n",
            "Epoch:0089 train loss:0.389 acc:86.62 | val loss:0.334 acc:87.75\n",
            "Epoch:0090 train loss:0.383 acc:86.74 | val loss:0.333 acc:87.77\n",
            "Epoch:0091 train loss:0.378 acc:87.02 | val loss:0.333 acc:87.81\n",
            "Epoch:0092 train loss:0.379 acc:86.96 | val loss:0.333 acc:87.81\n",
            "Epoch:0093 train loss:0.375 acc:86.49 | val loss:0.330 acc:87.88\n",
            "Epoch:0094 train loss:0.372 acc:86.92 | val loss:0.329 acc:87.96\n",
            "Epoch:0095 train loss:0.370 acc:86.75 | val loss:0.329 acc:88.03\n",
            "Epoch:0096 train loss:0.371 acc:86.99 | val loss:0.328 acc:88.07\n",
            "Epoch:0097 train loss:0.372 acc:86.61 | val loss:0.327 acc:88.05\n",
            "Epoch:0098 train loss:0.378 acc:87.08 | val loss:0.326 acc:88.10\n",
            "Epoch:0099 train loss:0.370 acc:86.71 | val loss:0.325 acc:88.21\n",
            "Epoch:0100 train loss:0.371 acc:86.81 | val loss:0.324 acc:88.19\n",
            "Epoch:0101 train loss:0.374 acc:87.02 | val loss:0.324 acc:88.29\n",
            "Epoch:0102 train loss:0.365 acc:87.16 | val loss:0.325 acc:88.19\n",
            "Epoch:0103 train loss:0.375 acc:86.85 | val loss:0.323 acc:88.23\n",
            "Epoch:0104 train loss:0.369 acc:86.98 | val loss:0.323 acc:88.19\n",
            "Epoch:0105 train loss:0.364 acc:87.08 | val loss:0.321 acc:88.19\n",
            "Epoch:0106 train loss:0.370 acc:86.80 | val loss:0.322 acc:88.27\n",
            "Epoch:0107 train loss:0.368 acc:86.94 | val loss:0.320 acc:88.38\n",
            "Epoch:0108 train loss:0.356 acc:87.64 | val loss:0.319 acc:88.32\n",
            "Epoch:0109 train loss:0.363 acc:87.17 | val loss:0.318 acc:88.51\n",
            "Epoch:0110 train loss:0.365 acc:87.19 | val loss:0.325 acc:87.86\n",
            "Epoch:0111 train loss:0.374 acc:87.08 | val loss:0.319 acc:88.32\n",
            "Epoch:0112 train loss:0.362 acc:87.15 | val loss:0.320 acc:88.32\n",
            "Epoch:0113 train loss:0.366 acc:87.22 | val loss:0.317 acc:88.42\n",
            "Epoch:0114 train loss:0.363 acc:87.42 | val loss:0.321 acc:88.08\n",
            "Epoch:0115 train loss:0.364 acc:86.94 | val loss:0.317 acc:88.46\n",
            "Epoch:0116 train loss:0.360 acc:87.17 | val loss:0.316 acc:88.48\n",
            "Epoch:0117 train loss:0.356 acc:87.76 | val loss:0.314 acc:88.53\n",
            "Epoch:0118 train loss:0.357 acc:87.85 | val loss:0.314 acc:88.48\n",
            "Epoch:0119 train loss:0.347 acc:87.54 | val loss:0.314 acc:88.51\n",
            "Epoch:0120 train loss:0.353 acc:87.53 | val loss:0.313 acc:88.49\n",
            "Epoch:0121 train loss:0.352 acc:87.61 | val loss:0.314 acc:88.64\n",
            "Epoch:0122 train loss:0.351 acc:87.60 | val loss:0.313 acc:88.75\n",
            "Epoch:0123 train loss:0.352 acc:87.19 | val loss:0.312 acc:88.75\n",
            "Epoch:0124 train loss:0.354 acc:87.40 | val loss:0.312 acc:88.78\n",
            "Epoch:0125 train loss:0.349 acc:87.60 | val loss:0.312 acc:88.62\n",
            "Epoch:0126 train loss:0.344 acc:88.00 | val loss:0.311 acc:88.75\n",
            "Epoch:0127 train loss:0.351 acc:87.44 | val loss:0.311 acc:88.75\n",
            "Epoch:0128 train loss:0.348 acc:87.68 | val loss:0.310 acc:88.72\n",
            "Epoch:0129 train loss:0.343 acc:87.93 | val loss:0.310 acc:88.76\n",
            "Epoch:0130 train loss:0.351 acc:87.52 | val loss:0.308 acc:88.95\n",
            "Epoch:0131 train loss:0.344 acc:87.54 | val loss:0.308 acc:88.99\n",
            "Epoch:0132 train loss:0.348 acc:87.85 | val loss:0.308 acc:88.94\n",
            "Epoch:0133 train loss:0.347 acc:87.92 | val loss:0.308 acc:88.89\n",
            "Epoch:0134 train loss:0.336 acc:88.15 | val loss:0.306 acc:89.06\n",
            "Epoch:0135 train loss:0.340 acc:88.05 | val loss:0.307 acc:88.87\n",
            "Epoch:0136 train loss:0.348 acc:87.77 | val loss:0.305 acc:89.10\n",
            "Epoch:0137 train loss:0.347 acc:87.63 | val loss:0.305 acc:88.95\n",
            "Epoch:0138 train loss:0.348 acc:87.64 | val loss:0.304 acc:89.18\n",
            "Epoch:0139 train loss:0.344 acc:87.77 | val loss:0.305 acc:88.92\n",
            "Epoch:0140 train loss:0.342 acc:87.53 | val loss:0.306 acc:88.92\n",
            "Epoch:0141 train loss:0.342 acc:88.19 | val loss:0.306 acc:88.92\n",
            "Epoch:0142 train loss:0.350 acc:87.46 | val loss:0.307 acc:88.70\n",
            "Epoch:0143 train loss:0.343 acc:87.53 | val loss:0.304 acc:89.08\n",
            "Epoch:0144 train loss:0.344 acc:87.74 | val loss:0.307 acc:89.00\n",
            "Epoch:0145 train loss:0.344 acc:87.67 | val loss:0.304 acc:89.03\n",
            "Epoch:0146 train loss:0.340 acc:88.09 | val loss:0.303 acc:89.05\n",
            "Epoch:0147 train loss:0.340 acc:88.06 | val loss:0.302 acc:88.92\n",
            "Epoch:0148 train loss:0.341 acc:87.52 | val loss:0.301 acc:89.02\n",
            "Epoch:0149 train loss:0.333 acc:88.20 | val loss:0.301 acc:89.19\n",
            "Epoch:0150 train loss:0.338 acc:87.83 | val loss:0.301 acc:89.19\n",
            "Epoch:0151 train loss:0.340 acc:87.78 | val loss:0.300 acc:89.03\n",
            "Epoch:0152 train loss:0.338 acc:87.75 | val loss:0.303 acc:88.83\n",
            "Epoch:0153 train loss:0.334 acc:88.21 | val loss:0.301 acc:88.92\n",
            "Epoch:0154 train loss:0.335 acc:88.10 | val loss:0.302 acc:89.11\n",
            "Epoch:0155 train loss:0.340 acc:88.06 | val loss:0.303 acc:89.16\n",
            "Epoch:0156 train loss:0.345 acc:87.74 | val loss:0.302 acc:88.95\n",
            "Epoch:0157 train loss:0.338 acc:87.84 | val loss:0.302 acc:88.76\n",
            "Epoch:0158 train loss:0.332 acc:88.54 | val loss:0.300 acc:88.76\n",
            "Epoch:0159 train loss:0.339 acc:87.76 | val loss:0.298 acc:89.22\n",
            "Epoch:0160 train loss:0.347 acc:87.51 | val loss:0.300 acc:89.22\n",
            "Epoch:0161 train loss:0.335 acc:88.06 | val loss:0.298 acc:89.18\n",
            "Epoch:0162 train loss:0.336 acc:88.17 | val loss:0.297 acc:89.08\n",
            "Epoch:0163 train loss:0.334 acc:88.21 | val loss:0.298 acc:89.02\n",
            "Epoch:0164 train loss:0.334 acc:88.22 | val loss:0.298 acc:89.16\n",
            "Epoch:0165 train loss:0.336 acc:87.90 | val loss:0.296 acc:89.45\n",
            "Epoch:0166 train loss:0.332 acc:87.84 | val loss:0.297 acc:89.40\n",
            "Epoch:0167 train loss:0.331 acc:88.42 | val loss:0.298 acc:89.35\n",
            "Epoch:0168 train loss:0.333 acc:88.42 | val loss:0.296 acc:89.21\n",
            "Epoch:0169 train loss:0.328 acc:88.59 | val loss:0.296 acc:88.95\n",
            "Epoch:0170 train loss:0.334 acc:87.87 | val loss:0.295 acc:89.30\n",
            "Epoch:0171 train loss:0.335 acc:88.04 | val loss:0.294 acc:89.37\n",
            "Epoch:0172 train loss:0.329 acc:88.33 | val loss:0.294 acc:89.18\n",
            "Epoch:0173 train loss:0.329 acc:88.63 | val loss:0.295 acc:89.24\n",
            "Epoch:0174 train loss:0.335 acc:88.39 | val loss:0.296 acc:89.10\n",
            "Epoch:0175 train loss:0.325 acc:88.31 | val loss:0.294 acc:89.11\n",
            "Epoch:0176 train loss:0.331 acc:88.17 | val loss:0.293 acc:89.30\n",
            "Epoch:0177 train loss:0.327 acc:88.24 | val loss:0.295 acc:89.24\n",
            "Epoch:0178 train loss:0.330 acc:88.21 | val loss:0.292 acc:89.35\n",
            "Epoch:0179 train loss:0.332 acc:87.88 | val loss:0.293 acc:89.19\n",
            "Epoch:0180 train loss:0.328 acc:88.10 | val loss:0.292 acc:89.29\n",
            "Epoch:0181 train loss:0.335 acc:87.76 | val loss:0.296 acc:89.32\n",
            "Epoch:0182 train loss:0.328 acc:88.01 | val loss:0.291 acc:89.40\n",
            "Epoch:0183 train loss:0.331 acc:88.05 | val loss:0.295 acc:89.48\n",
            "Epoch:0184 train loss:0.332 acc:88.25 | val loss:0.299 acc:89.06\n",
            "Epoch:0185 train loss:0.333 acc:87.88 | val loss:0.294 acc:89.37\n",
            "Epoch:0186 train loss:0.330 acc:87.78 | val loss:0.297 acc:89.00\n",
            "Epoch:0187 train loss:0.338 acc:87.79 | val loss:0.292 acc:89.38\n",
            "Epoch:0188 train loss:0.327 acc:88.08 | val loss:0.294 acc:89.43\n",
            "Epoch:0189 train loss:0.337 acc:87.58 | val loss:0.291 acc:89.40\n",
            "Epoch:0190 train loss:0.327 acc:88.28 | val loss:0.291 acc:89.52\n",
            "Epoch:0191 train loss:0.327 acc:88.24 | val loss:0.292 acc:89.41\n",
            "Epoch:0192 train loss:0.329 acc:88.24 | val loss:0.291 acc:89.21\n",
            "Epoch:0193 train loss:0.324 acc:88.35 | val loss:0.290 acc:89.43\n",
            "Epoch:0194 train loss:0.323 acc:88.27 | val loss:0.289 acc:89.56\n",
            "Epoch:0195 train loss:0.326 acc:88.31 | val loss:0.290 acc:89.38\n",
            "Epoch:0196 train loss:0.321 acc:88.28 | val loss:0.290 acc:89.37\n",
            "Epoch:0197 train loss:0.322 acc:88.38 | val loss:0.291 acc:89.29\n",
            "Epoch:0198 train loss:0.321 acc:88.42 | val loss:0.290 acc:89.26\n",
            "Epoch:0199 train loss:0.324 acc:88.13 | val loss:0.290 acc:89.57\n",
            "Epoch:0200 train loss:0.323 acc:88.53 | val loss:0.290 acc:89.51\n",
            "Epoch:0201 train loss:0.317 acc:88.63 | val loss:0.289 acc:89.54\n",
            "Epoch:0202 train loss:0.321 acc:88.41 | val loss:0.291 acc:89.26\n",
            "Epoch:0203 train loss:0.323 acc:87.98 | val loss:0.291 acc:89.27\n",
            "Epoch:0204 train loss:0.323 acc:88.46 | val loss:0.289 acc:89.51\n",
            "Epoch:0205 train loss:0.320 acc:88.27 | val loss:0.290 acc:89.57\n",
            "Epoch:0206 train loss:0.326 acc:88.16 | val loss:0.288 acc:89.52\n",
            "Epoch:0207 train loss:0.313 acc:88.51 | val loss:0.294 acc:89.10\n",
            "Epoch:0208 train loss:0.322 acc:88.37 | val loss:0.289 acc:89.32\n",
            "Epoch:0209 train loss:0.314 acc:88.62 | val loss:0.290 acc:89.30\n",
            "Epoch:0210 train loss:0.323 acc:88.11 | val loss:0.288 acc:89.70\n",
            "Epoch:0211 train loss:0.319 acc:88.33 | val loss:0.291 acc:89.41\n",
            "Epoch:0212 train loss:0.325 acc:88.23 | val loss:0.286 acc:89.52\n",
            "Epoch:0213 train loss:0.316 acc:88.57 | val loss:0.286 acc:89.48\n",
            "Epoch:0214 train loss:0.313 acc:88.52 | val loss:0.285 acc:89.54\n",
            "Epoch:0215 train loss:0.315 acc:88.50 | val loss:0.285 acc:89.60\n",
            "Epoch:0216 train loss:0.313 acc:88.66 | val loss:0.285 acc:89.64\n",
            "Epoch:0217 train loss:0.316 acc:88.79 | val loss:0.285 acc:89.73\n",
            "Epoch:0218 train loss:0.319 acc:88.20 | val loss:0.285 acc:89.65\n",
            "Epoch:0219 train loss:0.320 acc:88.47 | val loss:0.285 acc:89.65\n",
            "Epoch:0220 train loss:0.315 acc:88.79 | val loss:0.285 acc:89.70\n",
            "Epoch:0221 train loss:0.313 acc:88.74 | val loss:0.287 acc:89.48\n",
            "Epoch:0222 train loss:0.315 acc:88.61 | val loss:0.288 acc:89.38\n",
            "Epoch:0223 train loss:0.315 acc:88.30 | val loss:0.284 acc:89.68\n",
            "Epoch:0224 train loss:0.314 acc:88.29 | val loss:0.284 acc:89.65\n",
            "Epoch:0225 train loss:0.316 acc:88.40 | val loss:0.285 acc:89.68\n",
            "Epoch:0226 train loss:0.312 acc:88.89 | val loss:0.285 acc:89.48\n",
            "Epoch:0227 train loss:0.313 acc:88.58 | val loss:0.285 acc:89.43\n",
            "Epoch:0228 train loss:0.315 acc:88.66 | val loss:0.283 acc:89.68\n",
            "Epoch:0229 train loss:0.316 acc:88.87 | val loss:0.289 acc:89.68\n",
            "Epoch:0230 train loss:0.317 acc:88.27 | val loss:0.283 acc:89.71\n",
            "Epoch:0231 train loss:0.316 acc:88.46 | val loss:0.284 acc:89.60\n",
            "Epoch:0232 train loss:0.308 acc:89.00 | val loss:0.287 acc:89.26\n",
            "Epoch:0233 train loss:0.318 acc:88.29 | val loss:0.284 acc:89.54\n",
            "Epoch:0234 train loss:0.314 acc:88.60 | val loss:0.283 acc:89.84\n",
            "Epoch:0235 train loss:0.315 acc:88.80 | val loss:0.285 acc:89.87\n",
            "Epoch:0236 train loss:0.316 acc:88.96 | val loss:0.283 acc:89.78\n",
            "Epoch:0237 train loss:0.311 acc:88.43 | val loss:0.283 acc:89.38\n",
            "Epoch:0238 train loss:0.314 acc:88.72 | val loss:0.285 acc:89.27\n",
            "Epoch:0239 train loss:0.316 acc:88.62 | val loss:0.288 acc:89.38\n",
            "Epoch:0240 train loss:0.311 acc:88.52 | val loss:0.283 acc:89.67\n",
            "Epoch:0241 train loss:0.318 acc:88.41 | val loss:0.287 acc:89.64\n",
            "Epoch:0242 train loss:0.323 acc:88.06 | val loss:0.293 acc:89.27\n",
            "Epoch:0243 train loss:0.321 acc:88.22 | val loss:0.287 acc:89.26\n",
            "Epoch:0244 train loss:0.314 acc:88.42 | val loss:0.287 acc:89.21\n",
            "Epoch:0245 train loss:0.326 acc:88.24 | val loss:0.282 acc:89.65\n",
            "Epoch:0246 train loss:0.311 acc:88.87 | val loss:0.286 acc:89.59\n",
            "Epoch:0247 train loss:0.321 acc:88.10 | val loss:0.281 acc:89.87\n",
            "Epoch:0248 train loss:0.314 acc:88.79 | val loss:0.281 acc:89.76\n",
            "Epoch:0249 train loss:0.307 acc:88.99 | val loss:0.283 acc:89.59\n",
            "Epoch:0250 train loss:0.304 acc:88.68 | val loss:0.284 acc:89.49\n",
            "Epoch:0251 train loss:0.315 acc:88.19 | val loss:0.281 acc:89.75\n",
            "Epoch:0252 train loss:0.311 acc:88.81 | val loss:0.282 acc:89.76\n",
            "Epoch:0253 train loss:0.311 acc:89.04 | val loss:0.282 acc:89.75\n",
            "Epoch:0254 train loss:0.311 acc:88.46 | val loss:0.284 acc:89.46\n",
            "Epoch:0255 train loss:0.310 acc:88.78 | val loss:0.284 acc:89.46\n",
            "Epoch:0256 train loss:0.303 acc:88.80 | val loss:0.284 acc:89.45\n",
            "Epoch:0257 train loss:0.309 acc:88.66 | val loss:0.280 acc:89.83\n",
            "Epoch:0258 train loss:0.305 acc:88.90 | val loss:0.282 acc:89.78\n",
            "Epoch:0259 train loss:0.309 acc:88.95 | val loss:0.278 acc:90.05\n",
            "Epoch:0260 train loss:0.312 acc:88.63 | val loss:0.278 acc:89.78\n",
            "Epoch:0261 train loss:0.303 acc:88.93 | val loss:0.281 acc:89.68\n",
            "Epoch:0262 train loss:0.304 acc:89.10 | val loss:0.280 acc:89.79\n",
            "Epoch:0263 train loss:0.305 acc:88.90 | val loss:0.277 acc:89.98\n",
            "Epoch:0264 train loss:0.306 acc:88.93 | val loss:0.277 acc:89.94\n",
            "Epoch:0265 train loss:0.299 acc:89.34 | val loss:0.282 acc:89.59\n",
            "Epoch:0266 train loss:0.304 acc:88.89 | val loss:0.280 acc:89.70\n",
            "Epoch:0267 train loss:0.305 acc:89.16 | val loss:0.279 acc:89.84\n",
            "Epoch:0268 train loss:0.309 acc:88.67 | val loss:0.281 acc:89.89\n",
            "Epoch:0269 train loss:0.301 acc:89.10 | val loss:0.278 acc:90.10\n",
            "Epoch:0270 train loss:0.297 acc:89.18 | val loss:0.276 acc:89.98\n",
            "Epoch:0271 train loss:0.309 acc:88.69 | val loss:0.276 acc:89.97\n",
            "Epoch:0272 train loss:0.302 acc:88.83 | val loss:0.281 acc:89.64\n",
            "Epoch:0273 train loss:0.304 acc:88.94 | val loss:0.278 acc:89.79\n",
            "Epoch:0274 train loss:0.302 acc:88.97 | val loss:0.275 acc:90.10\n",
            "Epoch:0275 train loss:0.305 acc:89.34 | val loss:0.275 acc:90.17\n",
            "Epoch:0276 train loss:0.302 acc:89.20 | val loss:0.277 acc:89.79\n",
            "Epoch:0277 train loss:0.294 acc:89.20 | val loss:0.277 acc:89.90\n",
            "Epoch:0278 train loss:0.302 acc:89.05 | val loss:0.278 acc:89.62\n",
            "Epoch:0279 train loss:0.291 acc:89.58 | val loss:0.275 acc:90.06\n",
            "Epoch:0280 train loss:0.302 acc:88.89 | val loss:0.277 acc:89.97\n",
            "Epoch:0281 train loss:0.298 acc:89.12 | val loss:0.275 acc:90.00\n",
            "Epoch:0282 train loss:0.296 acc:89.22 | val loss:0.275 acc:90.02\n",
            "Epoch:0283 train loss:0.297 acc:89.26 | val loss:0.275 acc:90.21\n",
            "Epoch:0284 train loss:0.293 acc:89.18 | val loss:0.275 acc:89.87\n",
            "Epoch:0285 train loss:0.299 acc:89.10 | val loss:0.277 acc:89.98\n",
            "Epoch:0286 train loss:0.299 acc:89.15 | val loss:0.275 acc:90.14\n",
            "Epoch:0287 train loss:0.301 acc:89.07 | val loss:0.275 acc:90.05\n",
            "Epoch:0288 train loss:0.298 acc:88.98 | val loss:0.275 acc:89.92\n",
            "Epoch:0289 train loss:0.294 acc:89.03 | val loss:0.275 acc:89.95\n",
            "Epoch:0290 train loss:0.301 acc:89.37 | val loss:0.277 acc:89.79\n",
            "Epoch:0291 train loss:0.293 acc:89.25 | val loss:0.276 acc:89.89\n",
            "Epoch:0292 train loss:0.300 acc:89.16 | val loss:0.274 acc:90.13\n",
            "Epoch:0293 train loss:0.295 acc:89.47 | val loss:0.274 acc:89.98\n",
            "Epoch:0294 train loss:0.290 acc:89.36 | val loss:0.276 acc:89.81\n",
            "Epoch:0295 train loss:0.294 acc:89.59 | val loss:0.276 acc:89.86\n",
            "Epoch:0296 train loss:0.291 acc:89.54 | val loss:0.275 acc:89.90\n",
            "Epoch:0297 train loss:0.293 acc:89.28 | val loss:0.274 acc:89.90\n",
            "Epoch:0298 train loss:0.296 acc:88.95 | val loss:0.275 acc:89.76\n",
            "Epoch:0299 train loss:0.291 acc:88.95 | val loss:0.277 acc:89.71\n",
            "Epoch:0300 train loss:0.302 acc:88.63 | val loss:0.273 acc:89.94\n",
            "Epoch:0301 train loss:0.293 acc:88.95 | val loss:0.277 acc:89.86\n",
            "Epoch:0302 train loss:0.295 acc:89.17 | val loss:0.272 acc:90.14\n",
            "Epoch:0303 train loss:0.295 acc:89.37 | val loss:0.273 acc:89.94\n",
            "Epoch:0304 train loss:0.295 acc:89.38 | val loss:0.275 acc:89.90\n",
            "Epoch:0305 train loss:0.292 acc:89.16 | val loss:0.274 acc:90.14\n",
            "Epoch:0306 train loss:0.298 acc:89.27 | val loss:0.273 acc:90.16\n",
            "Epoch:0307 train loss:0.293 acc:89.39 | val loss:0.275 acc:90.00\n",
            "Epoch:0308 train loss:0.290 acc:89.58 | val loss:0.273 acc:89.90\n",
            "Epoch:0309 train loss:0.293 acc:89.37 | val loss:0.272 acc:89.92\n",
            "Epoch:0310 train loss:0.300 acc:88.91 | val loss:0.274 acc:89.98\n",
            "Epoch:0311 train loss:0.293 acc:89.42 | val loss:0.274 acc:90.00\n",
            "Epoch:0312 train loss:0.299 acc:89.23 | val loss:0.272 acc:90.41\n",
            "Epoch:0313 train loss:0.294 acc:89.37 | val loss:0.272 acc:90.17\n",
            "Epoch:0314 train loss:0.287 acc:89.38 | val loss:0.276 acc:90.10\n",
            "Epoch:0315 train loss:0.292 acc:89.04 | val loss:0.272 acc:90.27\n",
            "Epoch:0316 train loss:0.285 acc:89.51 | val loss:0.275 acc:90.24\n",
            "Epoch:0317 train loss:0.288 acc:89.46 | val loss:0.270 acc:90.21\n",
            "Epoch:0318 train loss:0.298 acc:88.79 | val loss:0.270 acc:90.29\n",
            "Epoch:0319 train loss:0.292 acc:89.07 | val loss:0.275 acc:90.32\n",
            "Epoch:0320 train loss:0.288 acc:89.57 | val loss:0.272 acc:90.11\n",
            "Epoch:0321 train loss:0.285 acc:89.75 | val loss:0.272 acc:90.27\n",
            "Epoch:0322 train loss:0.289 acc:89.57 | val loss:0.273 acc:90.17\n",
            "Epoch:0323 train loss:0.287 acc:89.52 | val loss:0.272 acc:90.22\n",
            "Epoch:0324 train loss:0.287 acc:89.28 | val loss:0.273 acc:90.03\n",
            "Epoch:0325 train loss:0.287 acc:89.54 | val loss:0.271 acc:90.16\n",
            "Epoch:0326 train loss:0.289 acc:89.34 | val loss:0.268 acc:90.29\n",
            "Epoch:0327 train loss:0.285 acc:89.59 | val loss:0.274 acc:90.13\n",
            "Epoch:0328 train loss:0.281 acc:90.05 | val loss:0.269 acc:90.25\n",
            "Epoch:0329 train loss:0.285 acc:89.43 | val loss:0.271 acc:89.95\n",
            "Epoch:0330 train loss:0.292 acc:89.13 | val loss:0.284 acc:89.73\n",
            "Epoch:0331 train loss:0.295 acc:88.99 | val loss:0.270 acc:90.30\n",
            "Epoch:0332 train loss:0.291 acc:89.46 | val loss:0.269 acc:90.08\n",
            "Epoch:0333 train loss:0.287 acc:89.36 | val loss:0.281 acc:89.68\n",
            "Epoch:0334 train loss:0.290 acc:89.10 | val loss:0.274 acc:90.06\n",
            "Epoch:0335 train loss:0.294 acc:89.19 | val loss:0.272 acc:90.03\n",
            "Epoch:0336 train loss:0.297 acc:89.15 | val loss:0.271 acc:90.30\n",
            "Epoch:0337 train loss:0.287 acc:89.70 | val loss:0.277 acc:89.92\n",
            "Epoch:0338 train loss:0.293 acc:89.36 | val loss:0.271 acc:90.11\n",
            "Epoch:0339 train loss:0.287 acc:89.44 | val loss:0.270 acc:90.21\n",
            "Epoch:0340 train loss:0.288 acc:89.73 | val loss:0.281 acc:89.81\n",
            "Epoch:0341 train loss:0.294 acc:89.24 | val loss:0.269 acc:90.24\n",
            "Epoch:0342 train loss:0.287 acc:89.90 | val loss:0.270 acc:90.19\n",
            "Epoch:0343 train loss:0.286 acc:89.79 | val loss:0.278 acc:89.79\n",
            "Epoch:0344 train loss:0.285 acc:89.55 | val loss:0.274 acc:89.95\n",
            "Epoch:0345 train loss:0.278 acc:89.81 | val loss:0.268 acc:90.16\n",
            "Epoch:0346 train loss:0.291 acc:89.24 | val loss:0.268 acc:90.33\n",
            "Epoch:0347 train loss:0.290 acc:89.26 | val loss:0.278 acc:89.86\n",
            "Epoch:0348 train loss:0.292 acc:89.34 | val loss:0.269 acc:90.06\n",
            "Epoch:0349 train loss:0.284 acc:89.82 | val loss:0.268 acc:90.32\n",
            "Epoch:0350 train loss:0.284 acc:89.38 | val loss:0.271 acc:90.19\n",
            "Epoch:0351 train loss:0.286 acc:89.73 | val loss:0.273 acc:90.10\n",
            "Epoch:0352 train loss:0.282 acc:89.68 | val loss:0.269 acc:90.22\n",
            "Epoch:0353 train loss:0.282 acc:89.79 | val loss:0.270 acc:90.06\n",
            "Epoch:0354 train loss:0.283 acc:89.52 | val loss:0.279 acc:89.62\n",
            "Epoch:0355 train loss:0.286 acc:89.39 | val loss:0.268 acc:90.24\n",
            "Epoch:0356 train loss:0.285 acc:89.52 | val loss:0.268 acc:90.35\n",
            "Epoch:0357 train loss:0.287 acc:89.34 | val loss:0.274 acc:89.92\n",
            "Epoch:0358 train loss:0.278 acc:89.97 | val loss:0.281 acc:89.54\n",
            "Epoch:0359 train loss:0.284 acc:89.56 | val loss:0.268 acc:90.10\n",
            "Epoch:0360 train loss:0.281 acc:89.80 | val loss:0.269 acc:90.25\n",
            "Epoch:0361 train loss:0.287 acc:89.53 | val loss:0.281 acc:89.57\n",
            "Epoch:0362 train loss:0.282 acc:89.19 | val loss:0.274 acc:89.90\n",
            "Epoch:0363 train loss:0.288 acc:89.32 | val loss:0.272 acc:90.05\n",
            "Epoch:0364 train loss:0.295 acc:89.36 | val loss:0.271 acc:90.11\n",
            "Epoch:0365 train loss:0.285 acc:89.54 | val loss:0.275 acc:89.83\n",
            "Epoch:0366 train loss:0.286 acc:89.69 | val loss:0.265 acc:90.40\n",
            "Epoch:0367 train loss:0.281 acc:89.74 | val loss:0.266 acc:90.30\n",
            "Epoch:0368 train loss:0.282 acc:89.82 | val loss:0.270 acc:90.22\n",
            "Epoch:0369 train loss:0.279 acc:89.55 | val loss:0.277 acc:89.89\n",
            "Epoch:0370 train loss:0.283 acc:89.55 | val loss:0.269 acc:90.32\n",
            "Epoch:0371 train loss:0.279 acc:89.70 | val loss:0.269 acc:90.25\n",
            "Epoch:0372 train loss:0.281 acc:89.52 | val loss:0.276 acc:89.92\n",
            "Epoch:0373 train loss:0.279 acc:89.65 | val loss:0.276 acc:89.95\n",
            "Epoch:0374 train loss:0.284 acc:89.55 | val loss:0.269 acc:90.25\n",
            "Epoch:0375 train loss:0.283 acc:89.72 | val loss:0.268 acc:90.25\n",
            "Epoch:0376 train loss:0.276 acc:90.06 | val loss:0.270 acc:90.36\n",
            "Epoch:0377 train loss:0.277 acc:90.01 | val loss:0.271 acc:90.29\n",
            "Epoch:0378 train loss:0.277 acc:90.03 | val loss:0.268 acc:90.38\n",
            "Epoch:0379 train loss:0.278 acc:89.81 | val loss:0.272 acc:90.10\n",
            "Epoch:0380 train loss:0.274 acc:89.65 | val loss:0.276 acc:89.84\n",
            "Epoch:0381 train loss:0.285 acc:89.25 | val loss:0.266 acc:90.48\n",
            "Epoch:0382 train loss:0.268 acc:90.27 | val loss:0.265 acc:90.43\n",
            "Epoch:0383 train loss:0.276 acc:89.95 | val loss:0.270 acc:90.24\n",
            "Epoch:0384 train loss:0.275 acc:89.88 | val loss:0.270 acc:90.10\n",
            "Epoch:0385 train loss:0.283 acc:89.26 | val loss:0.267 acc:90.32\n",
            "Epoch:0386 train loss:0.288 acc:89.28 | val loss:0.266 acc:90.38\n",
            "Epoch:0387 train loss:0.266 acc:90.34 | val loss:0.276 acc:90.03\n",
            "Epoch:0388 train loss:0.278 acc:89.91 | val loss:0.268 acc:90.41\n",
            "Epoch:0389 train loss:0.272 acc:90.24 | val loss:0.270 acc:90.22\n",
            "Epoch:0390 train loss:0.273 acc:90.03 | val loss:0.270 acc:90.19\n",
            "Epoch:0391 train loss:0.278 acc:89.59 | val loss:0.274 acc:90.21\n",
            "Epoch:0392 train loss:0.281 acc:89.68 | val loss:0.267 acc:90.32\n",
            "Epoch:0393 train loss:0.277 acc:89.84 | val loss:0.266 acc:90.21\n",
            "Epoch:0394 train loss:0.273 acc:89.83 | val loss:0.270 acc:89.95\n",
            "Epoch:0395 train loss:0.274 acc:89.98 | val loss:0.275 acc:89.89\n",
            "Epoch:0396 train loss:0.265 acc:90.44 | val loss:0.268 acc:90.32\n",
            "Epoch:0397 train loss:0.270 acc:90.25 | val loss:0.267 acc:90.44\n",
            "Epoch:0398 train loss:0.275 acc:90.07 | val loss:0.271 acc:90.29\n",
            "Epoch:0399 train loss:0.274 acc:90.12 | val loss:0.272 acc:90.13\n",
            "Epoch:0400 train loss:0.267 acc:90.11 | val loss:0.268 acc:90.35\n",
            "Epoch:0401 train loss:0.279 acc:89.50 | val loss:0.267 acc:90.36\n",
            "Epoch:0402 train loss:0.270 acc:89.98 | val loss:0.279 acc:89.78\n",
            "Epoch:0403 train loss:0.275 acc:89.88 | val loss:0.270 acc:90.30\n",
            "Epoch:0404 train loss:0.269 acc:89.95 | val loss:0.266 acc:90.35\n",
            "Epoch:0405 train loss:0.273 acc:90.18 | val loss:0.265 acc:90.57\n",
            "Epoch:0406 train loss:0.272 acc:89.71 | val loss:0.272 acc:90.33\n",
            "Epoch:0407 train loss:0.270 acc:89.93 | val loss:0.272 acc:90.29\n",
            "Epoch:0408 train loss:0.273 acc:89.93 | val loss:0.267 acc:90.46\n",
            "Epoch:0409 train loss:0.268 acc:89.87 | val loss:0.266 acc:90.55\n",
            "Epoch:0410 train loss:0.272 acc:89.78 | val loss:0.276 acc:90.02\n",
            "Epoch:0411 train loss:0.272 acc:89.86 | val loss:0.271 acc:90.21\n",
            "Epoch:0412 train loss:0.277 acc:89.51 | val loss:0.264 acc:90.33\n",
            "Epoch:0413 train loss:0.267 acc:90.15 | val loss:0.263 acc:90.46\n",
            "Epoch:0414 train loss:0.273 acc:89.97 | val loss:0.269 acc:90.54\n",
            "Epoch:0415 train loss:0.262 acc:90.18 | val loss:0.271 acc:90.38\n",
            "Epoch:0416 train loss:0.276 acc:89.96 | val loss:0.267 acc:90.30\n",
            "Epoch:0417 train loss:0.275 acc:89.72 | val loss:0.265 acc:90.57\n",
            "Epoch:0418 train loss:0.272 acc:90.05 | val loss:0.271 acc:90.22\n",
            "Epoch:0419 train loss:0.264 acc:90.06 | val loss:0.269 acc:90.41\n",
            "Epoch:0420 train loss:0.276 acc:90.03 | val loss:0.267 acc:90.17\n",
            "Epoch:0421 train loss:0.265 acc:90.19 | val loss:0.270 acc:90.10\n",
            "Epoch:0422 train loss:0.259 acc:90.45 | val loss:0.271 acc:90.46\n",
            "Epoch:0423 train loss:0.265 acc:90.45 | val loss:0.268 acc:90.43\n",
            "Epoch:0424 train loss:0.264 acc:90.25 | val loss:0.265 acc:90.35\n",
            "Epoch:0425 train loss:0.271 acc:89.95 | val loss:0.270 acc:90.10\n",
            "Epoch:0426 train loss:0.271 acc:89.78 | val loss:0.276 acc:89.75\n",
            "Epoch:0427 train loss:0.271 acc:90.14 | val loss:0.265 acc:90.40\n",
            "Epoch:0428 train loss:0.265 acc:90.14 | val loss:0.265 acc:90.52\n",
            "Epoch:0429 train loss:0.274 acc:89.87 | val loss:0.265 acc:90.48\n",
            "Epoch:0430 train loss:0.270 acc:90.09 | val loss:0.275 acc:90.11\n",
            "Epoch:0431 train loss:0.266 acc:90.23 | val loss:0.272 acc:90.00\n",
            "Epoch:0432 train loss:0.274 acc:89.46 | val loss:0.266 acc:90.32\n",
            "Epoch:0433 train loss:0.267 acc:90.39 | val loss:0.273 acc:90.25\n",
            "Epoch:0434 train loss:0.276 acc:90.42 | val loss:0.265 acc:90.49\n",
            "Epoch:0435 train loss:0.266 acc:90.50 | val loss:0.264 acc:90.33\n",
            "Epoch:0436 train loss:0.269 acc:90.18 | val loss:0.272 acc:89.94\n",
            "Epoch:0437 train loss:0.273 acc:90.15 | val loss:0.276 acc:89.94\n",
            "Epoch:0438 train loss:0.265 acc:90.30 | val loss:0.262 acc:90.57\n",
            "Epoch:0439 train loss:0.268 acc:90.12 | val loss:0.263 acc:90.43\n",
            "Epoch:0440 train loss:0.262 acc:90.49 | val loss:0.269 acc:90.35\n",
            "Epoch:0441 train loss:0.267 acc:90.47 | val loss:0.276 acc:90.13\n",
            "Epoch:0442 train loss:0.271 acc:89.75 | val loss:0.269 acc:90.11\n",
            "Epoch:0443 train loss:0.274 acc:89.90 | val loss:0.268 acc:90.11\n",
            "Epoch:0444 train loss:0.268 acc:90.01 | val loss:0.270 acc:90.32\n",
            "Epoch:0445 train loss:0.265 acc:90.15 | val loss:0.269 acc:90.40\n",
            "Epoch:0446 train loss:0.269 acc:89.82 | val loss:0.262 acc:90.62\n",
            "Epoch:0447 train loss:0.275 acc:90.18 | val loss:0.267 acc:90.43\n",
            "Epoch:0448 train loss:0.269 acc:89.97 | val loss:0.271 acc:90.22\n",
            "Epoch:0449 train loss:0.266 acc:90.15 | val loss:0.267 acc:90.52\n",
            "Epoch:0450 train loss:0.268 acc:90.12 | val loss:0.266 acc:90.46\n",
            "Epoch:0451 train loss:0.272 acc:89.78 | val loss:0.268 acc:90.46\n",
            "Epoch:0452 train loss:0.261 acc:90.43 | val loss:0.275 acc:90.21\n",
            "Epoch:0453 train loss:0.268 acc:90.07 | val loss:0.266 acc:90.36\n",
            "Epoch:0454 train loss:0.261 acc:90.42 | val loss:0.263 acc:90.60\n",
            "Epoch:0455 train loss:0.260 acc:90.40 | val loss:0.269 acc:90.32\n",
            "Epoch:0456 train loss:0.267 acc:90.24 | val loss:0.265 acc:90.49\n",
            "Epoch:0457 train loss:0.261 acc:89.96 | val loss:0.264 acc:90.43\n",
            "Epoch:0458 train loss:0.265 acc:90.34 | val loss:0.267 acc:90.46\n",
            "Epoch:0459 train loss:0.261 acc:90.28 | val loss:0.271 acc:90.41\n",
            "Epoch:0460 train loss:0.267 acc:90.23 | val loss:0.265 acc:90.60\n",
            "Epoch:0461 train loss:0.263 acc:90.43 | val loss:0.265 acc:90.54\n",
            "Epoch:0462 train loss:0.268 acc:90.15 | val loss:0.273 acc:90.41\n",
            "Epoch:0463 train loss:0.260 acc:90.39 | val loss:0.266 acc:90.36\n",
            "Epoch:0464 train loss:0.260 acc:90.53 | val loss:0.263 acc:90.57\n",
            "Epoch:0465 train loss:0.261 acc:90.34 | val loss:0.268 acc:90.38\n",
            "Epoch:0466 train loss:0.258 acc:90.16 | val loss:0.267 acc:90.54\n",
            "Epoch:0467 train loss:0.254 acc:90.42 | val loss:0.266 acc:90.30\n",
            "Epoch:0468 train loss:0.258 acc:90.21 | val loss:0.269 acc:90.25\n",
            "Epoch:0469 train loss:0.255 acc:90.54 | val loss:0.267 acc:90.54\n",
            "Epoch:0470 train loss:0.257 acc:90.46 | val loss:0.265 acc:90.67\n",
            "Epoch:0471 train loss:0.260 acc:90.59 | val loss:0.266 acc:90.63\n",
            "Epoch:0472 train loss:0.260 acc:90.23 | val loss:0.265 acc:90.62\n",
            "Epoch:0473 train loss:0.263 acc:90.20 | val loss:0.265 acc:90.63\n",
            "Epoch:0474 train loss:0.261 acc:90.30 | val loss:0.264 acc:90.68\n",
            "Epoch:0475 train loss:0.255 acc:90.42 | val loss:0.263 acc:90.70\n",
            "Epoch:0476 train loss:0.256 acc:90.75 | val loss:0.268 acc:90.48\n",
            "Epoch:0477 train loss:0.263 acc:90.37 | val loss:0.264 acc:90.59\n",
            "Epoch:0478 train loss:0.261 acc:90.28 | val loss:0.264 acc:90.73\n",
            "Epoch:0479 train loss:0.261 acc:90.76 | val loss:0.268 acc:90.48\n",
            "Epoch:0480 train loss:0.262 acc:90.51 | val loss:0.266 acc:90.46\n",
            "Epoch:0481 train loss:0.258 acc:90.45 | val loss:0.269 acc:90.24\n",
            "Epoch:0482 train loss:0.259 acc:90.37 | val loss:0.267 acc:90.57\n",
            "Epoch:0483 train loss:0.263 acc:90.39 | val loss:0.265 acc:90.65\n",
            "Epoch:0484 train loss:0.257 acc:90.40 | val loss:0.267 acc:90.65\n",
            "Epoch:0485 train loss:0.258 acc:90.53 | val loss:0.269 acc:90.36\n",
            "Epoch:0486 train loss:0.257 acc:90.31 | val loss:0.267 acc:90.62\n",
            "Epoch:0487 train loss:0.255 acc:90.61 | val loss:0.267 acc:90.51\n",
            "Epoch:0488 train loss:0.255 acc:90.61 | val loss:0.264 acc:90.60\n",
            "Epoch:0489 train loss:0.266 acc:90.14 | val loss:0.275 acc:90.19\n",
            "Epoch:0490 train loss:0.254 acc:90.52 | val loss:0.277 acc:89.67\n",
            "Epoch:0491 train loss:0.267 acc:90.03 | val loss:0.266 acc:90.33\n",
            "Epoch:0492 train loss:0.263 acc:90.10 | val loss:0.264 acc:90.57\n",
            "Epoch:0493 train loss:0.251 acc:90.96 | val loss:0.281 acc:90.05\n",
            "Epoch:0494 train loss:0.267 acc:89.98 | val loss:0.266 acc:90.36\n",
            "Epoch:0495 train loss:0.258 acc:90.64 | val loss:0.276 acc:89.97\n",
            "Epoch:0496 train loss:0.259 acc:90.27 | val loss:0.282 acc:89.79\n",
            "4 : 89.88\n",
            "Epoch:0001 train loss:1.097 acc:38.98 | val loss:1.089 acc:38.91\n",
            "Epoch:0002 train loss:1.089 acc:39.13 | val loss:1.079 acc:38.91\n",
            "Epoch:0003 train loss:1.080 acc:39.23 | val loss:1.065 acc:38.91\n",
            "Epoch:0004 train loss:1.066 acc:40.01 | val loss:1.049 acc:38.91\n",
            "Epoch:0005 train loss:1.053 acc:40.02 | val loss:1.039 acc:38.91\n",
            "Epoch:0006 train loss:1.046 acc:41.12 | val loss:1.032 acc:39.06\n",
            "Epoch:0007 train loss:1.041 acc:42.66 | val loss:1.020 acc:57.31\n",
            "Epoch:0008 train loss:1.030 acc:46.97 | val loss:1.009 acc:64.36\n",
            "Epoch:0009 train loss:1.016 acc:48.92 | val loss:0.997 acc:64.07\n",
            "Epoch:0010 train loss:1.005 acc:51.60 | val loss:0.982 acc:62.35\n",
            "Epoch:0011 train loss:0.990 acc:54.01 | val loss:0.963 acc:59.33\n",
            "Epoch:0012 train loss:0.971 acc:55.67 | val loss:0.939 acc:56.13\n",
            "Epoch:0013 train loss:0.949 acc:54.99 | val loss:0.912 acc:53.99\n",
            "Epoch:0014 train loss:0.926 acc:53.62 | val loss:0.885 acc:53.66\n",
            "Epoch:0015 train loss:0.897 acc:53.71 | val loss:0.858 acc:55.67\n",
            "Epoch:0016 train loss:0.878 acc:55.36 | val loss:0.833 acc:60.05\n",
            "Epoch:0017 train loss:0.848 acc:58.70 | val loss:0.808 acc:61.71\n",
            "Epoch:0018 train loss:0.826 acc:59.91 | val loss:0.778 acc:62.16\n",
            "Epoch:0019 train loss:0.804 acc:59.99 | val loss:0.752 acc:62.36\n",
            "Epoch:0020 train loss:0.778 acc:61.59 | val loss:0.732 acc:63.04\n",
            "Epoch:0021 train loss:0.752 acc:63.43 | val loss:0.713 acc:64.03\n",
            "Epoch:0022 train loss:0.749 acc:64.01 | val loss:0.702 acc:63.41\n",
            "Epoch:0023 train loss:0.736 acc:64.70 | val loss:0.664 acc:65.56\n",
            "Epoch:0024 train loss:0.698 acc:67.85 | val loss:0.649 acc:71.66\n",
            "Epoch:0025 train loss:0.696 acc:69.49 | val loss:0.627 acc:76.78\n",
            "Epoch:0026 train loss:0.666 acc:71.09 | val loss:0.605 acc:78.59\n",
            "Epoch:0027 train loss:0.644 acc:73.45 | val loss:0.583 acc:79.64\n",
            "Epoch:0028 train loss:0.620 acc:74.73 | val loss:0.565 acc:80.41\n",
            "Epoch:0029 train loss:0.611 acc:76.28 | val loss:0.548 acc:81.11\n",
            "Epoch:0030 train loss:0.594 acc:77.70 | val loss:0.535 acc:81.39\n",
            "Epoch:0031 train loss:0.576 acc:79.91 | val loss:0.526 acc:81.30\n",
            "Epoch:0032 train loss:0.577 acc:79.86 | val loss:0.517 acc:81.70\n",
            "Epoch:0033 train loss:0.552 acc:80.94 | val loss:0.503 acc:81.82\n",
            "Epoch:0034 train loss:0.550 acc:80.57 | val loss:0.495 acc:81.84\n",
            "Epoch:0035 train loss:0.533 acc:81.50 | val loss:0.485 acc:82.03\n",
            "Epoch:0036 train loss:0.531 acc:81.23 | val loss:0.475 acc:82.20\n",
            "Epoch:0037 train loss:0.519 acc:82.43 | val loss:0.468 acc:82.46\n",
            "Epoch:0038 train loss:0.515 acc:82.38 | val loss:0.461 acc:82.63\n",
            "Epoch:0039 train loss:0.504 acc:82.47 | val loss:0.453 acc:83.23\n",
            "Epoch:0040 train loss:0.489 acc:82.97 | val loss:0.442 acc:83.47\n",
            "Epoch:0041 train loss:0.484 acc:82.73 | val loss:0.435 acc:83.95\n",
            "Epoch:0042 train loss:0.477 acc:83.84 | val loss:0.431 acc:84.12\n",
            "Epoch:0043 train loss:0.471 acc:83.42 | val loss:0.424 acc:84.41\n",
            "Epoch:0044 train loss:0.466 acc:83.65 | val loss:0.418 acc:84.69\n",
            "Epoch:0045 train loss:0.456 acc:83.68 | val loss:0.415 acc:84.79\n",
            "Epoch:0046 train loss:0.455 acc:84.14 | val loss:0.423 acc:84.33\n",
            "Epoch:0047 train loss:0.452 acc:83.87 | val loss:0.414 acc:84.55\n",
            "Epoch:0048 train loss:0.433 acc:84.20 | val loss:0.409 acc:84.69\n",
            "Epoch:0049 train loss:0.441 acc:84.21 | val loss:0.402 acc:84.96\n",
            "Epoch:0050 train loss:0.431 acc:84.71 | val loss:0.411 acc:84.61\n",
            "Epoch:0051 train loss:0.443 acc:84.33 | val loss:0.400 acc:85.06\n",
            "Epoch:0052 train loss:0.431 acc:85.02 | val loss:0.402 acc:84.75\n",
            "Epoch:0053 train loss:0.442 acc:84.41 | val loss:0.399 acc:84.85\n",
            "Epoch:0054 train loss:0.423 acc:85.07 | val loss:0.400 acc:84.98\n",
            "Epoch:0055 train loss:0.426 acc:84.42 | val loss:0.388 acc:85.40\n",
            "Epoch:0056 train loss:0.412 acc:85.49 | val loss:0.388 acc:85.40\n",
            "Epoch:0057 train loss:0.423 acc:85.47 | val loss:0.381 acc:85.69\n",
            "Epoch:0058 train loss:0.412 acc:85.33 | val loss:0.385 acc:85.56\n",
            "Epoch:0059 train loss:0.414 acc:85.45 | val loss:0.384 acc:85.55\n",
            "Epoch:0060 train loss:0.403 acc:85.54 | val loss:0.378 acc:85.67\n",
            "Epoch:0061 train loss:0.401 acc:85.88 | val loss:0.379 acc:85.59\n",
            "Epoch:0062 train loss:0.409 acc:85.80 | val loss:0.373 acc:85.86\n",
            "Epoch:0063 train loss:0.404 acc:85.90 | val loss:0.375 acc:86.02\n",
            "Epoch:0064 train loss:0.401 acc:86.10 | val loss:0.373 acc:86.18\n",
            "Epoch:0065 train loss:0.406 acc:85.65 | val loss:0.368 acc:86.12\n",
            "Epoch:0066 train loss:0.395 acc:86.22 | val loss:0.370 acc:86.05\n",
            "Epoch:0067 train loss:0.403 acc:85.77 | val loss:0.368 acc:85.99\n",
            "Epoch:0068 train loss:0.394 acc:86.21 | val loss:0.371 acc:86.29\n",
            "Epoch:0069 train loss:0.388 acc:85.99 | val loss:0.366 acc:86.45\n",
            "Epoch:0070 train loss:0.386 acc:86.83 | val loss:0.360 acc:86.37\n",
            "Epoch:0071 train loss:0.387 acc:86.89 | val loss:0.359 acc:86.42\n",
            "Epoch:0072 train loss:0.382 acc:86.72 | val loss:0.356 acc:86.53\n",
            "Epoch:0073 train loss:0.384 acc:86.72 | val loss:0.359 acc:86.59\n",
            "Epoch:0074 train loss:0.381 acc:86.89 | val loss:0.357 acc:86.69\n",
            "Epoch:0075 train loss:0.379 acc:86.70 | val loss:0.356 acc:86.47\n",
            "Epoch:0076 train loss:0.382 acc:86.38 | val loss:0.354 acc:86.64\n",
            "Epoch:0077 train loss:0.375 acc:86.90 | val loss:0.353 acc:86.70\n",
            "Epoch:0078 train loss:0.374 acc:86.49 | val loss:0.351 acc:86.77\n",
            "Epoch:0079 train loss:0.374 acc:86.73 | val loss:0.348 acc:86.89\n",
            "Epoch:0080 train loss:0.368 acc:87.02 | val loss:0.348 acc:86.91\n",
            "Epoch:0081 train loss:0.374 acc:86.97 | val loss:0.349 acc:86.80\n",
            "Epoch:0082 train loss:0.370 acc:86.90 | val loss:0.349 acc:86.89\n",
            "Epoch:0083 train loss:0.369 acc:86.92 | val loss:0.348 acc:86.85\n",
            "Epoch:0084 train loss:0.369 acc:87.10 | val loss:0.346 acc:86.96\n",
            "Epoch:0085 train loss:0.371 acc:86.48 | val loss:0.345 acc:86.91\n",
            "Epoch:0086 train loss:0.365 acc:87.09 | val loss:0.345 acc:87.02\n",
            "Epoch:0087 train loss:0.370 acc:86.86 | val loss:0.343 acc:87.04\n",
            "Epoch:0088 train loss:0.363 acc:86.94 | val loss:0.342 acc:87.15\n",
            "Epoch:0089 train loss:0.360 acc:87.14 | val loss:0.341 acc:87.15\n",
            "Epoch:0090 train loss:0.363 acc:87.01 | val loss:0.344 acc:87.05\n",
            "Epoch:0091 train loss:0.356 acc:86.94 | val loss:0.345 acc:87.04\n",
            "Epoch:0092 train loss:0.366 acc:87.18 | val loss:0.340 acc:87.04\n",
            "Epoch:0093 train loss:0.359 acc:87.51 | val loss:0.338 acc:87.08\n",
            "Epoch:0094 train loss:0.361 acc:87.13 | val loss:0.336 acc:87.35\n",
            "Epoch:0095 train loss:0.349 acc:87.78 | val loss:0.338 acc:87.48\n",
            "Epoch:0096 train loss:0.351 acc:87.31 | val loss:0.335 acc:87.42\n",
            "Epoch:0097 train loss:0.356 acc:87.27 | val loss:0.335 acc:87.39\n",
            "Epoch:0098 train loss:0.356 acc:87.46 | val loss:0.336 acc:87.21\n",
            "Epoch:0099 train loss:0.349 acc:87.41 | val loss:0.340 acc:87.29\n",
            "Epoch:0100 train loss:0.354 acc:87.38 | val loss:0.335 acc:87.34\n",
            "Epoch:0101 train loss:0.351 acc:87.57 | val loss:0.333 acc:87.46\n",
            "Epoch:0102 train loss:0.357 acc:87.28 | val loss:0.331 acc:87.59\n",
            "Epoch:0103 train loss:0.352 acc:87.35 | val loss:0.334 acc:87.54\n",
            "Epoch:0104 train loss:0.350 acc:87.49 | val loss:0.330 acc:87.56\n",
            "Epoch:0105 train loss:0.342 acc:87.88 | val loss:0.330 acc:87.51\n",
            "Epoch:0106 train loss:0.354 acc:87.19 | val loss:0.328 acc:87.77\n",
            "Epoch:0107 train loss:0.350 acc:87.79 | val loss:0.330 acc:87.64\n",
            "Epoch:0108 train loss:0.345 acc:87.85 | val loss:0.327 acc:87.73\n",
            "Epoch:0109 train loss:0.345 acc:87.65 | val loss:0.325 acc:87.94\n",
            "Epoch:0110 train loss:0.338 acc:87.91 | val loss:0.325 acc:87.86\n",
            "Epoch:0111 train loss:0.347 acc:87.65 | val loss:0.326 acc:87.73\n",
            "Epoch:0112 train loss:0.341 acc:87.75 | val loss:0.325 acc:87.94\n",
            "Epoch:0113 train loss:0.345 acc:87.76 | val loss:0.325 acc:87.88\n",
            "Epoch:0114 train loss:0.344 acc:87.86 | val loss:0.327 acc:87.73\n",
            "Epoch:0115 train loss:0.342 acc:88.06 | val loss:0.326 acc:87.72\n",
            "Epoch:0116 train loss:0.338 acc:88.01 | val loss:0.323 acc:87.88\n",
            "Epoch:0117 train loss:0.345 acc:87.61 | val loss:0.321 acc:88.00\n",
            "Epoch:0118 train loss:0.347 acc:87.89 | val loss:0.324 acc:87.64\n",
            "Epoch:0119 train loss:0.347 acc:87.57 | val loss:0.319 acc:88.00\n",
            "Epoch:0120 train loss:0.342 acc:87.77 | val loss:0.320 acc:87.92\n",
            "Epoch:0121 train loss:0.340 acc:87.88 | val loss:0.320 acc:88.00\n",
            "Epoch:0122 train loss:0.339 acc:87.90 | val loss:0.321 acc:87.89\n",
            "Epoch:0123 train loss:0.341 acc:87.65 | val loss:0.317 acc:88.13\n",
            "Epoch:0124 train loss:0.337 acc:87.85 | val loss:0.317 acc:88.13\n",
            "Epoch:0125 train loss:0.336 acc:88.05 | val loss:0.318 acc:88.10\n",
            "Epoch:0126 train loss:0.333 acc:87.95 | val loss:0.323 acc:87.77\n",
            "Epoch:0127 train loss:0.340 acc:87.85 | val loss:0.319 acc:88.00\n",
            "Epoch:0128 train loss:0.336 acc:87.85 | val loss:0.319 acc:88.03\n",
            "Epoch:0129 train loss:0.340 acc:87.86 | val loss:0.321 acc:87.97\n",
            "Epoch:0130 train loss:0.335 acc:87.87 | val loss:0.321 acc:87.92\n",
            "Epoch:0131 train loss:0.337 acc:88.03 | val loss:0.316 acc:88.07\n",
            "Epoch:0132 train loss:0.336 acc:87.85 | val loss:0.314 acc:88.07\n",
            "Epoch:0133 train loss:0.333 acc:88.16 | val loss:0.315 acc:88.21\n",
            "Epoch:0134 train loss:0.339 acc:87.53 | val loss:0.312 acc:88.23\n",
            "Epoch:0135 train loss:0.331 acc:88.37 | val loss:0.310 acc:88.30\n",
            "Epoch:0136 train loss:0.336 acc:88.11 | val loss:0.311 acc:88.29\n",
            "Epoch:0137 train loss:0.337 acc:87.89 | val loss:0.315 acc:88.19\n",
            "Epoch:0138 train loss:0.336 acc:88.07 | val loss:0.312 acc:88.23\n",
            "Epoch:0139 train loss:0.332 acc:88.12 | val loss:0.313 acc:88.24\n",
            "Epoch:0140 train loss:0.332 acc:88.22 | val loss:0.313 acc:88.19\n",
            "Epoch:0141 train loss:0.329 acc:88.32 | val loss:0.319 acc:88.03\n",
            "Epoch:0142 train loss:0.336 acc:87.97 | val loss:0.313 acc:88.19\n",
            "Epoch:0143 train loss:0.322 acc:88.57 | val loss:0.313 acc:88.29\n",
            "Epoch:0144 train loss:0.339 acc:88.33 | val loss:0.313 acc:88.13\n",
            "Epoch:0145 train loss:0.328 acc:88.25 | val loss:0.314 acc:88.11\n",
            "Epoch:0146 train loss:0.335 acc:88.19 | val loss:0.310 acc:88.38\n",
            "Epoch:0147 train loss:0.331 acc:88.10 | val loss:0.307 acc:88.38\n",
            "Epoch:0148 train loss:0.324 acc:88.40 | val loss:0.312 acc:88.15\n",
            "Epoch:0149 train loss:0.328 acc:88.09 | val loss:0.307 acc:88.32\n",
            "Epoch:0150 train loss:0.331 acc:88.31 | val loss:0.308 acc:88.48\n",
            "Epoch:0151 train loss:0.326 acc:88.12 | val loss:0.307 acc:88.35\n",
            "Epoch:0152 train loss:0.331 acc:88.19 | val loss:0.313 acc:88.11\n",
            "Epoch:0153 train loss:0.328 acc:88.09 | val loss:0.311 acc:88.08\n",
            "Epoch:0154 train loss:0.327 acc:87.98 | val loss:0.312 acc:88.19\n",
            "Epoch:0155 train loss:0.332 acc:88.41 | val loss:0.311 acc:88.08\n",
            "Epoch:0156 train loss:0.325 acc:88.37 | val loss:0.313 acc:88.16\n",
            "Epoch:0157 train loss:0.325 acc:88.38 | val loss:0.307 acc:88.46\n",
            "Epoch:0158 train loss:0.326 acc:88.29 | val loss:0.307 acc:88.61\n",
            "Epoch:0159 train loss:0.321 acc:88.63 | val loss:0.309 acc:88.26\n",
            "Epoch:0160 train loss:0.326 acc:88.12 | val loss:0.307 acc:88.37\n",
            "Epoch:0161 train loss:0.319 acc:88.38 | val loss:0.305 acc:88.51\n",
            "Epoch:0162 train loss:0.314 acc:88.88 | val loss:0.307 acc:88.61\n",
            "Epoch:0163 train loss:0.319 acc:88.40 | val loss:0.309 acc:88.26\n",
            "Epoch:0164 train loss:0.324 acc:88.27 | val loss:0.313 acc:88.10\n",
            "Epoch:0165 train loss:0.321 acc:88.42 | val loss:0.307 acc:88.48\n",
            "Epoch:0166 train loss:0.322 acc:88.87 | val loss:0.309 acc:88.29\n",
            "Epoch:0167 train loss:0.326 acc:88.00 | val loss:0.311 acc:88.21\n",
            "Epoch:0168 train loss:0.313 acc:88.94 | val loss:0.310 acc:88.26\n",
            "Epoch:0169 train loss:0.329 acc:88.34 | val loss:0.306 acc:88.64\n",
            "Epoch:0170 train loss:0.321 acc:88.62 | val loss:0.305 acc:88.49\n",
            "Epoch:0171 train loss:0.320 acc:88.54 | val loss:0.311 acc:88.21\n",
            "Epoch:0172 train loss:0.321 acc:88.26 | val loss:0.312 acc:88.15\n",
            "Epoch:0173 train loss:0.325 acc:88.25 | val loss:0.303 acc:88.45\n",
            "Epoch:0174 train loss:0.319 acc:88.44 | val loss:0.305 acc:88.59\n",
            "Epoch:0175 train loss:0.325 acc:88.50 | val loss:0.303 acc:88.48\n",
            "Epoch:0176 train loss:0.318 acc:88.42 | val loss:0.306 acc:88.45\n",
            "Epoch:0177 train loss:0.317 acc:88.50 | val loss:0.301 acc:88.73\n",
            "Epoch:0178 train loss:0.325 acc:88.40 | val loss:0.302 acc:88.68\n",
            "Epoch:0179 train loss:0.317 acc:88.91 | val loss:0.301 acc:88.61\n",
            "Epoch:0180 train loss:0.313 acc:88.99 | val loss:0.306 acc:88.49\n",
            "Epoch:0181 train loss:0.319 acc:88.63 | val loss:0.301 acc:88.64\n",
            "Epoch:0182 train loss:0.317 acc:88.27 | val loss:0.301 acc:88.64\n",
            "Epoch:0183 train loss:0.322 acc:88.58 | val loss:0.300 acc:88.61\n",
            "Epoch:0184 train loss:0.322 acc:88.43 | val loss:0.306 acc:88.48\n",
            "Epoch:0185 train loss:0.319 acc:88.21 | val loss:0.301 acc:88.62\n",
            "Epoch:0186 train loss:0.319 acc:88.56 | val loss:0.296 acc:88.84\n",
            "Epoch:0187 train loss:0.315 acc:89.03 | val loss:0.296 acc:88.91\n",
            "Epoch:0188 train loss:0.314 acc:88.62 | val loss:0.299 acc:88.68\n",
            "Epoch:0189 train loss:0.308 acc:89.14 | val loss:0.309 acc:88.45\n",
            "Epoch:0190 train loss:0.323 acc:88.38 | val loss:0.301 acc:88.75\n",
            "Epoch:0191 train loss:0.308 acc:88.95 | val loss:0.304 acc:88.80\n",
            "Epoch:0192 train loss:0.321 acc:88.28 | val loss:0.298 acc:88.87\n",
            "Epoch:0193 train loss:0.317 acc:88.52 | val loss:0.304 acc:88.68\n",
            "Epoch:0194 train loss:0.311 acc:88.71 | val loss:0.295 acc:88.81\n",
            "Epoch:0195 train loss:0.308 acc:89.06 | val loss:0.295 acc:88.81\n",
            "Epoch:0196 train loss:0.314 acc:88.71 | val loss:0.293 acc:88.97\n",
            "Epoch:0197 train loss:0.317 acc:88.77 | val loss:0.297 acc:88.78\n",
            "Epoch:0198 train loss:0.308 acc:88.87 | val loss:0.299 acc:88.72\n",
            "Epoch:0199 train loss:0.317 acc:88.57 | val loss:0.295 acc:88.83\n",
            "Epoch:0200 train loss:0.306 acc:89.33 | val loss:0.295 acc:88.81\n",
            "Epoch:0201 train loss:0.314 acc:88.52 | val loss:0.296 acc:88.83\n",
            "Epoch:0202 train loss:0.307 acc:89.19 | val loss:0.300 acc:88.65\n",
            "Epoch:0203 train loss:0.307 acc:88.85 | val loss:0.297 acc:88.73\n",
            "Epoch:0204 train loss:0.306 acc:88.98 | val loss:0.297 acc:88.99\n",
            "Epoch:0205 train loss:0.312 acc:88.85 | val loss:0.294 acc:88.99\n",
            "Epoch:0206 train loss:0.299 acc:89.37 | val loss:0.295 acc:88.86\n",
            "Epoch:0207 train loss:0.306 acc:89.34 | val loss:0.296 acc:88.89\n",
            "Epoch:0208 train loss:0.311 acc:88.76 | val loss:0.295 acc:88.97\n",
            "Epoch:0209 train loss:0.309 acc:88.74 | val loss:0.295 acc:88.99\n",
            "Epoch:0210 train loss:0.309 acc:89.05 | val loss:0.294 acc:88.97\n",
            "Epoch:0211 train loss:0.305 acc:88.82 | val loss:0.293 acc:88.91\n",
            "Epoch:0212 train loss:0.312 acc:88.85 | val loss:0.291 acc:88.97\n",
            "Epoch:0213 train loss:0.307 acc:89.13 | val loss:0.292 acc:89.03\n",
            "Epoch:0214 train loss:0.308 acc:88.62 | val loss:0.297 acc:88.80\n",
            "Epoch:0215 train loss:0.313 acc:88.60 | val loss:0.298 acc:88.81\n",
            "Epoch:0216 train loss:0.304 acc:88.97 | val loss:0.294 acc:88.94\n",
            "Epoch:0217 train loss:0.305 acc:88.81 | val loss:0.293 acc:88.91\n",
            "Epoch:0218 train loss:0.307 acc:89.17 | val loss:0.295 acc:88.84\n",
            "Epoch:0219 train loss:0.307 acc:88.91 | val loss:0.298 acc:88.76\n",
            "Epoch:0220 train loss:0.308 acc:88.69 | val loss:0.294 acc:88.81\n",
            "Epoch:0221 train loss:0.309 acc:88.88 | val loss:0.293 acc:88.83\n",
            "Epoch:0222 train loss:0.310 acc:88.47 | val loss:0.291 acc:88.89\n",
            "Epoch:0223 train loss:0.300 acc:89.19 | val loss:0.292 acc:88.83\n",
            "Epoch:0224 train loss:0.304 acc:89.16 | val loss:0.291 acc:88.95\n",
            "Epoch:0225 train loss:0.303 acc:88.91 | val loss:0.294 acc:88.83\n",
            "Epoch:0226 train loss:0.305 acc:88.89 | val loss:0.294 acc:88.76\n",
            "Epoch:0227 train loss:0.301 acc:89.01 | val loss:0.295 acc:88.76\n",
            "Epoch:0228 train loss:0.297 acc:89.33 | val loss:0.293 acc:88.92\n",
            "Epoch:0229 train loss:0.299 acc:89.12 | val loss:0.290 acc:89.10\n",
            "Epoch:0230 train loss:0.301 acc:89.18 | val loss:0.292 acc:89.06\n",
            "Epoch:0231 train loss:0.293 acc:89.41 | val loss:0.295 acc:88.80\n",
            "Epoch:0232 train loss:0.307 acc:89.14 | val loss:0.292 acc:88.97\n",
            "Epoch:0233 train loss:0.296 acc:89.42 | val loss:0.290 acc:89.06\n",
            "Epoch:0234 train loss:0.299 acc:89.23 | val loss:0.289 acc:89.11\n",
            "Epoch:0235 train loss:0.299 acc:89.32 | val loss:0.291 acc:88.84\n",
            "Epoch:0236 train loss:0.299 acc:89.07 | val loss:0.292 acc:88.87\n",
            "Epoch:0237 train loss:0.300 acc:89.55 | val loss:0.291 acc:89.16\n",
            "Epoch:0238 train loss:0.295 acc:89.30 | val loss:0.289 acc:89.00\n",
            "Epoch:0239 train loss:0.300 acc:89.36 | val loss:0.292 acc:88.81\n",
            "Epoch:0240 train loss:0.305 acc:88.80 | val loss:0.289 acc:89.10\n",
            "Epoch:0241 train loss:0.299 acc:89.38 | val loss:0.289 acc:89.03\n",
            "Epoch:0242 train loss:0.303 acc:89.26 | val loss:0.292 acc:88.80\n",
            "Epoch:0243 train loss:0.305 acc:89.20 | val loss:0.299 acc:88.65\n",
            "Epoch:0244 train loss:0.294 acc:89.32 | val loss:0.288 acc:89.22\n",
            "Epoch:0245 train loss:0.293 acc:89.89 | val loss:0.287 acc:89.33\n",
            "Epoch:0246 train loss:0.301 acc:88.95 | val loss:0.290 acc:89.03\n",
            "Epoch:0247 train loss:0.301 acc:89.08 | val loss:0.289 acc:88.99\n",
            "Epoch:0248 train loss:0.296 acc:89.62 | val loss:0.291 acc:88.99\n",
            "Epoch:0249 train loss:0.295 acc:89.41 | val loss:0.291 acc:88.99\n",
            "Epoch:0250 train loss:0.293 acc:89.31 | val loss:0.290 acc:88.89\n",
            "Epoch:0251 train loss:0.301 acc:89.03 | val loss:0.287 acc:89.05\n",
            "Epoch:0252 train loss:0.296 acc:89.31 | val loss:0.287 acc:89.35\n",
            "Epoch:0253 train loss:0.293 acc:89.54 | val loss:0.288 acc:89.26\n",
            "Epoch:0254 train loss:0.291 acc:89.75 | val loss:0.297 acc:88.73\n",
            "Epoch:0255 train loss:0.300 acc:89.20 | val loss:0.291 acc:89.02\n",
            "Epoch:0256 train loss:0.295 acc:89.07 | val loss:0.288 acc:89.26\n",
            "Epoch:0257 train loss:0.291 acc:89.31 | val loss:0.287 acc:89.19\n",
            "Epoch:0258 train loss:0.298 acc:89.16 | val loss:0.289 acc:89.14\n",
            "Epoch:0259 train loss:0.298 acc:89.27 | val loss:0.289 acc:89.14\n",
            "Epoch:0260 train loss:0.295 acc:89.45 | val loss:0.289 acc:89.19\n",
            "Epoch:0261 train loss:0.297 acc:89.57 | val loss:0.287 acc:89.24\n",
            "Epoch:0262 train loss:0.294 acc:89.08 | val loss:0.289 acc:89.08\n",
            "Epoch:0263 train loss:0.296 acc:89.01 | val loss:0.285 acc:89.29\n",
            "Epoch:0264 train loss:0.286 acc:89.77 | val loss:0.287 acc:89.21\n",
            "Epoch:0265 train loss:0.292 acc:89.37 | val loss:0.288 acc:89.21\n",
            "Epoch:0266 train loss:0.287 acc:89.61 | val loss:0.292 acc:89.05\n",
            "Epoch:0267 train loss:0.291 acc:89.44 | val loss:0.288 acc:89.26\n",
            "Epoch:0268 train loss:0.291 acc:89.63 | val loss:0.287 acc:89.41\n",
            "Epoch:0269 train loss:0.295 acc:89.40 | val loss:0.287 acc:89.18\n",
            "Epoch:0270 train loss:0.291 acc:89.44 | val loss:0.287 acc:89.22\n",
            "Epoch:0271 train loss:0.290 acc:89.77 | val loss:0.288 acc:89.14\n",
            "Epoch:0272 train loss:0.291 acc:89.17 | val loss:0.285 acc:89.33\n",
            "Epoch:0273 train loss:0.286 acc:89.95 | val loss:0.288 acc:89.22\n",
            "Epoch:0274 train loss:0.297 acc:89.67 | val loss:0.284 acc:89.35\n",
            "Epoch:0275 train loss:0.290 acc:89.73 | val loss:0.289 acc:89.08\n",
            "Epoch:0276 train loss:0.295 acc:89.17 | val loss:0.291 acc:88.99\n",
            "Epoch:0277 train loss:0.302 acc:89.02 | val loss:0.292 acc:88.99\n",
            "Epoch:0278 train loss:0.289 acc:89.38 | val loss:0.286 acc:89.33\n",
            "Epoch:0279 train loss:0.289 acc:89.44 | val loss:0.287 acc:89.41\n",
            "Epoch:0280 train loss:0.287 acc:89.58 | val loss:0.287 acc:89.33\n",
            "Epoch:0281 train loss:0.292 acc:89.91 | val loss:0.287 acc:89.37\n",
            "Epoch:0282 train loss:0.297 acc:89.37 | val loss:0.288 acc:89.14\n",
            "Epoch:0283 train loss:0.288 acc:89.76 | val loss:0.284 acc:89.45\n",
            "Epoch:0284 train loss:0.283 acc:89.73 | val loss:0.286 acc:89.32\n",
            "Epoch:0285 train loss:0.285 acc:89.51 | val loss:0.284 acc:89.35\n",
            "Epoch:0286 train loss:0.284 acc:89.64 | val loss:0.286 acc:89.38\n",
            "Epoch:0287 train loss:0.285 acc:89.44 | val loss:0.287 acc:89.27\n",
            "Epoch:0288 train loss:0.284 acc:89.68 | val loss:0.289 acc:89.21\n",
            "Epoch:0289 train loss:0.294 acc:89.49 | val loss:0.287 acc:89.38\n",
            "Epoch:0290 train loss:0.288 acc:89.25 | val loss:0.285 acc:89.54\n",
            "Epoch:0291 train loss:0.288 acc:89.58 | val loss:0.290 acc:89.03\n",
            "Epoch:0292 train loss:0.296 acc:89.23 | val loss:0.282 acc:89.62\n",
            "Epoch:0293 train loss:0.285 acc:89.80 | val loss:0.290 acc:89.30\n",
            "Epoch:0294 train loss:0.291 acc:89.44 | val loss:0.286 acc:89.46\n",
            "Epoch:0295 train loss:0.286 acc:89.83 | val loss:0.297 acc:88.80\n",
            "Epoch:0296 train loss:0.298 acc:89.23 | val loss:0.284 acc:89.67\n",
            "Epoch:0297 train loss:0.294 acc:89.53 | val loss:0.291 acc:89.27\n",
            "Epoch:0298 train loss:0.295 acc:89.24 | val loss:0.290 acc:89.21\n",
            "Epoch:0299 train loss:0.285 acc:89.55 | val loss:0.296 acc:88.86\n",
            "Epoch:0300 train loss:0.298 acc:88.86 | val loss:0.282 acc:89.56\n",
            "Epoch:0301 train loss:0.277 acc:89.98 | val loss:0.290 acc:89.18\n",
            "Epoch:0302 train loss:0.305 acc:89.02 | val loss:0.283 acc:89.32\n",
            "Epoch:0303 train loss:0.292 acc:89.58 | val loss:0.292 acc:89.06\n",
            "Epoch:0304 train loss:0.288 acc:89.79 | val loss:0.284 acc:89.46\n",
            "Epoch:0305 train loss:0.292 acc:89.36 | val loss:0.287 acc:89.29\n",
            "Epoch:0306 train loss:0.283 acc:89.86 | val loss:0.281 acc:89.68\n",
            "Epoch:0307 train loss:0.285 acc:89.73 | val loss:0.289 acc:89.13\n",
            "Epoch:0308 train loss:0.288 acc:89.61 | val loss:0.285 acc:89.54\n",
            "Epoch:0309 train loss:0.283 acc:89.86 | val loss:0.288 acc:89.21\n",
            "Epoch:0310 train loss:0.286 acc:89.28 | val loss:0.283 acc:89.51\n",
            "Epoch:0311 train loss:0.287 acc:89.75 | val loss:0.286 acc:89.33\n",
            "Epoch:0312 train loss:0.289 acc:89.69 | val loss:0.284 acc:89.49\n",
            "Epoch:0313 train loss:0.287 acc:89.73 | val loss:0.280 acc:89.64\n",
            "Epoch:0314 train loss:0.282 acc:89.72 | val loss:0.286 acc:89.37\n",
            "Epoch:0315 train loss:0.285 acc:89.84 | val loss:0.286 acc:89.22\n",
            "Epoch:0316 train loss:0.288 acc:89.84 | val loss:0.289 acc:89.29\n",
            "Epoch:0317 train loss:0.285 acc:89.53 | val loss:0.281 acc:89.46\n",
            "Epoch:0318 train loss:0.275 acc:89.99 | val loss:0.284 acc:89.57\n",
            "Epoch:0319 train loss:0.282 acc:89.81 | val loss:0.285 acc:89.46\n",
            "Epoch:0320 train loss:0.284 acc:89.87 | val loss:0.292 acc:89.06\n",
            "Epoch:0321 train loss:0.286 acc:89.64 | val loss:0.285 acc:89.40\n",
            "Epoch:0322 train loss:0.284 acc:89.45 | val loss:0.280 acc:89.87\n",
            "Epoch:0323 train loss:0.280 acc:90.14 | val loss:0.280 acc:89.71\n",
            "Epoch:0324 train loss:0.277 acc:89.91 | val loss:0.282 acc:89.57\n",
            "Epoch:0325 train loss:0.275 acc:90.05 | val loss:0.289 acc:89.24\n",
            "Epoch:0326 train loss:0.284 acc:89.75 | val loss:0.288 acc:89.26\n",
            "Epoch:0327 train loss:0.279 acc:89.97 | val loss:0.285 acc:89.60\n",
            "Epoch:0328 train loss:0.278 acc:89.94 | val loss:0.282 acc:89.64\n",
            "Epoch:0329 train loss:0.280 acc:89.87 | val loss:0.286 acc:89.40\n",
            "Epoch:0330 train loss:0.278 acc:90.05 | val loss:0.283 acc:89.49\n",
            "Epoch:0331 train loss:0.275 acc:89.93 | val loss:0.283 acc:89.54\n",
            "Epoch:0332 train loss:0.280 acc:89.76 | val loss:0.280 acc:89.57\n",
            "Epoch:0333 train loss:0.280 acc:89.86 | val loss:0.281 acc:89.62\n",
            "Epoch:0334 train loss:0.278 acc:90.28 | val loss:0.286 acc:89.32\n",
            "Epoch:0335 train loss:0.286 acc:89.88 | val loss:0.285 acc:89.51\n",
            "Epoch:0336 train loss:0.280 acc:89.92 | val loss:0.288 acc:89.32\n",
            "Epoch:0337 train loss:0.280 acc:89.82 | val loss:0.281 acc:89.70\n",
            "Epoch:0338 train loss:0.283 acc:89.63 | val loss:0.284 acc:89.51\n",
            "Epoch:0339 train loss:0.276 acc:89.60 | val loss:0.281 acc:89.65\n",
            "Epoch:0340 train loss:0.284 acc:89.64 | val loss:0.286 acc:89.27\n",
            "Epoch:0341 train loss:0.286 acc:89.51 | val loss:0.284 acc:89.48\n",
            "Epoch:0342 train loss:0.277 acc:90.31 | val loss:0.284 acc:89.57\n",
            "Epoch:0343 train loss:0.279 acc:89.88 | val loss:0.280 acc:89.67\n",
            "Epoch:0344 train loss:0.271 acc:90.16 | val loss:0.278 acc:89.79\n",
            "Epoch:0345 train loss:0.280 acc:89.99 | val loss:0.281 acc:89.70\n",
            "Epoch:0346 train loss:0.277 acc:90.01 | val loss:0.287 acc:89.43\n",
            "Epoch:0347 train loss:0.285 acc:89.68 | val loss:0.286 acc:89.59\n",
            "Epoch:0348 train loss:0.277 acc:89.90 | val loss:0.281 acc:89.86\n",
            "Epoch:0349 train loss:0.277 acc:89.82 | val loss:0.278 acc:89.79\n",
            "Epoch:0350 train loss:0.265 acc:90.18 | val loss:0.279 acc:89.75\n",
            "Epoch:0351 train loss:0.282 acc:89.76 | val loss:0.279 acc:89.78\n",
            "Epoch:0352 train loss:0.277 acc:89.89 | val loss:0.281 acc:89.68\n",
            "Epoch:0353 train loss:0.277 acc:89.76 | val loss:0.283 acc:89.56\n",
            "Epoch:0354 train loss:0.269 acc:90.44 | val loss:0.282 acc:89.64\n",
            "Epoch:0355 train loss:0.268 acc:89.92 | val loss:0.280 acc:89.83\n",
            "Epoch:0356 train loss:0.278 acc:89.99 | val loss:0.279 acc:89.89\n",
            "Epoch:0357 train loss:0.276 acc:90.14 | val loss:0.279 acc:89.87\n",
            "Epoch:0358 train loss:0.275 acc:90.20 | val loss:0.283 acc:89.56\n",
            "Epoch:0359 train loss:0.273 acc:90.17 | val loss:0.283 acc:89.59\n",
            "Epoch:0360 train loss:0.280 acc:89.78 | val loss:0.280 acc:89.83\n",
            "Epoch:0361 train loss:0.274 acc:90.28 | val loss:0.279 acc:89.84\n",
            "Epoch:0362 train loss:0.269 acc:90.49 | val loss:0.282 acc:89.87\n",
            "Epoch:0363 train loss:0.275 acc:90.13 | val loss:0.286 acc:89.60\n",
            "Epoch:0364 train loss:0.276 acc:90.36 | val loss:0.285 acc:89.64\n",
            "Epoch:0365 train loss:0.270 acc:90.32 | val loss:0.281 acc:89.87\n",
            "Epoch:0366 train loss:0.274 acc:89.98 | val loss:0.279 acc:89.81\n",
            "Epoch:0367 train loss:0.272 acc:90.03 | val loss:0.280 acc:89.75\n",
            "Epoch:0368 train loss:0.267 acc:90.21 | val loss:0.279 acc:89.73\n",
            "Epoch:0369 train loss:0.270 acc:90.54 | val loss:0.280 acc:89.62\n",
            "Epoch:0370 train loss:0.275 acc:89.89 | val loss:0.280 acc:89.75\n",
            "Epoch:0371 train loss:0.278 acc:90.00 | val loss:0.281 acc:89.81\n",
            "Epoch:0372 train loss:0.275 acc:90.11 | val loss:0.281 acc:89.87\n",
            "Epoch:0373 train loss:0.273 acc:90.16 | val loss:0.284 acc:89.71\n",
            "Epoch:0374 train loss:0.277 acc:89.83 | val loss:0.285 acc:89.62\n",
            "Epoch:0375 train loss:0.271 acc:90.23 | val loss:0.282 acc:89.64\n",
            "Epoch:0376 train loss:0.272 acc:90.31 | val loss:0.279 acc:89.78\n",
            "Epoch:0377 train loss:0.268 acc:90.30 | val loss:0.278 acc:89.78\n",
            "Epoch:0378 train loss:0.271 acc:89.82 | val loss:0.278 acc:89.78\n",
            "Epoch:0379 train loss:0.268 acc:89.96 | val loss:0.277 acc:89.76\n",
            "Epoch:0380 train loss:0.268 acc:90.17 | val loss:0.280 acc:89.81\n",
            "Epoch:0381 train loss:0.270 acc:90.27 | val loss:0.285 acc:89.52\n",
            "Epoch:0382 train loss:0.272 acc:90.11 | val loss:0.283 acc:89.62\n",
            "Epoch:0383 train loss:0.271 acc:90.13 | val loss:0.279 acc:89.95\n",
            "Epoch:0384 train loss:0.273 acc:90.06 | val loss:0.277 acc:89.90\n",
            "Epoch:0385 train loss:0.271 acc:90.16 | val loss:0.280 acc:89.56\n",
            "Epoch:0386 train loss:0.273 acc:89.99 | val loss:0.283 acc:89.26\n",
            "Epoch:0387 train loss:0.271 acc:90.14 | val loss:0.283 acc:89.41\n",
            "Epoch:0388 train loss:0.278 acc:89.84 | val loss:0.277 acc:89.60\n",
            "Epoch:0389 train loss:0.267 acc:90.33 | val loss:0.281 acc:89.52\n",
            "Epoch:0390 train loss:0.276 acc:89.91 | val loss:0.276 acc:89.87\n",
            "Epoch:0391 train loss:0.269 acc:90.12 | val loss:0.280 acc:89.79\n",
            "Epoch:0392 train loss:0.271 acc:90.42 | val loss:0.286 acc:89.40\n",
            "Epoch:0393 train loss:0.274 acc:89.63 | val loss:0.283 acc:89.43\n",
            "Epoch:0394 train loss:0.268 acc:90.00 | val loss:0.280 acc:89.71\n",
            "Epoch:0395 train loss:0.264 acc:90.47 | val loss:0.278 acc:89.97\n",
            "Epoch:0396 train loss:0.259 acc:90.81 | val loss:0.283 acc:89.60\n",
            "Epoch:0397 train loss:0.277 acc:89.81 | val loss:0.279 acc:89.81\n",
            "Epoch:0398 train loss:0.266 acc:90.24 | val loss:0.283 acc:89.54\n",
            "Epoch:0399 train loss:0.275 acc:89.87 | val loss:0.282 acc:89.40\n",
            "Epoch:0400 train loss:0.264 acc:90.61 | val loss:0.280 acc:89.59\n",
            "Epoch:0401 train loss:0.268 acc:90.37 | val loss:0.276 acc:89.86\n",
            "Epoch:0402 train loss:0.270 acc:90.09 | val loss:0.276 acc:89.84\n",
            "Epoch:0403 train loss:0.275 acc:90.21 | val loss:0.281 acc:89.52\n",
            "Epoch:0404 train loss:0.266 acc:90.49 | val loss:0.283 acc:89.43\n",
            "Epoch:0405 train loss:0.263 acc:90.31 | val loss:0.283 acc:89.62\n",
            "Epoch:0406 train loss:0.269 acc:90.26 | val loss:0.280 acc:89.75\n",
            "Epoch:0407 train loss:0.268 acc:90.51 | val loss:0.282 acc:89.57\n",
            "Epoch:0408 train loss:0.267 acc:90.25 | val loss:0.277 acc:89.79\n",
            "Epoch:0409 train loss:0.272 acc:90.29 | val loss:0.278 acc:89.79\n",
            "Epoch:0410 train loss:0.263 acc:90.36 | val loss:0.278 acc:89.64\n",
            "Epoch:0411 train loss:0.272 acc:90.49 | val loss:0.279 acc:89.68\n",
            "Epoch:0412 train loss:0.265 acc:90.51 | val loss:0.280 acc:89.68\n",
            "Epoch:0413 train loss:0.272 acc:90.21 | val loss:0.279 acc:89.79\n",
            "Epoch:0414 train loss:0.268 acc:90.31 | val loss:0.281 acc:89.73\n",
            "Epoch:0415 train loss:0.267 acc:90.30 | val loss:0.282 acc:89.71\n",
            "Epoch:0416 train loss:0.264 acc:90.35 | val loss:0.280 acc:89.75\n",
            "Epoch:0417 train loss:0.270 acc:90.09 | val loss:0.278 acc:89.62\n",
            "Epoch:0418 train loss:0.269 acc:90.31 | val loss:0.278 acc:89.59\n",
            "Epoch:0419 train loss:0.267 acc:90.19 | val loss:0.277 acc:89.73\n",
            "Epoch:0420 train loss:0.265 acc:90.33 | val loss:0.282 acc:89.51\n",
            "Epoch:0421 train loss:0.264 acc:90.39 | val loss:0.285 acc:89.38\n",
            "Epoch:0422 train loss:0.267 acc:90.33 | val loss:0.281 acc:89.60\n",
            "Epoch:0423 train loss:0.271 acc:90.07 | val loss:0.276 acc:89.89\n",
            "Epoch:0424 train loss:0.266 acc:90.52 | val loss:0.276 acc:89.83\n",
            "Epoch:0425 train loss:0.262 acc:90.91 | val loss:0.280 acc:89.65\n",
            "Epoch:0426 train loss:0.261 acc:90.64 | val loss:0.279 acc:89.84\n",
            "Epoch:0427 train loss:0.267 acc:90.17 | val loss:0.280 acc:89.87\n",
            "Epoch:0428 train loss:0.255 acc:90.76 | val loss:0.278 acc:90.10\n",
            "Epoch:0429 train loss:0.260 acc:90.56 | val loss:0.281 acc:89.70\n",
            "Epoch:0430 train loss:0.261 acc:90.44 | val loss:0.278 acc:90.19\n",
            "Epoch:0431 train loss:0.265 acc:90.33 | val loss:0.280 acc:89.83\n",
            "Epoch:0432 train loss:0.263 acc:90.56 | val loss:0.279 acc:89.84\n",
            "Epoch:0433 train loss:0.263 acc:90.46 | val loss:0.275 acc:89.97\n",
            "Epoch:0434 train loss:0.259 acc:90.52 | val loss:0.275 acc:90.11\n",
            "Epoch:0435 train loss:0.266 acc:90.54 | val loss:0.277 acc:89.98\n",
            "Epoch:0436 train loss:0.265 acc:90.67 | val loss:0.280 acc:89.81\n",
            "Epoch:0437 train loss:0.261 acc:90.64 | val loss:0.278 acc:89.75\n",
            "Epoch:0438 train loss:0.264 acc:90.11 | val loss:0.277 acc:89.94\n",
            "Epoch:0439 train loss:0.256 acc:90.80 | val loss:0.276 acc:89.95\n",
            "Epoch:0440 train loss:0.266 acc:90.32 | val loss:0.278 acc:89.75\n",
            "Epoch:0441 train loss:0.251 acc:90.82 | val loss:0.280 acc:89.60\n",
            "Epoch:0442 train loss:0.259 acc:90.57 | val loss:0.279 acc:89.81\n",
            "Epoch:0443 train loss:0.262 acc:90.52 | val loss:0.279 acc:89.97\n",
            "Epoch:0444 train loss:0.257 acc:90.43 | val loss:0.284 acc:89.59\n",
            "Epoch:0445 train loss:0.262 acc:90.40 | val loss:0.289 acc:89.37\n",
            "Epoch:0446 train loss:0.260 acc:90.85 | val loss:0.282 acc:89.70\n",
            "Epoch:0447 train loss:0.265 acc:90.45 | val loss:0.279 acc:89.94\n",
            "Epoch:0448 train loss:0.256 acc:90.56 | val loss:0.283 acc:89.54\n",
            "Epoch:0449 train loss:0.266 acc:90.43 | val loss:0.278 acc:89.68\n",
            "Epoch:0450 train loss:0.265 acc:90.55 | val loss:0.281 acc:89.79\n",
            "Epoch:0451 train loss:0.268 acc:90.12 | val loss:0.276 acc:89.60\n",
            "Epoch:0452 train loss:0.258 acc:90.69 | val loss:0.276 acc:89.68\n",
            "Epoch:0453 train loss:0.266 acc:90.30 | val loss:0.275 acc:89.83\n",
            "Epoch:0454 train loss:0.263 acc:90.10 | val loss:0.277 acc:89.86\n",
            "Epoch:0455 train loss:0.262 acc:90.66 | val loss:0.286 acc:89.45\n",
            "Epoch:0456 train loss:0.261 acc:90.47 | val loss:0.283 acc:89.54\n",
            "Epoch:0457 train loss:0.255 acc:91.11 | val loss:0.281 acc:89.73\n",
            "Epoch:0458 train loss:0.270 acc:90.63 | val loss:0.277 acc:89.87\n",
            "Epoch:0459 train loss:0.264 acc:90.13 | val loss:0.276 acc:89.90\n",
            "Epoch:0460 train loss:0.251 acc:90.95 | val loss:0.277 acc:89.73\n",
            "Epoch:0461 train loss:0.255 acc:90.90 | val loss:0.279 acc:89.59\n",
            "Epoch:0462 train loss:0.256 acc:90.38 | val loss:0.278 acc:89.67\n",
            "Epoch:0463 train loss:0.261 acc:90.63 | val loss:0.276 acc:89.79\n",
            "Epoch:0464 train loss:0.259 acc:90.71 | val loss:0.276 acc:89.89\n",
            "Epoch:0465 train loss:0.261 acc:90.59 | val loss:0.279 acc:89.73\n",
            "Epoch:0466 train loss:0.256 acc:90.90 | val loss:0.280 acc:89.57\n",
            "Epoch:0467 train loss:0.263 acc:90.57 | val loss:0.280 acc:89.70\n",
            "Epoch:0468 train loss:0.258 acc:90.48 | val loss:0.276 acc:89.90\n",
            "Epoch:0469 train loss:0.256 acc:90.61 | val loss:0.283 acc:89.64\n",
            "Epoch:0470 train loss:0.259 acc:90.61 | val loss:0.275 acc:89.71\n",
            "Epoch:0471 train loss:0.253 acc:91.13 | val loss:0.280 acc:89.73\n",
            "Epoch:0472 train loss:0.268 acc:89.91 | val loss:0.278 acc:89.65\n",
            "Epoch:0473 train loss:0.260 acc:90.55 | val loss:0.275 acc:89.83\n",
            "Epoch:0474 train loss:0.263 acc:90.14 | val loss:0.277 acc:89.78\n",
            "Epoch:0475 train loss:0.262 acc:90.48 | val loss:0.276 acc:89.76\n",
            "Epoch:0476 train loss:0.260 acc:90.55 | val loss:0.288 acc:89.45\n",
            "Epoch:0477 train loss:0.272 acc:90.48 | val loss:0.276 acc:89.87\n",
            "Epoch:0478 train loss:0.253 acc:90.93 | val loss:0.288 acc:89.73\n",
            "Epoch:0479 train loss:0.275 acc:89.81 | val loss:0.287 acc:89.45\n",
            "Epoch:0480 train loss:0.261 acc:90.74 | val loss:0.293 acc:89.10\n",
            "Epoch:0481 train loss:0.273 acc:90.25 | val loss:0.275 acc:89.78\n",
            "Epoch:0482 train loss:0.263 acc:90.26 | val loss:0.279 acc:89.94\n",
            "Epoch:0483 train loss:0.271 acc:89.97 | val loss:0.276 acc:89.65\n",
            "Epoch:0484 train loss:0.264 acc:90.63 | val loss:0.286 acc:89.40\n",
            "Epoch:0485 train loss:0.263 acc:90.56 | val loss:0.283 acc:89.62\n",
            "Epoch:0486 train loss:0.260 acc:90.48 | val loss:0.280 acc:89.75\n",
            "Epoch:0487 train loss:0.258 acc:90.57 | val loss:0.275 acc:89.76\n",
            "Epoch:0488 train loss:0.257 acc:90.71 | val loss:0.280 acc:89.68\n",
            "Epoch:0489 train loss:0.268 acc:90.30 | val loss:0.273 acc:89.95\n",
            "Epoch:0490 train loss:0.256 acc:90.33 | val loss:0.279 acc:89.65\n",
            "Epoch:0491 train loss:0.263 acc:90.21 | val loss:0.280 acc:89.64\n",
            "Epoch:0492 train loss:0.257 acc:90.98 | val loss:0.280 acc:89.52\n",
            "Epoch:0493 train loss:0.254 acc:90.90 | val loss:0.274 acc:89.87\n",
            "Epoch:0494 train loss:0.261 acc:90.63 | val loss:0.275 acc:90.02\n",
            "Epoch:0495 train loss:0.260 acc:90.52 | val loss:0.276 acc:89.68\n",
            "Epoch:0496 train loss:0.254 acc:90.57 | val loss:0.285 acc:89.48\n",
            "Epoch:0497 train loss:0.263 acc:90.54 | val loss:0.280 acc:89.62\n",
            "Epoch:0498 train loss:0.256 acc:90.79 | val loss:0.276 acc:89.97\n",
            "Epoch:0499 train loss:0.257 acc:90.79 | val loss:0.274 acc:90.06\n",
            "Epoch:0500 train loss:0.261 acc:90.62 | val loss:0.278 acc:89.81\n",
            "Epoch:0501 train loss:0.257 acc:90.53 | val loss:0.282 acc:89.62\n",
            "Epoch:0502 train loss:0.260 acc:90.27 | val loss:0.283 acc:89.64\n",
            "Epoch:0503 train loss:0.261 acc:90.32 | val loss:0.278 acc:89.83\n",
            "Epoch:0504 train loss:0.259 acc:90.52 | val loss:0.273 acc:89.86\n",
            "Epoch:0505 train loss:0.251 acc:90.73 | val loss:0.275 acc:89.83\n",
            "Epoch:0506 train loss:0.253 acc:90.67 | val loss:0.274 acc:89.92\n",
            "Epoch:0507 train loss:0.256 acc:90.57 | val loss:0.279 acc:89.78\n",
            "Epoch:0508 train loss:0.249 acc:91.02 | val loss:0.281 acc:89.76\n",
            "Epoch:0509 train loss:0.251 acc:90.65 | val loss:0.282 acc:89.71\n",
            "Epoch:0510 train loss:0.256 acc:90.72 | val loss:0.277 acc:89.92\n",
            "Epoch:0511 train loss:0.255 acc:90.47 | val loss:0.275 acc:90.11\n",
            "Epoch:0512 train loss:0.248 acc:90.79 | val loss:0.274 acc:89.86\n",
            "Epoch:0513 train loss:0.250 acc:90.99 | val loss:0.278 acc:89.73\n",
            "Epoch:0514 train loss:0.252 acc:91.05 | val loss:0.279 acc:89.81\n",
            "Epoch:0515 train loss:0.255 acc:90.66 | val loss:0.278 acc:89.79\n",
            "Epoch:0516 train loss:0.251 acc:91.01 | val loss:0.276 acc:89.78\n",
            "Epoch:0517 train loss:0.256 acc:90.91 | val loss:0.278 acc:89.79\n",
            "Epoch:0518 train loss:0.252 acc:90.79 | val loss:0.281 acc:89.57\n",
            "Epoch:0519 train loss:0.254 acc:90.98 | val loss:0.281 acc:89.62\n",
            "Epoch:0520 train loss:0.250 acc:90.98 | val loss:0.280 acc:89.65\n",
            "Epoch:0521 train loss:0.254 acc:90.94 | val loss:0.275 acc:89.62\n",
            "Epoch:0522 train loss:0.251 acc:90.99 | val loss:0.273 acc:89.92\n",
            "Epoch:0523 train loss:0.245 acc:91.13 | val loss:0.274 acc:89.81\n",
            "Epoch:0524 train loss:0.255 acc:90.91 | val loss:0.280 acc:89.51\n",
            "Epoch:0525 train loss:0.254 acc:90.77 | val loss:0.283 acc:89.54\n",
            "Epoch:0526 train loss:0.247 acc:90.99 | val loss:0.277 acc:89.89\n",
            "Epoch:0527 train loss:0.256 acc:90.73 | val loss:0.277 acc:89.78\n",
            "Epoch:0528 train loss:0.260 acc:90.25 | val loss:0.275 acc:90.00\n",
            "Epoch:0529 train loss:0.251 acc:91.05 | val loss:0.277 acc:89.73\n",
            "Epoch:0530 train loss:0.251 acc:90.73 | val loss:0.281 acc:89.54\n",
            "Epoch:0531 train loss:0.254 acc:90.90 | val loss:0.284 acc:89.32\n",
            "Epoch:0532 train loss:0.258 acc:90.16 | val loss:0.274 acc:89.76\n",
            "Epoch:0533 train loss:0.252 acc:90.92 | val loss:0.273 acc:90.00\n",
            "Epoch:0534 train loss:0.247 acc:91.08 | val loss:0.274 acc:90.03\n",
            "Epoch:0535 train loss:0.251 acc:91.02 | val loss:0.278 acc:89.62\n",
            "Epoch:0536 train loss:0.248 acc:91.33 | val loss:0.281 acc:89.71\n",
            "Epoch:0537 train loss:0.248 acc:91.36 | val loss:0.281 acc:89.70\n",
            "Epoch:0538 train loss:0.250 acc:91.09 | val loss:0.277 acc:89.95\n",
            "Epoch:0539 train loss:0.247 acc:91.07 | val loss:0.275 acc:89.97\n",
            "Epoch:0540 train loss:0.247 acc:90.96 | val loss:0.275 acc:89.78\n",
            "Epoch:0541 train loss:0.247 acc:90.73 | val loss:0.280 acc:89.62\n",
            "Epoch:0542 train loss:0.243 acc:91.44 | val loss:0.283 acc:89.52\n",
            "Epoch:0543 train loss:0.252 acc:90.99 | val loss:0.278 acc:89.56\n",
            "Epoch:0544 train loss:0.254 acc:90.81 | val loss:0.275 acc:89.92\n",
            "Epoch:0545 train loss:0.253 acc:90.68 | val loss:0.274 acc:89.92\n",
            "Epoch:0546 train loss:0.250 acc:91.01 | val loss:0.277 acc:89.78\n",
            "Epoch:0547 train loss:0.249 acc:90.68 | val loss:0.280 acc:89.65\n",
            "Epoch:0548 train loss:0.249 acc:91.18 | val loss:0.280 acc:89.65\n",
            "Epoch:0549 train loss:0.245 acc:91.23 | val loss:0.275 acc:89.59\n",
            "Epoch:0550 train loss:0.245 acc:91.21 | val loss:0.273 acc:89.79\n",
            "Epoch:0551 train loss:0.250 acc:90.91 | val loss:0.274 acc:89.78\n",
            "Epoch:0552 train loss:0.245 acc:91.02 | val loss:0.277 acc:89.67\n",
            "Epoch:0553 train loss:0.244 acc:91.00 | val loss:0.283 acc:89.51\n",
            "Epoch:0554 train loss:0.248 acc:90.69 | val loss:0.280 acc:89.68\n",
            "Epoch:0555 train loss:0.246 acc:91.25 | val loss:0.276 acc:89.95\n",
            "Epoch:0556 train loss:0.250 acc:90.99 | val loss:0.277 acc:89.78\n",
            "Epoch:0557 train loss:0.250 acc:90.94 | val loss:0.276 acc:89.65\n",
            "Epoch:0558 train loss:0.240 acc:91.27 | val loss:0.279 acc:89.87\n",
            "Epoch:0559 train loss:0.251 acc:90.76 | val loss:0.279 acc:89.57\n",
            "Epoch:0560 train loss:0.246 acc:91.00 | val loss:0.283 acc:89.57\n",
            "Epoch:0561 train loss:0.251 acc:90.71 | val loss:0.277 acc:89.76\n",
            "Epoch:0562 train loss:0.243 acc:91.07 | val loss:0.274 acc:89.84\n",
            "Epoch:0563 train loss:0.244 acc:91.36 | val loss:0.273 acc:89.87\n",
            "Epoch:0564 train loss:0.249 acc:90.86 | val loss:0.276 acc:89.76\n",
            "Epoch:0565 train loss:0.248 acc:91.13 | val loss:0.279 acc:89.67\n",
            "Epoch:0566 train loss:0.247 acc:91.12 | val loss:0.278 acc:89.78\n",
            "Epoch:0567 train loss:0.251 acc:90.90 | val loss:0.278 acc:89.79\n",
            "Epoch:0568 train loss:0.240 acc:91.17 | val loss:0.278 acc:89.84\n",
            "Epoch:0569 train loss:0.246 acc:90.99 | val loss:0.277 acc:89.89\n",
            "Epoch:0570 train loss:0.250 acc:91.17 | val loss:0.275 acc:89.86\n",
            "Epoch:0571 train loss:0.243 acc:91.48 | val loss:0.276 acc:89.84\n",
            "Epoch:0572 train loss:0.249 acc:90.93 | val loss:0.275 acc:89.87\n",
            "5 : 90.47\n",
            "Epoch:0001 train loss:1.115 acc:28.27 | val loss:1.103 acc:39.16\n",
            "Epoch:0002 train loss:1.104 acc:39.17 | val loss:1.093 acc:39.16\n",
            "Epoch:0003 train loss:1.093 acc:39.17 | val loss:1.079 acc:39.18\n",
            "Epoch:0004 train loss:1.079 acc:39.50 | val loss:1.062 acc:40.82\n",
            "Epoch:0005 train loss:1.063 acc:40.61 | val loss:1.047 acc:42.87\n",
            "Epoch:0006 train loss:1.045 acc:43.99 | val loss:1.046 acc:51.35\n",
            "Epoch:0007 train loss:1.048 acc:43.19 | val loss:1.036 acc:54.82\n",
            "Epoch:0008 train loss:1.041 acc:44.85 | val loss:1.021 acc:54.79\n",
            "Epoch:0009 train loss:1.024 acc:47.23 | val loss:1.008 acc:54.93\n",
            "Epoch:0010 train loss:1.008 acc:49.86 | val loss:0.996 acc:56.21\n",
            "Epoch:0011 train loss:0.998 acc:51.81 | val loss:0.981 acc:58.80\n",
            "Epoch:0012 train loss:0.983 acc:55.17 | val loss:0.961 acc:61.27\n",
            "Epoch:0013 train loss:0.962 acc:57.96 | val loss:0.936 acc:62.96\n",
            "Epoch:0014 train loss:0.942 acc:59.26 | val loss:0.906 acc:64.31\n",
            "Epoch:0015 train loss:0.916 acc:59.96 | val loss:0.872 acc:64.25\n",
            "Epoch:0016 train loss:0.880 acc:61.02 | val loss:0.836 acc:64.22\n",
            "Epoch:0017 train loss:0.849 acc:61.57 | val loss:0.797 acc:64.36\n",
            "Epoch:0018 train loss:0.813 acc:62.31 | val loss:0.758 acc:64.75\n",
            "Epoch:0019 train loss:0.780 acc:62.89 | val loss:0.720 acc:64.48\n",
            "Epoch:0020 train loss:0.750 acc:64.26 | val loss:0.689 acc:65.56\n",
            "Epoch:0021 train loss:0.711 acc:65.52 | val loss:0.657 acc:66.20\n",
            "Epoch:0022 train loss:0.686 acc:67.33 | val loss:0.631 acc:67.37\n",
            "Epoch:0023 train loss:0.664 acc:68.47 | val loss:0.611 acc:70.92\n",
            "Epoch:0024 train loss:0.641 acc:71.28 | val loss:0.609 acc:74.25\n",
            "Epoch:0025 train loss:0.643 acc:71.66 | val loss:0.616 acc:78.73\n",
            "Epoch:0026 train loss:0.657 acc:74.12 | val loss:0.578 acc:80.82\n",
            "Epoch:0027 train loss:0.613 acc:76.72 | val loss:0.576 acc:80.86\n",
            "Epoch:0028 train loss:0.614 acc:76.83 | val loss:0.553 acc:81.63\n",
            "Epoch:0029 train loss:0.590 acc:78.85 | val loss:0.545 acc:81.87\n",
            "Epoch:0030 train loss:0.572 acc:79.70 | val loss:0.549 acc:81.60\n",
            "Epoch:0031 train loss:0.582 acc:79.92 | val loss:0.529 acc:82.39\n",
            "Epoch:0032 train loss:0.557 acc:80.69 | val loss:0.526 acc:82.73\n",
            "Epoch:0033 train loss:0.549 acc:81.37 | val loss:0.516 acc:83.03\n",
            "Epoch:0034 train loss:0.547 acc:81.78 | val loss:0.502 acc:82.85\n",
            "Epoch:0035 train loss:0.532 acc:81.77 | val loss:0.499 acc:82.66\n",
            "Epoch:0036 train loss:0.536 acc:81.86 | val loss:0.489 acc:82.92\n",
            "Epoch:0037 train loss:0.526 acc:82.13 | val loss:0.474 acc:83.45\n",
            "Epoch:0038 train loss:0.518 acc:82.75 | val loss:0.471 acc:84.18\n",
            "Epoch:0039 train loss:0.521 acc:81.97 | val loss:0.459 acc:84.31\n",
            "Epoch:0040 train loss:0.499 acc:82.90 | val loss:0.451 acc:83.87\n",
            "Epoch:0041 train loss:0.499 acc:82.48 | val loss:0.447 acc:83.88\n",
            "Epoch:0042 train loss:0.493 acc:82.69 | val loss:0.436 acc:84.12\n",
            "Epoch:0043 train loss:0.484 acc:82.54 | val loss:0.433 acc:84.66\n",
            "Epoch:0044 train loss:0.476 acc:83.14 | val loss:0.428 acc:84.90\n",
            "Epoch:0045 train loss:0.480 acc:83.02 | val loss:0.425 acc:84.39\n",
            "Epoch:0046 train loss:0.471 acc:83.31 | val loss:0.425 acc:84.44\n",
            "Epoch:0047 train loss:0.465 acc:83.30 | val loss:0.417 acc:84.77\n",
            "Epoch:0048 train loss:0.469 acc:83.00 | val loss:0.414 acc:84.99\n",
            "Epoch:0049 train loss:0.461 acc:83.47 | val loss:0.412 acc:85.13\n",
            "Epoch:0050 train loss:0.460 acc:83.62 | val loss:0.406 acc:85.23\n",
            "Epoch:0051 train loss:0.452 acc:83.94 | val loss:0.404 acc:85.17\n",
            "Epoch:0052 train loss:0.453 acc:84.10 | val loss:0.401 acc:85.32\n",
            "Epoch:0053 train loss:0.448 acc:84.40 | val loss:0.397 acc:85.59\n",
            "Epoch:0054 train loss:0.439 acc:84.85 | val loss:0.395 acc:85.75\n",
            "Epoch:0055 train loss:0.435 acc:84.46 | val loss:0.392 acc:85.83\n",
            "Epoch:0056 train loss:0.439 acc:84.52 | val loss:0.388 acc:85.97\n",
            "Epoch:0057 train loss:0.426 acc:84.56 | val loss:0.386 acc:85.99\n",
            "Epoch:0058 train loss:0.432 acc:84.30 | val loss:0.384 acc:85.94\n",
            "Epoch:0059 train loss:0.424 acc:85.11 | val loss:0.381 acc:86.10\n",
            "Epoch:0060 train loss:0.427 acc:84.58 | val loss:0.378 acc:86.26\n",
            "Epoch:0061 train loss:0.419 acc:85.71 | val loss:0.376 acc:86.32\n",
            "Epoch:0062 train loss:0.421 acc:85.53 | val loss:0.373 acc:86.42\n",
            "Epoch:0063 train loss:0.421 acc:85.04 | val loss:0.371 acc:86.47\n",
            "Epoch:0064 train loss:0.412 acc:85.10 | val loss:0.369 acc:86.53\n",
            "Epoch:0065 train loss:0.413 acc:85.33 | val loss:0.367 acc:86.62\n",
            "Epoch:0066 train loss:0.406 acc:85.70 | val loss:0.366 acc:86.66\n",
            "Epoch:0067 train loss:0.403 acc:86.15 | val loss:0.364 acc:86.85\n",
            "Epoch:0068 train loss:0.407 acc:85.53 | val loss:0.362 acc:86.86\n",
            "Epoch:0069 train loss:0.403 acc:85.62 | val loss:0.360 acc:86.96\n",
            "Epoch:0070 train loss:0.397 acc:85.82 | val loss:0.359 acc:87.05\n",
            "Epoch:0071 train loss:0.400 acc:86.09 | val loss:0.357 acc:87.00\n",
            "Epoch:0072 train loss:0.396 acc:86.20 | val loss:0.355 acc:87.12\n",
            "Epoch:0073 train loss:0.392 acc:86.15 | val loss:0.354 acc:87.24\n",
            "Epoch:0074 train loss:0.397 acc:85.87 | val loss:0.352 acc:87.23\n",
            "Epoch:0075 train loss:0.392 acc:85.96 | val loss:0.351 acc:87.31\n",
            "Epoch:0076 train loss:0.389 acc:85.91 | val loss:0.350 acc:87.39\n",
            "Epoch:0077 train loss:0.388 acc:86.05 | val loss:0.348 acc:87.39\n",
            "Epoch:0078 train loss:0.383 acc:86.34 | val loss:0.347 acc:87.43\n",
            "Epoch:0079 train loss:0.380 acc:86.05 | val loss:0.346 acc:87.64\n",
            "Epoch:0080 train loss:0.385 acc:86.07 | val loss:0.345 acc:87.67\n",
            "Epoch:0081 train loss:0.387 acc:86.27 | val loss:0.343 acc:87.77\n",
            "Epoch:0082 train loss:0.379 acc:86.23 | val loss:0.342 acc:87.72\n",
            "Epoch:0083 train loss:0.382 acc:86.46 | val loss:0.340 acc:87.88\n",
            "Epoch:0084 train loss:0.376 acc:86.81 | val loss:0.339 acc:87.75\n",
            "Epoch:0085 train loss:0.380 acc:86.25 | val loss:0.338 acc:87.69\n",
            "Epoch:0086 train loss:0.377 acc:86.46 | val loss:0.337 acc:87.86\n",
            "Epoch:0087 train loss:0.379 acc:86.59 | val loss:0.336 acc:88.08\n",
            "Epoch:0088 train loss:0.377 acc:86.05 | val loss:0.336 acc:88.16\n",
            "Epoch:0089 train loss:0.378 acc:86.92 | val loss:0.335 acc:88.16\n",
            "Epoch:0090 train loss:0.374 acc:86.66 | val loss:0.333 acc:88.13\n",
            "Epoch:0091 train loss:0.370 acc:86.54 | val loss:0.333 acc:87.99\n",
            "Epoch:0092 train loss:0.365 acc:86.66 | val loss:0.332 acc:87.99\n",
            "Epoch:0093 train loss:0.368 acc:86.93 | val loss:0.332 acc:88.18\n",
            "Epoch:0094 train loss:0.365 acc:86.71 | val loss:0.331 acc:88.23\n",
            "Epoch:0095 train loss:0.367 acc:86.80 | val loss:0.331 acc:88.05\n",
            "Epoch:0096 train loss:0.364 acc:86.96 | val loss:0.330 acc:88.43\n",
            "Epoch:0097 train loss:0.355 acc:87.29 | val loss:0.330 acc:88.43\n",
            "Epoch:0098 train loss:0.362 acc:86.94 | val loss:0.328 acc:88.38\n",
            "Epoch:0099 train loss:0.361 acc:86.81 | val loss:0.326 acc:88.27\n",
            "Epoch:0100 train loss:0.369 acc:86.74 | val loss:0.326 acc:88.30\n",
            "Epoch:0101 train loss:0.360 acc:86.78 | val loss:0.325 acc:88.35\n",
            "Epoch:0102 train loss:0.363 acc:86.83 | val loss:0.326 acc:88.57\n",
            "Epoch:0103 train loss:0.368 acc:86.83 | val loss:0.325 acc:88.62\n",
            "Epoch:0104 train loss:0.359 acc:87.32 | val loss:0.324 acc:88.61\n",
            "Epoch:0105 train loss:0.362 acc:86.98 | val loss:0.323 acc:88.40\n",
            "Epoch:0106 train loss:0.359 acc:87.11 | val loss:0.323 acc:88.57\n",
            "Epoch:0107 train loss:0.356 acc:87.20 | val loss:0.321 acc:88.62\n",
            "Epoch:0108 train loss:0.359 acc:86.96 | val loss:0.324 acc:88.61\n",
            "Epoch:0109 train loss:0.361 acc:87.03 | val loss:0.322 acc:88.57\n",
            "Epoch:0110 train loss:0.350 acc:87.20 | val loss:0.320 acc:88.62\n",
            "Epoch:0111 train loss:0.351 acc:87.66 | val loss:0.322 acc:88.54\n",
            "Epoch:0112 train loss:0.362 acc:87.45 | val loss:0.319 acc:88.76\n",
            "Epoch:0113 train loss:0.358 acc:87.56 | val loss:0.322 acc:88.72\n",
            "Epoch:0114 train loss:0.355 acc:87.39 | val loss:0.320 acc:88.67\n",
            "Epoch:0115 train loss:0.356 acc:87.38 | val loss:0.319 acc:88.68\n",
            "Epoch:0116 train loss:0.354 acc:87.17 | val loss:0.317 acc:88.75\n",
            "Epoch:0117 train loss:0.345 acc:87.51 | val loss:0.317 acc:88.65\n",
            "Epoch:0118 train loss:0.347 acc:87.55 | val loss:0.318 acc:88.75\n",
            "Epoch:0119 train loss:0.348 acc:87.72 | val loss:0.316 acc:88.80\n",
            "Epoch:0120 train loss:0.350 acc:87.96 | val loss:0.316 acc:88.89\n",
            "Epoch:0121 train loss:0.345 acc:87.36 | val loss:0.315 acc:88.76\n",
            "Epoch:0122 train loss:0.346 acc:87.65 | val loss:0.315 acc:88.81\n",
            "Epoch:0123 train loss:0.350 acc:87.68 | val loss:0.315 acc:88.80\n",
            "Epoch:0124 train loss:0.347 acc:87.71 | val loss:0.314 acc:88.81\n",
            "Epoch:0125 train loss:0.341 acc:87.96 | val loss:0.313 acc:88.99\n",
            "Epoch:0126 train loss:0.346 acc:87.63 | val loss:0.312 acc:88.94\n",
            "Epoch:0127 train loss:0.340 acc:87.88 | val loss:0.312 acc:88.92\n",
            "Epoch:0128 train loss:0.350 acc:87.50 | val loss:0.311 acc:88.95\n",
            "Epoch:0129 train loss:0.346 acc:87.46 | val loss:0.310 acc:88.97\n",
            "Epoch:0130 train loss:0.346 acc:87.65 | val loss:0.309 acc:88.91\n",
            "Epoch:0131 train loss:0.343 acc:87.59 | val loss:0.310 acc:89.08\n",
            "Epoch:0132 train loss:0.345 acc:87.48 | val loss:0.311 acc:89.03\n",
            "Epoch:0133 train loss:0.343 acc:87.61 | val loss:0.309 acc:89.02\n",
            "Epoch:0134 train loss:0.345 acc:87.63 | val loss:0.309 acc:88.97\n",
            "Epoch:0135 train loss:0.340 acc:87.88 | val loss:0.309 acc:88.97\n",
            "Epoch:0136 train loss:0.336 acc:87.87 | val loss:0.309 acc:89.08\n",
            "Epoch:0137 train loss:0.341 acc:87.85 | val loss:0.309 acc:89.14\n",
            "Epoch:0138 train loss:0.337 acc:87.78 | val loss:0.308 acc:89.11\n",
            "Epoch:0139 train loss:0.333 acc:87.91 | val loss:0.306 acc:89.08\n",
            "Epoch:0140 train loss:0.338 acc:87.86 | val loss:0.306 acc:89.22\n",
            "Epoch:0141 train loss:0.336 acc:88.09 | val loss:0.305 acc:89.10\n",
            "Epoch:0142 train loss:0.341 acc:87.85 | val loss:0.305 acc:89.16\n",
            "Epoch:0143 train loss:0.342 acc:87.75 | val loss:0.307 acc:89.22\n",
            "Epoch:0144 train loss:0.334 acc:87.93 | val loss:0.304 acc:89.24\n",
            "Epoch:0145 train loss:0.335 acc:87.89 | val loss:0.305 acc:89.22\n",
            "Epoch:0146 train loss:0.330 acc:88.23 | val loss:0.305 acc:89.14\n",
            "Epoch:0147 train loss:0.343 acc:87.63 | val loss:0.304 acc:89.27\n",
            "Epoch:0148 train loss:0.338 acc:87.70 | val loss:0.305 acc:89.18\n",
            "Epoch:0149 train loss:0.337 acc:88.10 | val loss:0.304 acc:89.22\n",
            "Epoch:0150 train loss:0.332 acc:87.95 | val loss:0.304 acc:89.27\n",
            "Epoch:0151 train loss:0.329 acc:88.08 | val loss:0.304 acc:89.29\n",
            "Epoch:0152 train loss:0.335 acc:87.72 | val loss:0.304 acc:89.14\n",
            "Epoch:0153 train loss:0.338 acc:87.77 | val loss:0.304 acc:89.21\n",
            "Epoch:0154 train loss:0.335 acc:88.08 | val loss:0.304 acc:89.35\n",
            "Epoch:0155 train loss:0.332 acc:88.01 | val loss:0.302 acc:89.32\n",
            "Epoch:0156 train loss:0.335 acc:87.79 | val loss:0.303 acc:89.10\n",
            "Epoch:0157 train loss:0.335 acc:87.86 | val loss:0.301 acc:89.43\n",
            "Epoch:0158 train loss:0.329 acc:87.69 | val loss:0.302 acc:89.33\n",
            "Epoch:0159 train loss:0.334 acc:88.08 | val loss:0.301 acc:89.38\n",
            "Epoch:0160 train loss:0.331 acc:87.86 | val loss:0.302 acc:89.27\n",
            "Epoch:0161 train loss:0.340 acc:87.56 | val loss:0.302 acc:89.33\n",
            "Epoch:0162 train loss:0.328 acc:87.83 | val loss:0.305 acc:89.19\n",
            "Epoch:0163 train loss:0.336 acc:87.64 | val loss:0.302 acc:89.22\n",
            "Epoch:0164 train loss:0.335 acc:88.13 | val loss:0.302 acc:89.33\n",
            "Epoch:0165 train loss:0.338 acc:87.78 | val loss:0.300 acc:89.30\n",
            "Epoch:0166 train loss:0.335 acc:87.78 | val loss:0.300 acc:89.21\n",
            "Epoch:0167 train loss:0.337 acc:88.02 | val loss:0.298 acc:89.29\n",
            "Epoch:0168 train loss:0.332 acc:88.16 | val loss:0.299 acc:89.33\n",
            "Epoch:0169 train loss:0.329 acc:88.12 | val loss:0.298 acc:89.27\n",
            "Epoch:0170 train loss:0.328 acc:88.14 | val loss:0.300 acc:89.33\n",
            "Epoch:0171 train loss:0.329 acc:88.01 | val loss:0.297 acc:89.29\n",
            "Epoch:0172 train loss:0.323 acc:88.37 | val loss:0.298 acc:89.45\n",
            "Epoch:0173 train loss:0.331 acc:87.84 | val loss:0.297 acc:89.30\n",
            "Epoch:0174 train loss:0.322 acc:88.23 | val loss:0.298 acc:89.43\n",
            "Epoch:0175 train loss:0.324 acc:88.21 | val loss:0.297 acc:89.43\n",
            "Epoch:0176 train loss:0.324 acc:88.22 | val loss:0.297 acc:89.35\n",
            "Epoch:0177 train loss:0.324 acc:88.56 | val loss:0.296 acc:89.33\n",
            "Epoch:0178 train loss:0.327 acc:88.02 | val loss:0.295 acc:89.40\n",
            "Epoch:0179 train loss:0.322 acc:88.24 | val loss:0.295 acc:89.43\n",
            "Epoch:0180 train loss:0.325 acc:87.77 | val loss:0.295 acc:89.40\n",
            "Epoch:0181 train loss:0.319 acc:88.43 | val loss:0.295 acc:89.46\n",
            "Epoch:0182 train loss:0.326 acc:88.06 | val loss:0.296 acc:89.54\n",
            "Epoch:0183 train loss:0.330 acc:87.84 | val loss:0.295 acc:89.56\n",
            "Epoch:0184 train loss:0.321 acc:88.19 | val loss:0.294 acc:89.54\n",
            "Epoch:0185 train loss:0.326 acc:88.17 | val loss:0.294 acc:89.62\n",
            "Epoch:0186 train loss:0.318 acc:88.71 | val loss:0.293 acc:89.48\n",
            "Epoch:0187 train loss:0.328 acc:87.96 | val loss:0.295 acc:89.62\n",
            "Epoch:0188 train loss:0.326 acc:88.13 | val loss:0.293 acc:89.52\n",
            "Epoch:0189 train loss:0.323 acc:88.03 | val loss:0.295 acc:89.49\n",
            "Epoch:0190 train loss:0.320 acc:88.31 | val loss:0.295 acc:89.57\n",
            "Epoch:0191 train loss:0.323 acc:88.17 | val loss:0.292 acc:89.54\n",
            "Epoch:0192 train loss:0.325 acc:88.07 | val loss:0.294 acc:89.35\n",
            "Epoch:0193 train loss:0.326 acc:88.04 | val loss:0.292 acc:89.60\n",
            "Epoch:0194 train loss:0.323 acc:88.09 | val loss:0.296 acc:89.56\n",
            "Epoch:0195 train loss:0.322 acc:88.35 | val loss:0.294 acc:89.33\n",
            "Epoch:0196 train loss:0.330 acc:87.81 | val loss:0.292 acc:89.54\n",
            "Epoch:0197 train loss:0.318 acc:88.16 | val loss:0.295 acc:89.41\n",
            "Epoch:0198 train loss:0.318 acc:88.23 | val loss:0.290 acc:89.64\n",
            "Epoch:0199 train loss:0.317 acc:88.59 | val loss:0.293 acc:89.41\n",
            "Epoch:0200 train loss:0.329 acc:88.16 | val loss:0.291 acc:89.51\n",
            "Epoch:0201 train loss:0.315 acc:88.99 | val loss:0.293 acc:89.57\n",
            "Epoch:0202 train loss:0.329 acc:88.14 | val loss:0.290 acc:89.57\n",
            "Epoch:0203 train loss:0.317 acc:88.08 | val loss:0.289 acc:89.59\n",
            "Epoch:0204 train loss:0.310 acc:88.62 | val loss:0.292 acc:89.60\n",
            "Epoch:0205 train loss:0.323 acc:88.21 | val loss:0.290 acc:89.62\n",
            "Epoch:0206 train loss:0.327 acc:88.06 | val loss:0.289 acc:89.67\n",
            "Epoch:0207 train loss:0.315 acc:88.31 | val loss:0.290 acc:89.49\n",
            "Epoch:0208 train loss:0.314 acc:88.63 | val loss:0.292 acc:89.57\n",
            "Epoch:0209 train loss:0.313 acc:88.72 | val loss:0.290 acc:89.49\n",
            "Epoch:0210 train loss:0.316 acc:88.62 | val loss:0.288 acc:89.78\n",
            "Epoch:0211 train loss:0.319 acc:88.44 | val loss:0.289 acc:89.57\n",
            "Epoch:0212 train loss:0.315 acc:88.30 | val loss:0.286 acc:89.84\n",
            "Epoch:0213 train loss:0.305 acc:88.96 | val loss:0.286 acc:89.86\n",
            "Epoch:0214 train loss:0.311 acc:88.70 | val loss:0.287 acc:89.73\n",
            "Epoch:0215 train loss:0.318 acc:88.52 | val loss:0.287 acc:89.78\n",
            "Epoch:0216 train loss:0.313 acc:88.67 | val loss:0.288 acc:89.76\n",
            "Epoch:0217 train loss:0.313 acc:88.63 | val loss:0.288 acc:89.70\n",
            "Epoch:0218 train loss:0.316 acc:88.32 | val loss:0.288 acc:89.78\n",
            "Epoch:0219 train loss:0.310 acc:88.61 | val loss:0.286 acc:89.71\n",
            "Epoch:0220 train loss:0.311 acc:88.48 | val loss:0.284 acc:89.84\n",
            "Epoch:0221 train loss:0.306 acc:88.61 | val loss:0.285 acc:89.73\n",
            "Epoch:0222 train loss:0.317 acc:88.60 | val loss:0.284 acc:89.83\n",
            "Epoch:0223 train loss:0.314 acc:88.39 | val loss:0.285 acc:89.73\n",
            "Epoch:0224 train loss:0.314 acc:88.19 | val loss:0.283 acc:89.78\n",
            "Epoch:0225 train loss:0.314 acc:88.40 | val loss:0.284 acc:89.79\n",
            "Epoch:0226 train loss:0.308 acc:88.68 | val loss:0.286 acc:89.97\n",
            "Epoch:0227 train loss:0.312 acc:88.24 | val loss:0.286 acc:89.68\n",
            "Epoch:0228 train loss:0.311 acc:88.42 | val loss:0.285 acc:89.71\n",
            "Epoch:0229 train loss:0.311 acc:88.47 | val loss:0.288 acc:89.76\n",
            "Epoch:0230 train loss:0.317 acc:88.52 | val loss:0.284 acc:89.87\n",
            "Epoch:0231 train loss:0.313 acc:88.24 | val loss:0.285 acc:89.68\n",
            "Epoch:0232 train loss:0.312 acc:88.27 | val loss:0.285 acc:89.94\n",
            "Epoch:0233 train loss:0.309 acc:88.79 | val loss:0.284 acc:89.81\n",
            "Epoch:0234 train loss:0.306 acc:88.49 | val loss:0.285 acc:89.67\n",
            "Epoch:0235 train loss:0.312 acc:88.34 | val loss:0.282 acc:89.84\n",
            "Epoch:0236 train loss:0.305 acc:88.83 | val loss:0.284 acc:89.89\n",
            "Epoch:0237 train loss:0.305 acc:88.64 | val loss:0.283 acc:89.86\n",
            "Epoch:0238 train loss:0.305 acc:88.81 | val loss:0.282 acc:89.90\n",
            "Epoch:0239 train loss:0.311 acc:88.99 | val loss:0.283 acc:89.87\n",
            "Epoch:0240 train loss:0.303 acc:88.93 | val loss:0.284 acc:89.87\n",
            "Epoch:0241 train loss:0.310 acc:88.61 | val loss:0.284 acc:89.84\n",
            "Epoch:0242 train loss:0.301 acc:89.25 | val loss:0.284 acc:89.87\n",
            "Epoch:0243 train loss:0.308 acc:88.82 | val loss:0.283 acc:89.94\n",
            "Epoch:0244 train loss:0.308 acc:88.51 | val loss:0.281 acc:89.81\n",
            "Epoch:0245 train loss:0.309 acc:88.81 | val loss:0.282 acc:89.78\n",
            "Epoch:0246 train loss:0.299 acc:88.64 | val loss:0.280 acc:89.86\n",
            "Epoch:0247 train loss:0.303 acc:88.80 | val loss:0.286 acc:89.87\n",
            "Epoch:0248 train loss:0.317 acc:88.31 | val loss:0.283 acc:89.79\n",
            "Epoch:0249 train loss:0.306 acc:88.64 | val loss:0.282 acc:89.83\n",
            "Epoch:0250 train loss:0.303 acc:88.95 | val loss:0.286 acc:89.75\n",
            "Epoch:0251 train loss:0.309 acc:88.28 | val loss:0.279 acc:89.97\n",
            "Epoch:0252 train loss:0.304 acc:89.05 | val loss:0.280 acc:89.84\n",
            "Epoch:0253 train loss:0.306 acc:88.85 | val loss:0.279 acc:90.06\n",
            "Epoch:0254 train loss:0.301 acc:88.64 | val loss:0.280 acc:90.00\n",
            "Epoch:0255 train loss:0.310 acc:88.60 | val loss:0.279 acc:89.87\n",
            "Epoch:0256 train loss:0.304 acc:88.57 | val loss:0.280 acc:90.10\n",
            "Epoch:0257 train loss:0.306 acc:88.90 | val loss:0.279 acc:89.89\n",
            "Epoch:0258 train loss:0.298 acc:88.89 | val loss:0.279 acc:89.87\n",
            "Epoch:0259 train loss:0.302 acc:88.66 | val loss:0.279 acc:89.95\n",
            "Epoch:0260 train loss:0.296 acc:88.94 | val loss:0.279 acc:89.94\n",
            "Epoch:0261 train loss:0.309 acc:88.76 | val loss:0.278 acc:89.92\n",
            "Epoch:0262 train loss:0.300 acc:88.82 | val loss:0.279 acc:90.02\n",
            "Epoch:0263 train loss:0.304 acc:88.60 | val loss:0.278 acc:90.10\n",
            "Epoch:0264 train loss:0.301 acc:88.85 | val loss:0.278 acc:90.10\n",
            "Epoch:0265 train loss:0.299 acc:89.34 | val loss:0.282 acc:89.94\n",
            "Epoch:0266 train loss:0.302 acc:88.70 | val loss:0.279 acc:90.05\n",
            "Epoch:0267 train loss:0.300 acc:88.87 | val loss:0.280 acc:89.95\n",
            "Epoch:0268 train loss:0.303 acc:88.84 | val loss:0.280 acc:90.10\n",
            "Epoch:0269 train loss:0.303 acc:88.83 | val loss:0.278 acc:90.21\n",
            "Epoch:0270 train loss:0.303 acc:89.00 | val loss:0.278 acc:90.05\n",
            "Epoch:0271 train loss:0.302 acc:89.02 | val loss:0.277 acc:90.13\n",
            "Epoch:0272 train loss:0.300 acc:88.89 | val loss:0.277 acc:90.10\n",
            "Epoch:0273 train loss:0.299 acc:88.76 | val loss:0.279 acc:90.06\n",
            "Epoch:0274 train loss:0.302 acc:89.08 | val loss:0.279 acc:89.97\n",
            "Epoch:0275 train loss:0.297 acc:88.94 | val loss:0.277 acc:90.24\n",
            "Epoch:0276 train loss:0.295 acc:89.13 | val loss:0.279 acc:90.17\n",
            "Epoch:0277 train loss:0.300 acc:88.62 | val loss:0.277 acc:89.95\n",
            "Epoch:0278 train loss:0.297 acc:89.04 | val loss:0.276 acc:90.17\n",
            "Epoch:0279 train loss:0.291 acc:89.10 | val loss:0.278 acc:90.16\n",
            "Epoch:0280 train loss:0.295 acc:88.79 | val loss:0.277 acc:90.06\n",
            "Epoch:0281 train loss:0.302 acc:88.87 | val loss:0.277 acc:90.08\n",
            "Epoch:0282 train loss:0.294 acc:88.84 | val loss:0.278 acc:90.22\n",
            "Epoch:0283 train loss:0.303 acc:88.66 | val loss:0.276 acc:89.97\n",
            "Epoch:0284 train loss:0.300 acc:88.82 | val loss:0.275 acc:90.08\n",
            "Epoch:0285 train loss:0.297 acc:89.14 | val loss:0.276 acc:90.11\n",
            "Epoch:0286 train loss:0.299 acc:89.02 | val loss:0.275 acc:90.13\n",
            "Epoch:0287 train loss:0.296 acc:89.20 | val loss:0.275 acc:90.03\n",
            "Epoch:0288 train loss:0.290 acc:89.67 | val loss:0.277 acc:90.16\n",
            "Epoch:0289 train loss:0.300 acc:89.10 | val loss:0.278 acc:90.10\n",
            "Epoch:0290 train loss:0.301 acc:88.78 | val loss:0.278 acc:89.86\n",
            "Epoch:0291 train loss:0.298 acc:88.60 | val loss:0.275 acc:90.17\n",
            "Epoch:0292 train loss:0.293 acc:89.28 | val loss:0.277 acc:90.10\n",
            "Epoch:0293 train loss:0.294 acc:89.00 | val loss:0.277 acc:89.90\n",
            "Epoch:0294 train loss:0.299 acc:88.76 | val loss:0.277 acc:90.00\n",
            "Epoch:0295 train loss:0.294 acc:89.13 | val loss:0.282 acc:89.89\n",
            "Epoch:0296 train loss:0.308 acc:88.34 | val loss:0.277 acc:89.86\n",
            "Epoch:0297 train loss:0.290 acc:89.21 | val loss:0.277 acc:90.05\n",
            "Epoch:0298 train loss:0.294 acc:89.22 | val loss:0.279 acc:90.13\n",
            "Epoch:0299 train loss:0.295 acc:89.06 | val loss:0.274 acc:90.14\n",
            "Epoch:0300 train loss:0.292 acc:89.00 | val loss:0.273 acc:90.11\n",
            "Epoch:0301 train loss:0.291 acc:89.28 | val loss:0.274 acc:90.21\n",
            "Epoch:0302 train loss:0.296 acc:88.91 | val loss:0.273 acc:90.16\n",
            "Epoch:0303 train loss:0.294 acc:89.18 | val loss:0.274 acc:90.13\n",
            "Epoch:0304 train loss:0.294 acc:89.01 | val loss:0.276 acc:90.14\n",
            "Epoch:0305 train loss:0.288 acc:89.30 | val loss:0.276 acc:90.17\n",
            "Epoch:0306 train loss:0.285 acc:89.16 | val loss:0.277 acc:90.10\n",
            "Epoch:0307 train loss:0.295 acc:89.16 | val loss:0.276 acc:90.17\n",
            "Epoch:0308 train loss:0.289 acc:89.10 | val loss:0.275 acc:90.16\n",
            "Epoch:0309 train loss:0.295 acc:89.19 | val loss:0.273 acc:90.11\n",
            "Epoch:0310 train loss:0.289 acc:89.15 | val loss:0.273 acc:90.05\n",
            "Epoch:0311 train loss:0.296 acc:89.04 | val loss:0.275 acc:90.17\n",
            "Epoch:0312 train loss:0.300 acc:89.08 | val loss:0.274 acc:90.02\n",
            "Epoch:0313 train loss:0.291 acc:88.94 | val loss:0.276 acc:89.97\n",
            "Epoch:0314 train loss:0.289 acc:89.03 | val loss:0.277 acc:90.35\n",
            "Epoch:0315 train loss:0.289 acc:89.10 | val loss:0.277 acc:90.17\n",
            "Epoch:0316 train loss:0.292 acc:89.10 | val loss:0.276 acc:89.97\n",
            "Epoch:0317 train loss:0.291 acc:88.91 | val loss:0.273 acc:90.32\n",
            "Epoch:0318 train loss:0.287 acc:89.20 | val loss:0.273 acc:90.32\n",
            "Epoch:0319 train loss:0.287 acc:89.18 | val loss:0.270 acc:90.29\n",
            "Epoch:0320 train loss:0.287 acc:89.74 | val loss:0.272 acc:90.21\n",
            "Epoch:0321 train loss:0.298 acc:89.15 | val loss:0.272 acc:90.36\n",
            "Epoch:0322 train loss:0.290 acc:89.23 | val loss:0.274 acc:90.03\n",
            "Epoch:0323 train loss:0.290 acc:89.36 | val loss:0.274 acc:90.05\n",
            "Epoch:0324 train loss:0.287 acc:89.25 | val loss:0.274 acc:90.38\n",
            "Epoch:0325 train loss:0.284 acc:89.60 | val loss:0.274 acc:90.36\n",
            "Epoch:0326 train loss:0.291 acc:88.98 | val loss:0.274 acc:90.05\n",
            "Epoch:0327 train loss:0.291 acc:89.18 | val loss:0.274 acc:90.00\n",
            "Epoch:0328 train loss:0.290 acc:89.49 | val loss:0.275 acc:90.33\n",
            "Epoch:0329 train loss:0.286 acc:89.28 | val loss:0.272 acc:90.27\n",
            "Epoch:0330 train loss:0.283 acc:89.61 | val loss:0.276 acc:89.86\n",
            "Epoch:0331 train loss:0.290 acc:89.15 | val loss:0.272 acc:90.32\n",
            "Epoch:0332 train loss:0.289 acc:89.28 | val loss:0.275 acc:90.14\n",
            "Epoch:0333 train loss:0.294 acc:88.96 | val loss:0.283 acc:89.49\n",
            "Epoch:0334 train loss:0.299 acc:88.97 | val loss:0.269 acc:90.21\n",
            "Epoch:0335 train loss:0.295 acc:88.75 | val loss:0.285 acc:89.97\n",
            "Epoch:0336 train loss:0.308 acc:88.53 | val loss:0.275 acc:89.75\n",
            "Epoch:0337 train loss:0.296 acc:89.02 | val loss:0.277 acc:89.54\n",
            "Epoch:0338 train loss:0.305 acc:88.60 | val loss:0.273 acc:90.36\n",
            "Epoch:0339 train loss:0.296 acc:88.97 | val loss:0.279 acc:90.21\n",
            "Epoch:0340 train loss:0.296 acc:88.98 | val loss:0.275 acc:90.00\n",
            "Epoch:0341 train loss:0.293 acc:89.04 | val loss:0.282 acc:89.60\n",
            "Epoch:0342 train loss:0.302 acc:88.66 | val loss:0.277 acc:90.03\n",
            "Epoch:0343 train loss:0.287 acc:89.27 | val loss:0.287 acc:89.90\n",
            "Epoch:0344 train loss:0.307 acc:88.61 | val loss:0.274 acc:90.03\n",
            "Epoch:0345 train loss:0.293 acc:89.28 | val loss:0.281 acc:89.49\n",
            "Epoch:0346 train loss:0.299 acc:88.88 | val loss:0.270 acc:90.33\n",
            "Epoch:0347 train loss:0.284 acc:89.58 | val loss:0.280 acc:90.22\n",
            "Epoch:0348 train loss:0.294 acc:88.72 | val loss:0.270 acc:90.19\n",
            "Epoch:0349 train loss:0.290 acc:89.54 | val loss:0.276 acc:89.83\n",
            "Epoch:0350 train loss:0.291 acc:89.13 | val loss:0.273 acc:89.87\n",
            "Epoch:0351 train loss:0.285 acc:89.32 | val loss:0.273 acc:90.29\n",
            "Epoch:0352 train loss:0.286 acc:89.41 | val loss:0.274 acc:90.14\n",
            "Epoch:0353 train loss:0.285 acc:89.28 | val loss:0.272 acc:90.00\n",
            "Epoch:0354 train loss:0.284 acc:89.56 | val loss:0.273 acc:89.81\n",
            "Epoch:0355 train loss:0.292 acc:89.39 | val loss:0.271 acc:90.25\n",
            "Epoch:0356 train loss:0.283 acc:89.61 | val loss:0.273 acc:90.24\n",
            "Epoch:0357 train loss:0.291 acc:89.17 | val loss:0.268 acc:90.27\n",
            "Epoch:0358 train loss:0.282 acc:89.70 | val loss:0.272 acc:89.98\n",
            "Epoch:0359 train loss:0.290 acc:88.66 | val loss:0.268 acc:90.25\n",
            "Epoch:0360 train loss:0.284 acc:89.26 | val loss:0.268 acc:90.35\n",
            "Epoch:0361 train loss:0.288 acc:89.43 | val loss:0.269 acc:90.32\n",
            "Epoch:0362 train loss:0.282 acc:89.31 | val loss:0.270 acc:90.22\n",
            "Epoch:0363 train loss:0.286 acc:89.19 | val loss:0.270 acc:90.38\n",
            "Epoch:0364 train loss:0.274 acc:89.93 | val loss:0.272 acc:90.25\n",
            "Epoch:0365 train loss:0.283 acc:89.46 | val loss:0.272 acc:90.38\n",
            "Epoch:0366 train loss:0.277 acc:89.93 | val loss:0.271 acc:90.30\n",
            "Epoch:0367 train loss:0.284 acc:89.54 | val loss:0.270 acc:90.24\n",
            "Epoch:0368 train loss:0.279 acc:89.75 | val loss:0.269 acc:90.49\n",
            "Epoch:0369 train loss:0.273 acc:89.78 | val loss:0.270 acc:90.32\n",
            "Epoch:0370 train loss:0.279 acc:89.51 | val loss:0.270 acc:90.32\n",
            "Epoch:0371 train loss:0.288 acc:89.24 | val loss:0.272 acc:90.14\n",
            "Epoch:0372 train loss:0.279 acc:89.77 | val loss:0.272 acc:90.27\n",
            "Epoch:0373 train loss:0.276 acc:89.39 | val loss:0.273 acc:90.29\n",
            "Epoch:0374 train loss:0.273 acc:89.69 | val loss:0.272 acc:90.29\n",
            "Epoch:0375 train loss:0.282 acc:89.40 | val loss:0.271 acc:90.11\n",
            "Epoch:0376 train loss:0.280 acc:89.52 | val loss:0.270 acc:90.10\n",
            "Epoch:0377 train loss:0.284 acc:89.73 | val loss:0.268 acc:90.35\n",
            "Epoch:0378 train loss:0.283 acc:89.50 | val loss:0.267 acc:90.40\n",
            "Epoch:0379 train loss:0.278 acc:89.86 | val loss:0.269 acc:90.06\n",
            "Epoch:0380 train loss:0.283 acc:89.50 | val loss:0.268 acc:90.19\n",
            "Epoch:0381 train loss:0.275 acc:89.81 | val loss:0.270 acc:90.24\n",
            "Epoch:0382 train loss:0.283 acc:89.76 | val loss:0.269 acc:90.22\n",
            "Epoch:0383 train loss:0.270 acc:89.92 | val loss:0.271 acc:89.98\n",
            "Epoch:0384 train loss:0.285 acc:89.40 | val loss:0.268 acc:90.32\n",
            "Epoch:0385 train loss:0.271 acc:89.79 | val loss:0.268 acc:90.22\n",
            "Epoch:0386 train loss:0.277 acc:89.93 | val loss:0.266 acc:90.49\n",
            "Epoch:0387 train loss:0.275 acc:89.56 | val loss:0.268 acc:90.19\n",
            "Epoch:0388 train loss:0.273 acc:89.92 | val loss:0.268 acc:90.33\n",
            "Epoch:0389 train loss:0.280 acc:89.27 | val loss:0.271 acc:90.33\n",
            "Epoch:0390 train loss:0.274 acc:89.77 | val loss:0.271 acc:90.24\n",
            "Epoch:0391 train loss:0.276 acc:89.83 | val loss:0.272 acc:89.89\n",
            "Epoch:0392 train loss:0.287 acc:89.52 | val loss:0.270 acc:90.00\n",
            "Epoch:0393 train loss:0.280 acc:89.43 | val loss:0.270 acc:90.49\n",
            "Epoch:0394 train loss:0.277 acc:89.49 | val loss:0.268 acc:90.43\n",
            "Epoch:0395 train loss:0.279 acc:89.63 | val loss:0.269 acc:90.02\n",
            "Epoch:0396 train loss:0.281 acc:89.53 | val loss:0.269 acc:90.02\n",
            "Epoch:0397 train loss:0.275 acc:89.83 | val loss:0.273 acc:90.24\n",
            "Epoch:0398 train loss:0.282 acc:89.17 | val loss:0.269 acc:90.35\n",
            "Epoch:0399 train loss:0.270 acc:89.70 | val loss:0.275 acc:89.71\n",
            "Epoch:0400 train loss:0.284 acc:89.20 | val loss:0.269 acc:90.11\n",
            "Epoch:0401 train loss:0.273 acc:89.95 | val loss:0.275 acc:90.36\n",
            "Epoch:0402 train loss:0.289 acc:89.30 | val loss:0.268 acc:90.43\n",
            "Epoch:0403 train loss:0.272 acc:89.84 | val loss:0.270 acc:89.97\n",
            "Epoch:0404 train loss:0.282 acc:89.34 | val loss:0.266 acc:90.22\n",
            "Epoch:0405 train loss:0.268 acc:90.05 | val loss:0.274 acc:90.41\n",
            "Epoch:0406 train loss:0.286 acc:89.40 | val loss:0.266 acc:90.22\n",
            "Epoch:0407 train loss:0.276 acc:89.83 | val loss:0.272 acc:90.05\n",
            "Epoch:0408 train loss:0.283 acc:89.37 | val loss:0.267 acc:90.43\n",
            "Epoch:0409 train loss:0.278 acc:89.59 | val loss:0.272 acc:90.46\n",
            "Epoch:0410 train loss:0.287 acc:89.32 | val loss:0.268 acc:90.22\n",
            "Epoch:0411 train loss:0.274 acc:89.92 | val loss:0.270 acc:89.83\n",
            "Epoch:0412 train loss:0.285 acc:89.14 | val loss:0.264 acc:90.51\n",
            "Epoch:0413 train loss:0.270 acc:89.93 | val loss:0.272 acc:90.49\n",
            "Epoch:0414 train loss:0.282 acc:89.30 | val loss:0.266 acc:90.41\n",
            "Epoch:0415 train loss:0.276 acc:89.44 | val loss:0.272 acc:89.78\n",
            "Epoch:0416 train loss:0.280 acc:89.68 | val loss:0.269 acc:90.32\n",
            "Epoch:0417 train loss:0.278 acc:89.30 | val loss:0.273 acc:90.44\n",
            "Epoch:0418 train loss:0.275 acc:89.78 | val loss:0.269 acc:90.46\n",
            "Epoch:0419 train loss:0.270 acc:89.89 | val loss:0.271 acc:90.08\n",
            "Epoch:0420 train loss:0.273 acc:89.64 | val loss:0.270 acc:90.06\n",
            "Epoch:0421 train loss:0.274 acc:89.69 | val loss:0.269 acc:90.43\n",
            "Epoch:0422 train loss:0.270 acc:89.84 | val loss:0.271 acc:90.52\n",
            "Epoch:0423 train loss:0.278 acc:89.28 | val loss:0.269 acc:90.44\n",
            "Epoch:0424 train loss:0.274 acc:89.54 | val loss:0.271 acc:90.25\n",
            "Epoch:0425 train loss:0.272 acc:89.91 | val loss:0.268 acc:90.49\n",
            "Epoch:0426 train loss:0.271 acc:90.06 | val loss:0.270 acc:90.62\n",
            "Epoch:0427 train loss:0.284 acc:89.20 | val loss:0.266 acc:90.48\n",
            "Epoch:0428 train loss:0.262 acc:90.44 | val loss:0.268 acc:90.30\n",
            "Epoch:0429 train loss:0.276 acc:89.64 | val loss:0.265 acc:90.59\n",
            "Epoch:0430 train loss:0.269 acc:90.12 | val loss:0.267 acc:90.74\n",
            "Epoch:0431 train loss:0.275 acc:89.58 | val loss:0.265 acc:90.65\n",
            "Epoch:0432 train loss:0.273 acc:89.81 | val loss:0.268 acc:90.27\n",
            "Epoch:0433 train loss:0.272 acc:89.89 | val loss:0.267 acc:90.48\n",
            "Epoch:0434 train loss:0.281 acc:89.51 | val loss:0.269 acc:90.57\n",
            "Epoch:0435 train loss:0.284 acc:89.45 | val loss:0.266 acc:90.70\n",
            "Epoch:0436 train loss:0.270 acc:90.23 | val loss:0.266 acc:90.22\n",
            "Epoch:0437 train loss:0.264 acc:90.08 | val loss:0.270 acc:90.10\n",
            "Epoch:0438 train loss:0.279 acc:89.83 | val loss:0.264 acc:90.62\n",
            "Epoch:0439 train loss:0.267 acc:89.97 | val loss:0.271 acc:90.40\n",
            "Epoch:0440 train loss:0.280 acc:89.84 | val loss:0.267 acc:90.52\n",
            "Epoch:0441 train loss:0.273 acc:89.75 | val loss:0.273 acc:90.08\n",
            "Epoch:0442 train loss:0.286 acc:89.59 | val loss:0.266 acc:90.41\n",
            "Epoch:0443 train loss:0.266 acc:90.19 | val loss:0.271 acc:90.38\n",
            "Epoch:0444 train loss:0.280 acc:89.62 | val loss:0.265 acc:90.57\n",
            "Epoch:0445 train loss:0.273 acc:89.92 | val loss:0.267 acc:90.41\n",
            "Epoch:0446 train loss:0.269 acc:90.02 | val loss:0.265 acc:90.60\n",
            "Epoch:0447 train loss:0.268 acc:90.24 | val loss:0.266 acc:90.51\n",
            "Epoch:0448 train loss:0.268 acc:90.15 | val loss:0.267 acc:90.48\n",
            "Epoch:0449 train loss:0.266 acc:90.35 | val loss:0.268 acc:90.32\n",
            "Epoch:0450 train loss:0.276 acc:89.87 | val loss:0.265 acc:90.65\n",
            "Epoch:0451 train loss:0.257 acc:90.21 | val loss:0.265 acc:90.76\n",
            "Epoch:0452 train loss:0.272 acc:90.16 | val loss:0.265 acc:90.60\n",
            "Epoch:0453 train loss:0.265 acc:90.24 | val loss:0.266 acc:90.40\n",
            "Epoch:0454 train loss:0.269 acc:89.97 | val loss:0.267 acc:90.44\n",
            "Epoch:0455 train loss:0.270 acc:90.13 | val loss:0.269 acc:90.46\n",
            "Epoch:0456 train loss:0.267 acc:90.23 | val loss:0.267 acc:90.48\n",
            "Epoch:0457 train loss:0.269 acc:89.94 | val loss:0.268 acc:90.44\n",
            "Epoch:0458 train loss:0.274 acc:89.89 | val loss:0.266 acc:90.44\n",
            "Epoch:0459 train loss:0.263 acc:90.00 | val loss:0.266 acc:90.49\n",
            "Epoch:0460 train loss:0.267 acc:89.77 | val loss:0.267 acc:90.48\n",
            "Epoch:0461 train loss:0.262 acc:90.59 | val loss:0.267 acc:90.41\n",
            "Epoch:0462 train loss:0.263 acc:90.37 | val loss:0.265 acc:90.54\n",
            "6 : 89.81\n",
            "Epoch:0001 train loss:1.102 acc:27.21 | val loss:1.093 acc:39.41\n",
            "Epoch:0002 train loss:1.093 acc:39.50 | val loss:1.083 acc:39.78\n",
            "Epoch:0003 train loss:1.082 acc:42.00 | val loss:1.071 acc:41.13\n",
            "Epoch:0004 train loss:1.070 acc:43.32 | val loss:1.056 acc:43.26\n",
            "Epoch:0005 train loss:1.056 acc:44.12 | val loss:1.044 acc:48.05\n",
            "Epoch:0006 train loss:1.047 acc:44.08 | val loss:1.043 acc:59.81\n",
            "Epoch:0007 train loss:1.043 acc:44.58 | val loss:1.033 acc:62.08\n",
            "Epoch:0008 train loss:1.035 acc:46.37 | val loss:1.019 acc:61.90\n",
            "Epoch:0009 train loss:1.022 acc:48.63 | val loss:1.008 acc:61.24\n",
            "Epoch:0010 train loss:1.008 acc:51.19 | val loss:0.996 acc:61.47\n",
            "Epoch:0011 train loss:0.999 acc:53.93 | val loss:0.982 acc:61.57\n",
            "Epoch:0012 train loss:0.986 acc:55.53 | val loss:0.963 acc:61.87\n",
            "Epoch:0013 train loss:0.967 acc:57.32 | val loss:0.939 acc:62.14\n",
            "Epoch:0014 train loss:0.946 acc:58.39 | val loss:0.911 acc:62.27\n",
            "Epoch:0015 train loss:0.919 acc:58.82 | val loss:0.880 acc:62.39\n",
            "Epoch:0016 train loss:0.894 acc:58.97 | val loss:0.847 acc:62.96\n",
            "Epoch:0017 train loss:0.865 acc:60.08 | val loss:0.812 acc:63.41\n",
            "Epoch:0018 train loss:0.834 acc:61.38 | val loss:0.776 acc:64.96\n",
            "Epoch:0019 train loss:0.800 acc:62.17 | val loss:0.738 acc:65.72\n",
            "Epoch:0020 train loss:0.761 acc:63.47 | val loss:0.701 acc:65.52\n",
            "Epoch:0021 train loss:0.737 acc:64.77 | val loss:0.674 acc:66.34\n",
            "Epoch:0022 train loss:0.706 acc:65.86 | val loss:0.643 acc:67.32\n",
            "Epoch:0023 train loss:0.683 acc:68.07 | val loss:0.612 acc:67.88\n",
            "Epoch:0024 train loss:0.656 acc:69.33 | val loss:0.590 acc:71.39\n",
            "Epoch:0025 train loss:0.635 acc:71.67 | val loss:0.578 acc:79.14\n",
            "Epoch:0026 train loss:0.622 acc:73.98 | val loss:0.554 acc:81.25\n",
            "Epoch:0027 train loss:0.597 acc:76.23 | val loss:0.541 acc:81.93\n",
            "Epoch:0028 train loss:0.584 acc:77.95 | val loss:0.526 acc:82.69\n",
            "Epoch:0029 train loss:0.575 acc:79.23 | val loss:0.521 acc:82.61\n",
            "Epoch:0030 train loss:0.572 acc:80.48 | val loss:0.514 acc:82.35\n",
            "Epoch:0031 train loss:0.563 acc:80.29 | val loss:0.532 acc:82.39\n",
            "Epoch:0032 train loss:0.575 acc:80.82 | val loss:0.492 acc:83.11\n",
            "Epoch:0033 train loss:0.550 acc:81.22 | val loss:0.483 acc:83.33\n",
            "Epoch:0034 train loss:0.540 acc:81.91 | val loss:0.475 acc:83.44\n",
            "Epoch:0035 train loss:0.523 acc:82.23 | val loss:0.467 acc:83.61\n",
            "Epoch:0036 train loss:0.525 acc:82.15 | val loss:0.457 acc:83.96\n",
            "Epoch:0037 train loss:0.510 acc:83.19 | val loss:0.451 acc:84.20\n",
            "Epoch:0038 train loss:0.499 acc:82.76 | val loss:0.446 acc:84.14\n",
            "Epoch:0039 train loss:0.495 acc:82.76 | val loss:0.441 acc:84.28\n",
            "Epoch:0040 train loss:0.492 acc:82.90 | val loss:0.433 acc:84.25\n",
            "Epoch:0041 train loss:0.488 acc:82.88 | val loss:0.427 acc:84.39\n",
            "Epoch:0042 train loss:0.484 acc:83.26 | val loss:0.428 acc:84.26\n",
            "Epoch:0043 train loss:0.470 acc:83.12 | val loss:0.422 acc:84.29\n",
            "Epoch:0044 train loss:0.466 acc:83.09 | val loss:0.414 acc:84.48\n",
            "Epoch:0045 train loss:0.465 acc:83.62 | val loss:0.410 acc:84.69\n",
            "Epoch:0046 train loss:0.461 acc:83.50 | val loss:0.408 acc:84.80\n",
            "Epoch:0047 train loss:0.458 acc:83.56 | val loss:0.407 acc:84.60\n",
            "Epoch:0048 train loss:0.455 acc:83.41 | val loss:0.396 acc:85.29\n",
            "Epoch:0049 train loss:0.449 acc:84.09 | val loss:0.395 acc:85.39\n",
            "Epoch:0050 train loss:0.449 acc:84.43 | val loss:0.388 acc:85.55\n",
            "Epoch:0051 train loss:0.441 acc:84.50 | val loss:0.391 acc:85.47\n",
            "Epoch:0052 train loss:0.442 acc:84.24 | val loss:0.386 acc:85.75\n",
            "Epoch:0053 train loss:0.435 acc:84.73 | val loss:0.379 acc:85.90\n",
            "Epoch:0054 train loss:0.432 acc:84.92 | val loss:0.378 acc:85.97\n",
            "Epoch:0055 train loss:0.435 acc:85.23 | val loss:0.373 acc:86.07\n",
            "Epoch:0056 train loss:0.428 acc:84.84 | val loss:0.375 acc:86.13\n",
            "Epoch:0057 train loss:0.425 acc:84.66 | val loss:0.372 acc:86.18\n",
            "Epoch:0058 train loss:0.418 acc:85.32 | val loss:0.366 acc:86.26\n",
            "Epoch:0059 train loss:0.415 acc:85.43 | val loss:0.364 acc:86.37\n",
            "Epoch:0060 train loss:0.414 acc:85.77 | val loss:0.361 acc:86.39\n",
            "Epoch:0061 train loss:0.409 acc:85.74 | val loss:0.362 acc:86.56\n",
            "Epoch:0062 train loss:0.405 acc:85.68 | val loss:0.359 acc:86.62\n",
            "Epoch:0063 train loss:0.409 acc:85.45 | val loss:0.355 acc:86.77\n",
            "Epoch:0064 train loss:0.405 acc:86.06 | val loss:0.353 acc:86.78\n",
            "Epoch:0065 train loss:0.393 acc:86.22 | val loss:0.351 acc:86.86\n",
            "Epoch:0066 train loss:0.402 acc:85.90 | val loss:0.353 acc:86.89\n",
            "Epoch:0067 train loss:0.398 acc:85.71 | val loss:0.349 acc:87.13\n",
            "Epoch:0068 train loss:0.393 acc:86.42 | val loss:0.346 acc:87.29\n",
            "Epoch:0069 train loss:0.396 acc:86.35 | val loss:0.344 acc:87.27\n",
            "Epoch:0070 train loss:0.393 acc:85.96 | val loss:0.343 acc:87.24\n",
            "Epoch:0071 train loss:0.387 acc:86.79 | val loss:0.343 acc:87.46\n",
            "Epoch:0072 train loss:0.394 acc:85.99 | val loss:0.339 acc:87.48\n",
            "Epoch:0073 train loss:0.385 acc:86.75 | val loss:0.338 acc:87.53\n",
            "Epoch:0074 train loss:0.387 acc:86.47 | val loss:0.337 acc:87.58\n",
            "Epoch:0075 train loss:0.388 acc:85.99 | val loss:0.338 acc:87.65\n",
            "Epoch:0076 train loss:0.386 acc:86.36 | val loss:0.335 acc:87.75\n",
            "Epoch:0077 train loss:0.379 acc:86.58 | val loss:0.333 acc:87.78\n",
            "Epoch:0078 train loss:0.382 acc:86.17 | val loss:0.333 acc:87.84\n",
            "Epoch:0079 train loss:0.381 acc:86.60 | val loss:0.332 acc:87.86\n",
            "Epoch:0080 train loss:0.378 acc:86.57 | val loss:0.331 acc:87.84\n",
            "Epoch:0081 train loss:0.377 acc:86.71 | val loss:0.329 acc:87.92\n",
            "Epoch:0082 train loss:0.376 acc:86.58 | val loss:0.328 acc:88.02\n",
            "Epoch:0083 train loss:0.371 acc:87.10 | val loss:0.328 acc:87.99\n",
            "Epoch:0084 train loss:0.369 acc:87.01 | val loss:0.329 acc:87.91\n",
            "Epoch:0085 train loss:0.369 acc:86.97 | val loss:0.326 acc:88.05\n",
            "Epoch:0086 train loss:0.371 acc:86.97 | val loss:0.325 acc:88.00\n",
            "Epoch:0087 train loss:0.363 acc:87.29 | val loss:0.326 acc:88.08\n",
            "Epoch:0088 train loss:0.373 acc:87.05 | val loss:0.325 acc:88.08\n",
            "Epoch:0089 train loss:0.368 acc:87.00 | val loss:0.325 acc:88.13\n",
            "Epoch:0090 train loss:0.365 acc:87.26 | val loss:0.323 acc:88.03\n",
            "Epoch:0091 train loss:0.366 acc:87.10 | val loss:0.322 acc:88.18\n",
            "Epoch:0092 train loss:0.358 acc:87.42 | val loss:0.324 acc:88.10\n",
            "Epoch:0093 train loss:0.366 acc:86.82 | val loss:0.320 acc:88.16\n",
            "Epoch:0094 train loss:0.368 acc:87.08 | val loss:0.320 acc:88.21\n",
            "Epoch:0095 train loss:0.362 acc:87.46 | val loss:0.320 acc:88.32\n",
            "Epoch:0096 train loss:0.361 acc:87.33 | val loss:0.321 acc:88.21\n",
            "Epoch:0097 train loss:0.358 acc:87.46 | val loss:0.318 acc:88.30\n",
            "Epoch:0098 train loss:0.365 acc:87.07 | val loss:0.317 acc:88.35\n",
            "Epoch:0099 train loss:0.358 acc:87.72 | val loss:0.318 acc:88.24\n",
            "Epoch:0100 train loss:0.357 acc:87.44 | val loss:0.318 acc:88.24\n",
            "Epoch:0101 train loss:0.354 acc:87.83 | val loss:0.315 acc:88.35\n",
            "Epoch:0102 train loss:0.352 acc:87.48 | val loss:0.315 acc:88.42\n",
            "Epoch:0103 train loss:0.349 acc:87.90 | val loss:0.317 acc:88.21\n",
            "Epoch:0104 train loss:0.356 acc:87.41 | val loss:0.319 acc:88.27\n",
            "Epoch:0105 train loss:0.350 acc:87.91 | val loss:0.315 acc:88.26\n",
            "Epoch:0106 train loss:0.352 acc:87.67 | val loss:0.315 acc:88.21\n",
            "Epoch:0107 train loss:0.348 acc:87.33 | val loss:0.318 acc:88.21\n",
            "Epoch:0108 train loss:0.357 acc:87.26 | val loss:0.317 acc:88.18\n",
            "Epoch:0109 train loss:0.362 acc:87.32 | val loss:0.313 acc:88.23\n",
            "Epoch:0110 train loss:0.348 acc:87.70 | val loss:0.313 acc:88.35\n",
            "Epoch:0111 train loss:0.348 acc:87.55 | val loss:0.313 acc:88.30\n",
            "Epoch:0112 train loss:0.351 acc:87.65 | val loss:0.311 acc:88.38\n",
            "Epoch:0113 train loss:0.344 acc:88.11 | val loss:0.311 acc:88.48\n",
            "Epoch:0114 train loss:0.351 acc:87.38 | val loss:0.313 acc:88.24\n",
            "Epoch:0115 train loss:0.350 acc:87.64 | val loss:0.310 acc:88.40\n",
            "Epoch:0116 train loss:0.341 acc:87.93 | val loss:0.310 acc:88.34\n",
            "Epoch:0117 train loss:0.346 acc:87.32 | val loss:0.313 acc:88.43\n",
            "Epoch:0118 train loss:0.350 acc:87.72 | val loss:0.312 acc:88.35\n",
            "Epoch:0119 train loss:0.344 acc:87.61 | val loss:0.310 acc:88.32\n",
            "Epoch:0120 train loss:0.338 acc:87.96 | val loss:0.310 acc:88.34\n",
            "Epoch:0121 train loss:0.345 acc:87.73 | val loss:0.311 acc:88.43\n",
            "Epoch:0122 train loss:0.342 acc:88.03 | val loss:0.309 acc:88.42\n",
            "Epoch:0123 train loss:0.344 acc:88.00 | val loss:0.308 acc:88.23\n",
            "Epoch:0124 train loss:0.339 acc:87.70 | val loss:0.309 acc:88.49\n",
            "Epoch:0125 train loss:0.348 acc:87.82 | val loss:0.310 acc:88.49\n",
            "Epoch:0126 train loss:0.341 acc:88.15 | val loss:0.306 acc:88.49\n",
            "Epoch:0127 train loss:0.351 acc:87.55 | val loss:0.305 acc:88.51\n",
            "Epoch:0128 train loss:0.336 acc:88.02 | val loss:0.309 acc:88.56\n",
            "Epoch:0129 train loss:0.342 acc:87.77 | val loss:0.307 acc:88.53\n",
            "Epoch:0130 train loss:0.339 acc:88.20 | val loss:0.306 acc:88.53\n",
            "Epoch:0131 train loss:0.344 acc:87.73 | val loss:0.305 acc:88.49\n",
            "Epoch:0132 train loss:0.335 acc:87.92 | val loss:0.309 acc:88.48\n",
            "Epoch:0133 train loss:0.336 acc:87.85 | val loss:0.305 acc:88.53\n",
            "Epoch:0134 train loss:0.336 acc:87.77 | val loss:0.304 acc:88.65\n",
            "Epoch:0135 train loss:0.344 acc:87.98 | val loss:0.304 acc:88.59\n",
            "Epoch:0136 train loss:0.339 acc:88.07 | val loss:0.307 acc:88.67\n",
            "Epoch:0137 train loss:0.344 acc:87.58 | val loss:0.302 acc:88.65\n",
            "Epoch:0138 train loss:0.335 acc:88.01 | val loss:0.303 acc:88.65\n",
            "Epoch:0139 train loss:0.345 acc:87.98 | val loss:0.303 acc:88.59\n",
            "Epoch:0140 train loss:0.338 acc:87.90 | val loss:0.304 acc:88.67\n",
            "Epoch:0141 train loss:0.340 acc:87.85 | val loss:0.301 acc:88.76\n",
            "Epoch:0142 train loss:0.334 acc:87.90 | val loss:0.300 acc:88.86\n",
            "Epoch:0143 train loss:0.336 acc:88.12 | val loss:0.305 acc:88.67\n",
            "Epoch:0144 train loss:0.337 acc:88.30 | val loss:0.303 acc:88.70\n",
            "Epoch:0145 train loss:0.330 acc:88.45 | val loss:0.301 acc:88.86\n",
            "Epoch:0146 train loss:0.342 acc:88.13 | val loss:0.300 acc:88.80\n",
            "Epoch:0147 train loss:0.335 acc:87.59 | val loss:0.301 acc:88.68\n",
            "Epoch:0148 train loss:0.331 acc:88.24 | val loss:0.299 acc:88.75\n",
            "Epoch:0149 train loss:0.328 acc:88.48 | val loss:0.299 acc:88.73\n",
            "Epoch:0150 train loss:0.329 acc:88.15 | val loss:0.298 acc:88.81\n",
            "Epoch:0151 train loss:0.333 acc:87.93 | val loss:0.299 acc:89.00\n",
            "Epoch:0152 train loss:0.334 acc:88.16 | val loss:0.301 acc:88.75\n",
            "Epoch:0153 train loss:0.330 acc:88.57 | val loss:0.299 acc:88.73\n",
            "Epoch:0154 train loss:0.331 acc:88.04 | val loss:0.299 acc:88.91\n",
            "Epoch:0155 train loss:0.331 acc:88.11 | val loss:0.299 acc:88.83\n",
            "Epoch:0156 train loss:0.327 acc:88.07 | val loss:0.302 acc:88.76\n",
            "Epoch:0157 train loss:0.327 acc:87.91 | val loss:0.300 acc:88.94\n",
            "Epoch:0158 train loss:0.326 acc:88.12 | val loss:0.298 acc:89.13\n",
            "Epoch:0159 train loss:0.328 acc:88.56 | val loss:0.298 acc:88.78\n",
            "Epoch:0160 train loss:0.329 acc:88.06 | val loss:0.301 acc:88.76\n",
            "Epoch:0161 train loss:0.330 acc:88.16 | val loss:0.296 acc:88.94\n",
            "Epoch:0162 train loss:0.332 acc:88.27 | val loss:0.296 acc:89.22\n",
            "Epoch:0163 train loss:0.331 acc:87.90 | val loss:0.298 acc:88.99\n",
            "Epoch:0164 train loss:0.328 acc:88.34 | val loss:0.300 acc:88.92\n",
            "Epoch:0165 train loss:0.336 acc:87.93 | val loss:0.295 acc:89.02\n",
            "Epoch:0166 train loss:0.328 acc:88.05 | val loss:0.296 acc:89.05\n",
            "Epoch:0167 train loss:0.325 acc:88.27 | val loss:0.296 acc:88.94\n",
            "Epoch:0168 train loss:0.326 acc:88.63 | val loss:0.297 acc:88.97\n",
            "Epoch:0169 train loss:0.317 acc:88.68 | val loss:0.297 acc:89.10\n",
            "Epoch:0170 train loss:0.328 acc:88.24 | val loss:0.297 acc:89.05\n",
            "Epoch:0171 train loss:0.322 acc:88.51 | val loss:0.297 acc:88.95\n",
            "Epoch:0172 train loss:0.323 acc:88.40 | val loss:0.296 acc:88.94\n",
            "Epoch:0173 train loss:0.318 acc:88.67 | val loss:0.295 acc:88.99\n",
            "Epoch:0174 train loss:0.329 acc:88.04 | val loss:0.296 acc:89.06\n",
            "Epoch:0175 train loss:0.321 acc:88.43 | val loss:0.294 acc:89.14\n",
            "Epoch:0176 train loss:0.324 acc:88.32 | val loss:0.294 acc:89.03\n",
            "Epoch:0177 train loss:0.327 acc:88.62 | val loss:0.293 acc:89.10\n",
            "Epoch:0178 train loss:0.323 acc:88.26 | val loss:0.296 acc:89.00\n",
            "Epoch:0179 train loss:0.322 acc:88.44 | val loss:0.294 acc:88.97\n",
            "Epoch:0180 train loss:0.315 acc:89.01 | val loss:0.293 acc:89.11\n",
            "Epoch:0181 train loss:0.326 acc:88.57 | val loss:0.296 acc:89.02\n",
            "Epoch:0182 train loss:0.321 acc:88.38 | val loss:0.295 acc:88.95\n",
            "Epoch:0183 train loss:0.325 acc:88.23 | val loss:0.293 acc:89.13\n",
            "Epoch:0184 train loss:0.324 acc:88.19 | val loss:0.293 acc:88.94\n",
            "Epoch:0185 train loss:0.322 acc:88.51 | val loss:0.293 acc:89.11\n",
            "Epoch:0186 train loss:0.321 acc:88.37 | val loss:0.292 acc:89.24\n",
            "Epoch:0187 train loss:0.320 acc:88.29 | val loss:0.292 acc:89.10\n",
            "Epoch:0188 train loss:0.312 acc:88.49 | val loss:0.293 acc:89.14\n",
            "Epoch:0189 train loss:0.315 acc:88.60 | val loss:0.292 acc:89.13\n",
            "Epoch:0190 train loss:0.312 acc:88.81 | val loss:0.296 acc:88.87\n",
            "Epoch:0191 train loss:0.319 acc:88.38 | val loss:0.292 acc:89.14\n",
            "Epoch:0192 train loss:0.317 acc:88.83 | val loss:0.292 acc:89.19\n",
            "Epoch:0193 train loss:0.316 acc:88.40 | val loss:0.295 acc:89.00\n",
            "Epoch:0194 train loss:0.316 acc:88.62 | val loss:0.291 acc:89.29\n",
            "Epoch:0195 train loss:0.319 acc:88.17 | val loss:0.291 acc:89.05\n",
            "Epoch:0196 train loss:0.320 acc:88.71 | val loss:0.293 acc:89.14\n",
            "Epoch:0197 train loss:0.317 acc:88.53 | val loss:0.292 acc:89.21\n",
            "Epoch:0198 train loss:0.312 acc:88.56 | val loss:0.289 acc:89.19\n",
            "Epoch:0199 train loss:0.315 acc:88.49 | val loss:0.289 acc:89.13\n",
            "Epoch:0200 train loss:0.318 acc:88.94 | val loss:0.293 acc:89.18\n",
            "Epoch:0201 train loss:0.318 acc:88.57 | val loss:0.288 acc:89.24\n",
            "Epoch:0202 train loss:0.316 acc:88.75 | val loss:0.289 acc:89.29\n",
            "Epoch:0203 train loss:0.312 acc:88.88 | val loss:0.292 acc:89.02\n",
            "Epoch:0204 train loss:0.317 acc:88.41 | val loss:0.288 acc:89.22\n",
            "Epoch:0205 train loss:0.314 acc:88.33 | val loss:0.286 acc:89.32\n",
            "Epoch:0206 train loss:0.313 acc:88.60 | val loss:0.290 acc:89.11\n",
            "Epoch:0207 train loss:0.319 acc:88.60 | val loss:0.286 acc:89.37\n",
            "Epoch:0208 train loss:0.314 acc:88.77 | val loss:0.286 acc:89.48\n",
            "Epoch:0209 train loss:0.319 acc:88.43 | val loss:0.287 acc:89.27\n",
            "Epoch:0210 train loss:0.319 acc:88.56 | val loss:0.288 acc:89.32\n",
            "Epoch:0211 train loss:0.311 acc:88.34 | val loss:0.286 acc:89.45\n",
            "Epoch:0212 train loss:0.317 acc:88.71 | val loss:0.288 acc:89.22\n",
            "Epoch:0213 train loss:0.314 acc:88.66 | val loss:0.288 acc:89.35\n",
            "Epoch:0214 train loss:0.320 acc:88.15 | val loss:0.287 acc:89.37\n",
            "Epoch:0215 train loss:0.317 acc:88.28 | val loss:0.287 acc:89.46\n",
            "Epoch:0216 train loss:0.309 acc:88.95 | val loss:0.296 acc:89.03\n",
            "Epoch:0217 train loss:0.323 acc:88.28 | val loss:0.286 acc:89.33\n",
            "Epoch:0218 train loss:0.308 acc:88.98 | val loss:0.288 acc:89.18\n",
            "Epoch:0219 train loss:0.310 acc:88.76 | val loss:0.288 acc:89.24\n",
            "Epoch:0220 train loss:0.314 acc:88.50 | val loss:0.288 acc:89.26\n",
            "Epoch:0221 train loss:0.307 acc:88.47 | val loss:0.285 acc:89.45\n",
            "Epoch:0222 train loss:0.314 acc:88.87 | val loss:0.286 acc:89.40\n",
            "Epoch:0223 train loss:0.307 acc:89.03 | val loss:0.287 acc:89.35\n",
            "Epoch:0224 train loss:0.311 acc:88.67 | val loss:0.286 acc:89.40\n",
            "Epoch:0225 train loss:0.306 acc:88.80 | val loss:0.286 acc:89.19\n",
            "Epoch:0226 train loss:0.313 acc:88.77 | val loss:0.287 acc:89.22\n",
            "Epoch:0227 train loss:0.317 acc:88.47 | val loss:0.285 acc:89.41\n",
            "Epoch:0228 train loss:0.305 acc:89.14 | val loss:0.284 acc:89.48\n",
            "Epoch:0229 train loss:0.312 acc:88.34 | val loss:0.286 acc:89.21\n",
            "Epoch:0230 train loss:0.319 acc:88.95 | val loss:0.284 acc:89.41\n",
            "Epoch:0231 train loss:0.309 acc:88.59 | val loss:0.288 acc:89.24\n",
            "Epoch:0232 train loss:0.311 acc:88.53 | val loss:0.286 acc:89.16\n",
            "Epoch:0233 train loss:0.308 acc:88.77 | val loss:0.283 acc:89.26\n",
            "Epoch:0234 train loss:0.305 acc:88.75 | val loss:0.287 acc:89.32\n",
            "Epoch:0235 train loss:0.307 acc:88.97 | val loss:0.285 acc:89.24\n",
            "Epoch:0236 train loss:0.315 acc:88.50 | val loss:0.284 acc:89.38\n",
            "Epoch:0237 train loss:0.301 acc:88.72 | val loss:0.286 acc:89.29\n",
            "Epoch:0238 train loss:0.309 acc:88.77 | val loss:0.284 acc:89.29\n",
            "Epoch:0239 train loss:0.305 acc:88.68 | val loss:0.285 acc:89.38\n",
            "Epoch:0240 train loss:0.303 acc:88.63 | val loss:0.283 acc:89.45\n",
            "Epoch:0241 train loss:0.309 acc:88.65 | val loss:0.283 acc:89.22\n",
            "Epoch:0242 train loss:0.300 acc:89.24 | val loss:0.283 acc:89.41\n",
            "Epoch:0243 train loss:0.306 acc:88.63 | val loss:0.283 acc:89.27\n",
            "Epoch:0244 train loss:0.308 acc:88.57 | val loss:0.282 acc:89.33\n",
            "Epoch:0245 train loss:0.309 acc:88.49 | val loss:0.286 acc:89.24\n",
            "Epoch:0246 train loss:0.304 acc:88.89 | val loss:0.283 acc:89.26\n",
            "Epoch:0247 train loss:0.303 acc:88.68 | val loss:0.285 acc:89.26\n",
            "Epoch:0248 train loss:0.305 acc:89.06 | val loss:0.287 acc:89.18\n",
            "Epoch:0249 train loss:0.308 acc:88.53 | val loss:0.284 acc:89.21\n",
            "Epoch:0250 train loss:0.303 acc:88.99 | val loss:0.286 acc:89.03\n",
            "Epoch:0251 train loss:0.315 acc:88.52 | val loss:0.286 acc:89.33\n",
            "Epoch:0252 train loss:0.304 acc:88.61 | val loss:0.287 acc:89.30\n",
            "Epoch:0253 train loss:0.318 acc:88.28 | val loss:0.283 acc:89.16\n",
            "Epoch:0254 train loss:0.309 acc:88.61 | val loss:0.281 acc:89.45\n",
            "Epoch:0255 train loss:0.298 acc:89.45 | val loss:0.286 acc:89.24\n",
            "Epoch:0256 train loss:0.306 acc:88.64 | val loss:0.282 acc:89.37\n",
            "Epoch:0257 train loss:0.300 acc:89.12 | val loss:0.283 acc:89.24\n",
            "Epoch:0258 train loss:0.307 acc:88.76 | val loss:0.282 acc:89.43\n",
            "Epoch:0259 train loss:0.301 acc:89.03 | val loss:0.284 acc:89.37\n",
            "Epoch:0260 train loss:0.302 acc:88.84 | val loss:0.281 acc:89.41\n",
            "Epoch:0261 train loss:0.298 acc:89.09 | val loss:0.283 acc:89.21\n",
            "Epoch:0262 train loss:0.300 acc:89.04 | val loss:0.284 acc:89.38\n",
            "Epoch:0263 train loss:0.299 acc:88.83 | val loss:0.288 acc:89.13\n",
            "Epoch:0264 train loss:0.301 acc:88.89 | val loss:0.281 acc:89.35\n",
            "Epoch:0265 train loss:0.309 acc:88.70 | val loss:0.281 acc:89.29\n",
            "Epoch:0266 train loss:0.300 acc:88.79 | val loss:0.282 acc:89.33\n",
            "Epoch:0267 train loss:0.304 acc:88.94 | val loss:0.281 acc:89.46\n",
            "Epoch:0268 train loss:0.299 acc:88.84 | val loss:0.279 acc:89.49\n",
            "Epoch:0269 train loss:0.300 acc:88.94 | val loss:0.279 acc:89.43\n",
            "Epoch:0270 train loss:0.299 acc:89.22 | val loss:0.279 acc:89.45\n",
            "Epoch:0271 train loss:0.292 acc:89.43 | val loss:0.281 acc:89.48\n",
            "Epoch:0272 train loss:0.297 acc:89.22 | val loss:0.281 acc:89.43\n",
            "Epoch:0273 train loss:0.302 acc:88.87 | val loss:0.280 acc:89.38\n",
            "Epoch:0274 train loss:0.294 acc:89.10 | val loss:0.280 acc:89.43\n",
            "Epoch:0275 train loss:0.300 acc:89.09 | val loss:0.280 acc:89.32\n",
            "Epoch:0276 train loss:0.299 acc:89.10 | val loss:0.280 acc:89.40\n",
            "Epoch:0277 train loss:0.308 acc:88.87 | val loss:0.278 acc:89.45\n",
            "Epoch:0278 train loss:0.296 acc:89.53 | val loss:0.277 acc:89.43\n",
            "Epoch:0279 train loss:0.297 acc:89.10 | val loss:0.277 acc:89.35\n",
            "Epoch:0280 train loss:0.292 acc:89.75 | val loss:0.280 acc:89.43\n",
            "Epoch:0281 train loss:0.300 acc:89.25 | val loss:0.278 acc:89.38\n",
            "Epoch:0282 train loss:0.301 acc:88.99 | val loss:0.279 acc:89.40\n",
            "Epoch:0283 train loss:0.293 acc:89.36 | val loss:0.280 acc:89.48\n",
            "Epoch:0284 train loss:0.299 acc:88.84 | val loss:0.279 acc:89.38\n",
            "Epoch:0285 train loss:0.295 acc:89.05 | val loss:0.280 acc:89.35\n",
            "Epoch:0286 train loss:0.294 acc:89.38 | val loss:0.283 acc:89.29\n",
            "Epoch:0287 train loss:0.291 acc:89.23 | val loss:0.278 acc:89.38\n",
            "Epoch:0288 train loss:0.294 acc:89.46 | val loss:0.280 acc:89.30\n",
            "Epoch:0289 train loss:0.298 acc:89.17 | val loss:0.287 acc:89.48\n",
            "Epoch:0290 train loss:0.307 acc:88.70 | val loss:0.277 acc:89.48\n",
            "Epoch:0291 train loss:0.289 acc:89.32 | val loss:0.281 acc:89.24\n",
            "Epoch:0292 train loss:0.302 acc:88.97 | val loss:0.280 acc:89.35\n",
            "Epoch:0293 train loss:0.299 acc:89.00 | val loss:0.283 acc:89.41\n",
            "Epoch:0294 train loss:0.299 acc:89.08 | val loss:0.278 acc:89.51\n",
            "Epoch:0295 train loss:0.295 acc:89.18 | val loss:0.279 acc:89.45\n",
            "Epoch:0296 train loss:0.296 acc:89.25 | val loss:0.284 acc:89.33\n",
            "Epoch:0297 train loss:0.302 acc:88.85 | val loss:0.278 acc:89.40\n",
            "Epoch:0298 train loss:0.297 acc:88.66 | val loss:0.278 acc:89.40\n",
            "Epoch:0299 train loss:0.300 acc:88.66 | val loss:0.278 acc:89.46\n",
            "Epoch:0300 train loss:0.293 acc:89.26 | val loss:0.282 acc:89.40\n",
            "Epoch:0301 train loss:0.300 acc:89.17 | val loss:0.276 acc:89.48\n",
            "Epoch:0302 train loss:0.299 acc:89.03 | val loss:0.278 acc:89.37\n",
            "Epoch:0303 train loss:0.297 acc:89.00 | val loss:0.280 acc:89.46\n",
            "Epoch:0304 train loss:0.295 acc:89.47 | val loss:0.278 acc:89.37\n",
            "Epoch:0305 train loss:0.294 acc:89.15 | val loss:0.276 acc:89.43\n",
            "Epoch:0306 train loss:0.294 acc:89.40 | val loss:0.276 acc:89.45\n",
            "Epoch:0307 train loss:0.291 acc:89.25 | val loss:0.277 acc:89.48\n",
            "Epoch:0308 train loss:0.299 acc:88.85 | val loss:0.277 acc:89.48\n",
            "Epoch:0309 train loss:0.293 acc:89.23 | val loss:0.279 acc:89.46\n",
            "Epoch:0310 train loss:0.292 acc:89.44 | val loss:0.275 acc:89.46\n",
            "Epoch:0311 train loss:0.291 acc:89.37 | val loss:0.274 acc:89.46\n",
            "Epoch:0312 train loss:0.286 acc:89.43 | val loss:0.277 acc:89.51\n",
            "Epoch:0313 train loss:0.297 acc:89.16 | val loss:0.277 acc:89.48\n",
            "Epoch:0314 train loss:0.288 acc:89.45 | val loss:0.276 acc:89.46\n",
            "Epoch:0315 train loss:0.280 acc:89.75 | val loss:0.276 acc:89.30\n",
            "Epoch:0316 train loss:0.288 acc:89.35 | val loss:0.280 acc:89.49\n",
            "Epoch:0317 train loss:0.288 acc:89.17 | val loss:0.278 acc:89.48\n",
            "Epoch:0318 train loss:0.290 acc:89.32 | val loss:0.277 acc:89.37\n",
            "Epoch:0319 train loss:0.282 acc:89.54 | val loss:0.276 acc:89.38\n",
            "Epoch:0320 train loss:0.290 acc:89.12 | val loss:0.276 acc:89.57\n",
            "Epoch:0321 train loss:0.289 acc:89.41 | val loss:0.276 acc:89.62\n",
            "Epoch:0322 train loss:0.285 acc:89.44 | val loss:0.274 acc:89.52\n",
            "Epoch:0323 train loss:0.285 acc:89.56 | val loss:0.276 acc:89.45\n",
            "Epoch:0324 train loss:0.286 acc:89.39 | val loss:0.284 acc:89.27\n",
            "Epoch:0325 train loss:0.292 acc:89.26 | val loss:0.278 acc:89.46\n",
            "Epoch:0326 train loss:0.287 acc:89.25 | val loss:0.278 acc:89.33\n",
            "Epoch:0327 train loss:0.296 acc:89.21 | val loss:0.282 acc:89.46\n",
            "Epoch:0328 train loss:0.300 acc:88.91 | val loss:0.276 acc:89.51\n",
            "Epoch:0329 train loss:0.293 acc:89.06 | val loss:0.278 acc:89.40\n",
            "Epoch:0330 train loss:0.300 acc:88.95 | val loss:0.276 acc:89.60\n",
            "Epoch:0331 train loss:0.289 acc:89.24 | val loss:0.279 acc:89.54\n",
            "Epoch:0332 train loss:0.287 acc:89.65 | val loss:0.275 acc:89.56\n",
            "Epoch:0333 train loss:0.287 acc:89.42 | val loss:0.276 acc:89.52\n",
            "Epoch:0334 train loss:0.289 acc:89.50 | val loss:0.277 acc:89.43\n",
            "Epoch:0335 train loss:0.288 acc:89.74 | val loss:0.278 acc:89.49\n",
            "Epoch:0336 train loss:0.298 acc:89.20 | val loss:0.275 acc:89.48\n",
            "Epoch:0337 train loss:0.288 acc:88.97 | val loss:0.274 acc:89.56\n",
            "Epoch:0338 train loss:0.288 acc:89.35 | val loss:0.274 acc:89.48\n",
            "Epoch:0339 train loss:0.282 acc:89.42 | val loss:0.274 acc:89.54\n",
            "Epoch:0340 train loss:0.285 acc:89.47 | val loss:0.274 acc:89.60\n",
            "Epoch:0341 train loss:0.284 acc:89.30 | val loss:0.274 acc:89.62\n",
            "Epoch:0342 train loss:0.284 acc:89.38 | val loss:0.275 acc:89.51\n",
            "Epoch:0343 train loss:0.287 acc:89.57 | val loss:0.276 acc:89.41\n",
            "Epoch:0344 train loss:0.286 acc:89.57 | val loss:0.277 acc:89.40\n",
            "Epoch:0345 train loss:0.287 acc:89.39 | val loss:0.279 acc:89.48\n",
            "Epoch:0346 train loss:0.284 acc:89.51 | val loss:0.276 acc:89.43\n",
            "Epoch:0347 train loss:0.280 acc:89.46 | val loss:0.275 acc:89.57\n",
            "Epoch:0348 train loss:0.285 acc:89.80 | val loss:0.274 acc:89.38\n",
            "Epoch:0349 train loss:0.280 acc:89.60 | val loss:0.281 acc:89.46\n",
            "Epoch:0350 train loss:0.286 acc:89.55 | val loss:0.276 acc:89.41\n",
            "Epoch:0351 train loss:0.292 acc:88.85 | val loss:0.275 acc:89.54\n",
            "Epoch:0352 train loss:0.294 acc:89.46 | val loss:0.277 acc:89.73\n",
            "Epoch:0353 train loss:0.281 acc:89.73 | val loss:0.275 acc:89.45\n",
            "Epoch:0354 train loss:0.282 acc:89.58 | val loss:0.275 acc:89.51\n",
            "Epoch:0355 train loss:0.289 acc:89.16 | val loss:0.275 acc:89.49\n",
            "Epoch:0356 train loss:0.285 acc:89.32 | val loss:0.283 acc:89.49\n",
            "Epoch:0357 train loss:0.289 acc:89.40 | val loss:0.276 acc:89.45\n",
            "Epoch:0358 train loss:0.294 acc:89.37 | val loss:0.274 acc:89.45\n",
            "Epoch:0359 train loss:0.284 acc:89.53 | val loss:0.280 acc:89.57\n",
            "Epoch:0360 train loss:0.287 acc:89.38 | val loss:0.272 acc:89.64\n",
            "Epoch:0361 train loss:0.283 acc:89.39 | val loss:0.274 acc:89.41\n",
            "Epoch:0362 train loss:0.282 acc:89.72 | val loss:0.273 acc:89.43\n",
            "Epoch:0363 train loss:0.286 acc:89.05 | val loss:0.275 acc:89.59\n",
            "Epoch:0364 train loss:0.283 acc:89.59 | val loss:0.275 acc:89.48\n",
            "Epoch:0365 train loss:0.291 acc:89.14 | val loss:0.274 acc:89.57\n",
            "Epoch:0366 train loss:0.281 acc:89.50 | val loss:0.279 acc:89.45\n",
            "Epoch:0367 train loss:0.284 acc:89.32 | val loss:0.278 acc:89.46\n",
            "Epoch:0368 train loss:0.284 acc:89.46 | val loss:0.273 acc:89.49\n",
            "Epoch:0369 train loss:0.283 acc:89.61 | val loss:0.275 acc:89.68\n",
            "Epoch:0370 train loss:0.282 acc:89.63 | val loss:0.276 acc:89.65\n",
            "Epoch:0371 train loss:0.290 acc:89.21 | val loss:0.273 acc:89.35\n",
            "Epoch:0372 train loss:0.284 acc:89.57 | val loss:0.273 acc:89.62\n",
            "Epoch:0373 train loss:0.277 acc:89.74 | val loss:0.276 acc:89.43\n",
            "Epoch:0374 train loss:0.285 acc:89.27 | val loss:0.272 acc:89.60\n",
            "Epoch:0375 train loss:0.271 acc:89.83 | val loss:0.274 acc:89.70\n",
            "Epoch:0376 train loss:0.284 acc:89.67 | val loss:0.275 acc:89.62\n",
            "Epoch:0377 train loss:0.280 acc:89.56 | val loss:0.275 acc:89.56\n",
            "Epoch:0378 train loss:0.279 acc:89.53 | val loss:0.276 acc:89.48\n",
            "Epoch:0379 train loss:0.280 acc:89.58 | val loss:0.274 acc:89.60\n",
            "Epoch:0380 train loss:0.286 acc:89.51 | val loss:0.272 acc:89.79\n",
            "Epoch:0381 train loss:0.278 acc:89.95 | val loss:0.271 acc:89.81\n",
            "Epoch:0382 train loss:0.282 acc:89.65 | val loss:0.272 acc:89.70\n",
            "Epoch:0383 train loss:0.278 acc:89.81 | val loss:0.275 acc:89.54\n",
            "Epoch:0384 train loss:0.279 acc:89.60 | val loss:0.276 acc:89.40\n",
            "Epoch:0385 train loss:0.273 acc:89.92 | val loss:0.275 acc:89.48\n",
            "Epoch:0386 train loss:0.269 acc:90.36 | val loss:0.275 acc:89.57\n",
            "Epoch:0387 train loss:0.278 acc:89.71 | val loss:0.274 acc:89.65\n",
            "Epoch:0388 train loss:0.279 acc:89.74 | val loss:0.275 acc:89.49\n",
            "Epoch:0389 train loss:0.276 acc:89.84 | val loss:0.273 acc:89.46\n",
            "Epoch:0390 train loss:0.279 acc:89.57 | val loss:0.272 acc:89.59\n",
            "Epoch:0391 train loss:0.274 acc:89.67 | val loss:0.271 acc:89.64\n",
            "Epoch:0392 train loss:0.279 acc:89.40 | val loss:0.273 acc:89.62\n",
            "Epoch:0393 train loss:0.277 acc:89.95 | val loss:0.274 acc:89.56\n",
            "Epoch:0394 train loss:0.278 acc:89.51 | val loss:0.275 acc:89.51\n",
            "Epoch:0395 train loss:0.282 acc:89.47 | val loss:0.277 acc:89.35\n",
            "Epoch:0396 train loss:0.275 acc:89.71 | val loss:0.276 acc:89.43\n",
            "Epoch:0397 train loss:0.283 acc:89.75 | val loss:0.272 acc:89.65\n",
            "Epoch:0398 train loss:0.274 acc:89.71 | val loss:0.271 acc:89.90\n",
            "Epoch:0399 train loss:0.277 acc:90.06 | val loss:0.271 acc:89.67\n",
            "Epoch:0400 train loss:0.281 acc:89.61 | val loss:0.272 acc:89.45\n",
            "Epoch:0401 train loss:0.275 acc:89.90 | val loss:0.274 acc:89.45\n",
            "Epoch:0402 train loss:0.279 acc:89.57 | val loss:0.273 acc:89.52\n",
            "Epoch:0403 train loss:0.270 acc:90.14 | val loss:0.278 acc:89.65\n",
            "Epoch:0404 train loss:0.284 acc:89.60 | val loss:0.275 acc:89.65\n",
            "Epoch:0405 train loss:0.281 acc:89.54 | val loss:0.270 acc:89.81\n",
            "Epoch:0406 train loss:0.278 acc:89.79 | val loss:0.277 acc:89.73\n",
            "Epoch:0407 train loss:0.286 acc:89.19 | val loss:0.268 acc:90.00\n",
            "Epoch:0408 train loss:0.278 acc:89.72 | val loss:0.271 acc:89.65\n",
            "Epoch:0409 train loss:0.281 acc:89.20 | val loss:0.270 acc:89.76\n",
            "Epoch:0410 train loss:0.280 acc:89.77 | val loss:0.275 acc:89.52\n",
            "Epoch:0411 train loss:0.276 acc:89.81 | val loss:0.273 acc:89.73\n",
            "Epoch:0412 train loss:0.280 acc:89.77 | val loss:0.274 acc:89.76\n",
            "Epoch:0413 train loss:0.274 acc:89.80 | val loss:0.285 acc:89.51\n",
            "Epoch:0414 train loss:0.293 acc:89.24 | val loss:0.270 acc:89.94\n",
            "Epoch:0415 train loss:0.277 acc:89.87 | val loss:0.274 acc:89.57\n",
            "Epoch:0416 train loss:0.288 acc:89.74 | val loss:0.275 acc:89.79\n",
            "Epoch:0417 train loss:0.281 acc:89.63 | val loss:0.279 acc:89.60\n",
            "Epoch:0418 train loss:0.288 acc:88.89 | val loss:0.271 acc:89.71\n",
            "Epoch:0419 train loss:0.274 acc:89.87 | val loss:0.273 acc:89.60\n",
            "Epoch:0420 train loss:0.283 acc:89.37 | val loss:0.277 acc:89.83\n",
            "Epoch:0421 train loss:0.282 acc:89.69 | val loss:0.281 acc:89.65\n",
            "Epoch:0422 train loss:0.281 acc:89.36 | val loss:0.272 acc:89.62\n",
            "Epoch:0423 train loss:0.282 acc:89.46 | val loss:0.272 acc:89.57\n",
            "Epoch:0424 train loss:0.282 acc:89.28 | val loss:0.274 acc:89.76\n",
            "Epoch:0425 train loss:0.278 acc:89.60 | val loss:0.275 acc:89.83\n",
            "Epoch:0426 train loss:0.282 acc:89.78 | val loss:0.269 acc:89.89\n",
            "Epoch:0427 train loss:0.280 acc:89.41 | val loss:0.269 acc:89.92\n",
            "Epoch:0428 train loss:0.277 acc:90.08 | val loss:0.273 acc:89.67\n",
            "Epoch:0429 train loss:0.276 acc:89.92 | val loss:0.275 acc:89.67\n",
            "Epoch:0430 train loss:0.277 acc:89.68 | val loss:0.270 acc:89.83\n",
            "Epoch:0431 train loss:0.274 acc:89.63 | val loss:0.271 acc:90.02\n",
            "Epoch:0432 train loss:0.274 acc:89.89 | val loss:0.270 acc:89.68\n",
            "Epoch:0433 train loss:0.269 acc:90.13 | val loss:0.274 acc:89.78\n",
            "Epoch:0434 train loss:0.273 acc:90.02 | val loss:0.272 acc:89.71\n",
            "Epoch:0435 train loss:0.276 acc:89.75 | val loss:0.268 acc:89.84\n",
            "Epoch:0436 train loss:0.272 acc:89.81 | val loss:0.269 acc:90.02\n",
            "Epoch:0437 train loss:0.269 acc:90.18 | val loss:0.273 acc:89.89\n",
            "Epoch:0438 train loss:0.280 acc:89.84 | val loss:0.270 acc:89.87\n",
            "Epoch:0439 train loss:0.276 acc:89.92 | val loss:0.272 acc:89.64\n",
            "Epoch:0440 train loss:0.274 acc:89.82 | val loss:0.272 acc:89.71\n",
            "Epoch:0441 train loss:0.270 acc:90.06 | val loss:0.277 acc:89.90\n",
            "Epoch:0442 train loss:0.275 acc:89.76 | val loss:0.272 acc:89.86\n",
            "Epoch:0443 train loss:0.276 acc:90.13 | val loss:0.272 acc:89.68\n",
            "Epoch:0444 train loss:0.279 acc:89.98 | val loss:0.270 acc:89.81\n",
            "Epoch:0445 train loss:0.274 acc:89.56 | val loss:0.277 acc:89.68\n",
            "Epoch:0446 train loss:0.279 acc:89.47 | val loss:0.272 acc:89.86\n",
            "Epoch:0447 train loss:0.273 acc:89.92 | val loss:0.268 acc:89.78\n",
            "Epoch:0448 train loss:0.266 acc:90.28 | val loss:0.268 acc:89.90\n",
            "Epoch:0449 train loss:0.274 acc:89.92 | val loss:0.270 acc:89.90\n",
            "Epoch:0450 train loss:0.267 acc:90.32 | val loss:0.273 acc:89.83\n",
            "Epoch:0451 train loss:0.273 acc:90.09 | val loss:0.271 acc:89.83\n",
            "Epoch:0452 train loss:0.282 acc:89.22 | val loss:0.269 acc:89.73\n",
            "Epoch:0453 train loss:0.280 acc:90.05 | val loss:0.268 acc:89.86\n",
            "Epoch:0454 train loss:0.265 acc:90.08 | val loss:0.270 acc:90.03\n",
            "Epoch:0455 train loss:0.274 acc:90.00 | val loss:0.268 acc:90.00\n",
            "Epoch:0456 train loss:0.272 acc:89.70 | val loss:0.270 acc:89.68\n",
            "Epoch:0457 train loss:0.276 acc:89.99 | val loss:0.271 acc:89.75\n",
            "Epoch:0458 train loss:0.264 acc:90.00 | val loss:0.276 acc:89.62\n",
            "Epoch:0459 train loss:0.275 acc:89.59 | val loss:0.271 acc:89.81\n",
            "Epoch:0460 train loss:0.271 acc:89.91 | val loss:0.270 acc:89.90\n",
            "Epoch:0461 train loss:0.274 acc:89.76 | val loss:0.270 acc:89.89\n",
            "Epoch:0462 train loss:0.264 acc:90.20 | val loss:0.270 acc:89.86\n",
            "Epoch:0463 train loss:0.269 acc:90.07 | val loss:0.269 acc:89.81\n",
            "Epoch:0464 train loss:0.277 acc:89.65 | val loss:0.269 acc:89.84\n",
            "Epoch:0465 train loss:0.261 acc:90.31 | val loss:0.270 acc:89.86\n",
            "Epoch:0466 train loss:0.265 acc:90.15 | val loss:0.271 acc:89.87\n",
            "Epoch:0467 train loss:0.276 acc:89.67 | val loss:0.269 acc:89.94\n",
            "Epoch:0468 train loss:0.271 acc:89.91 | val loss:0.270 acc:89.81\n",
            "Epoch:0469 train loss:0.267 acc:90.16 | val loss:0.273 acc:89.76\n",
            "Epoch:0470 train loss:0.273 acc:89.93 | val loss:0.270 acc:89.97\n",
            "Epoch:0471 train loss:0.270 acc:90.07 | val loss:0.269 acc:90.06\n",
            "Epoch:0472 train loss:0.266 acc:90.18 | val loss:0.269 acc:90.05\n",
            "Epoch:0473 train loss:0.263 acc:90.31 | val loss:0.272 acc:89.86\n",
            "Epoch:0474 train loss:0.274 acc:89.97 | val loss:0.270 acc:89.83\n",
            "Epoch:0475 train loss:0.270 acc:89.68 | val loss:0.269 acc:90.08\n",
            "Epoch:0476 train loss:0.271 acc:90.09 | val loss:0.269 acc:90.05\n",
            "Epoch:0477 train loss:0.267 acc:89.83 | val loss:0.270 acc:89.98\n",
            "Epoch:0478 train loss:0.267 acc:90.08 | val loss:0.271 acc:89.84\n",
            "Epoch:0479 train loss:0.263 acc:90.09 | val loss:0.273 acc:89.81\n",
            "Epoch:0480 train loss:0.263 acc:90.29 | val loss:0.272 acc:89.94\n",
            "Epoch:0481 train loss:0.265 acc:90.10 | val loss:0.271 acc:89.98\n",
            "Epoch:0482 train loss:0.262 acc:90.34 | val loss:0.273 acc:89.90\n",
            "Epoch:0483 train loss:0.271 acc:90.28 | val loss:0.271 acc:89.90\n",
            "Epoch:0484 train loss:0.267 acc:90.03 | val loss:0.269 acc:89.83\n",
            "Epoch:0485 train loss:0.268 acc:90.13 | val loss:0.268 acc:89.95\n",
            "Epoch:0486 train loss:0.263 acc:90.20 | val loss:0.272 acc:89.95\n",
            "Epoch:0487 train loss:0.266 acc:90.34 | val loss:0.272 acc:89.86\n",
            "Epoch:0488 train loss:0.270 acc:90.25 | val loss:0.269 acc:89.92\n",
            "Epoch:0489 train loss:0.264 acc:90.31 | val loss:0.270 acc:90.00\n",
            "Epoch:0490 train loss:0.261 acc:90.17 | val loss:0.269 acc:89.98\n",
            "Epoch:0491 train loss:0.262 acc:90.39 | val loss:0.269 acc:89.75\n",
            "Epoch:0492 train loss:0.265 acc:90.26 | val loss:0.267 acc:90.03\n",
            "Epoch:0493 train loss:0.264 acc:90.30 | val loss:0.266 acc:90.11\n",
            "Epoch:0494 train loss:0.265 acc:90.12 | val loss:0.267 acc:90.06\n",
            "Epoch:0495 train loss:0.265 acc:90.19 | val loss:0.270 acc:89.95\n",
            "Epoch:0496 train loss:0.265 acc:90.14 | val loss:0.269 acc:89.86\n",
            "Epoch:0497 train loss:0.269 acc:89.94 | val loss:0.270 acc:89.83\n",
            "Epoch:0498 train loss:0.264 acc:90.16 | val loss:0.271 acc:89.78\n",
            "Epoch:0499 train loss:0.268 acc:89.96 | val loss:0.269 acc:89.97\n",
            "Epoch:0500 train loss:0.258 acc:90.31 | val loss:0.269 acc:90.00\n",
            "Epoch:0501 train loss:0.262 acc:90.25 | val loss:0.267 acc:90.06\n",
            "Epoch:0502 train loss:0.261 acc:90.37 | val loss:0.269 acc:89.98\n",
            "Epoch:0503 train loss:0.265 acc:90.27 | val loss:0.270 acc:89.84\n",
            "Epoch:0504 train loss:0.266 acc:89.97 | val loss:0.268 acc:89.86\n",
            "Epoch:0505 train loss:0.269 acc:89.83 | val loss:0.267 acc:90.13\n",
            "Epoch:0506 train loss:0.265 acc:90.02 | val loss:0.274 acc:90.00\n",
            "Epoch:0507 train loss:0.271 acc:89.62 | val loss:0.268 acc:89.97\n",
            "Epoch:0508 train loss:0.270 acc:89.88 | val loss:0.269 acc:89.83\n",
            "Epoch:0509 train loss:0.264 acc:90.50 | val loss:0.278 acc:89.89\n",
            "Epoch:0510 train loss:0.270 acc:90.17 | val loss:0.267 acc:90.00\n",
            "Epoch:0511 train loss:0.265 acc:90.47 | val loss:0.266 acc:89.98\n",
            "Epoch:0512 train loss:0.265 acc:90.02 | val loss:0.269 acc:89.95\n",
            "Epoch:0513 train loss:0.265 acc:89.84 | val loss:0.268 acc:89.86\n",
            "Epoch:0514 train loss:0.265 acc:90.15 | val loss:0.272 acc:89.52\n",
            "Epoch:0515 train loss:0.272 acc:89.82 | val loss:0.269 acc:89.78\n",
            "Epoch:0516 train loss:0.261 acc:90.64 | val loss:0.274 acc:89.95\n",
            "Epoch:0517 train loss:0.269 acc:89.75 | val loss:0.267 acc:89.89\n",
            "Epoch:0518 train loss:0.258 acc:90.03 | val loss:0.266 acc:90.02\n",
            "Epoch:0519 train loss:0.261 acc:90.50 | val loss:0.270 acc:89.86\n",
            "Epoch:0520 train loss:0.263 acc:90.08 | val loss:0.269 acc:89.86\n",
            "Epoch:0521 train loss:0.263 acc:90.36 | val loss:0.270 acc:89.90\n",
            "Epoch:0522 train loss:0.271 acc:90.11 | val loss:0.270 acc:89.81\n",
            "Epoch:0523 train loss:0.264 acc:90.33 | val loss:0.271 acc:89.86\n",
            "Epoch:0524 train loss:0.262 acc:89.97 | val loss:0.266 acc:90.13\n",
            "Epoch:0525 train loss:0.262 acc:90.36 | val loss:0.267 acc:90.03\n",
            "Epoch:0526 train loss:0.267 acc:90.13 | val loss:0.269 acc:89.92\n",
            "Epoch:0527 train loss:0.259 acc:90.42 | val loss:0.270 acc:89.84\n",
            "Epoch:0528 train loss:0.261 acc:90.21 | val loss:0.268 acc:90.14\n",
            "Epoch:0529 train loss:0.267 acc:90.10 | val loss:0.268 acc:90.08\n",
            "Epoch:0530 train loss:0.259 acc:90.02 | val loss:0.271 acc:89.95\n",
            "Epoch:0531 train loss:0.265 acc:90.28 | val loss:0.266 acc:90.10\n",
            "Epoch:0532 train loss:0.263 acc:90.50 | val loss:0.265 acc:90.05\n",
            "Epoch:0533 train loss:0.262 acc:90.46 | val loss:0.264 acc:90.17\n",
            "Epoch:0534 train loss:0.260 acc:90.30 | val loss:0.268 acc:90.05\n",
            "Epoch:0535 train loss:0.260 acc:90.31 | val loss:0.269 acc:89.97\n",
            "Epoch:0536 train loss:0.263 acc:90.34 | val loss:0.268 acc:89.97\n",
            "Epoch:0537 train loss:0.262 acc:90.40 | val loss:0.268 acc:90.05\n",
            "Epoch:0538 train loss:0.256 acc:90.51 | val loss:0.271 acc:90.00\n",
            "Epoch:0539 train loss:0.267 acc:90.00 | val loss:0.266 acc:90.25\n",
            "Epoch:0540 train loss:0.264 acc:90.02 | val loss:0.266 acc:90.08\n",
            "Epoch:0541 train loss:0.264 acc:90.52 | val loss:0.267 acc:90.06\n",
            "Epoch:0542 train loss:0.261 acc:90.37 | val loss:0.271 acc:89.68\n",
            "Epoch:0543 train loss:0.262 acc:90.12 | val loss:0.268 acc:90.06\n",
            "Epoch:0544 train loss:0.255 acc:90.38 | val loss:0.267 acc:90.16\n",
            "Epoch:0545 train loss:0.263 acc:90.31 | val loss:0.268 acc:90.14\n",
            "Epoch:0546 train loss:0.257 acc:90.64 | val loss:0.269 acc:90.06\n",
            "Epoch:0547 train loss:0.254 acc:90.68 | val loss:0.269 acc:90.00\n",
            "Epoch:0548 train loss:0.264 acc:90.06 | val loss:0.268 acc:90.03\n",
            "Epoch:0549 train loss:0.259 acc:90.38 | val loss:0.267 acc:90.10\n",
            "Epoch:0550 train loss:0.258 acc:90.54 | val loss:0.265 acc:90.21\n",
            "Epoch:0551 train loss:0.257 acc:90.15 | val loss:0.266 acc:90.21\n",
            "Epoch:0552 train loss:0.258 acc:90.71 | val loss:0.269 acc:90.00\n",
            "Epoch:0553 train loss:0.260 acc:90.29 | val loss:0.269 acc:90.10\n",
            "Epoch:0554 train loss:0.260 acc:90.53 | val loss:0.269 acc:90.10\n",
            "Epoch:0555 train loss:0.251 acc:90.59 | val loss:0.270 acc:90.06\n",
            "Epoch:0556 train loss:0.259 acc:90.53 | val loss:0.269 acc:90.16\n",
            "Epoch:0557 train loss:0.259 acc:90.39 | val loss:0.270 acc:90.05\n",
            "Epoch:0558 train loss:0.258 acc:90.42 | val loss:0.267 acc:90.11\n",
            "Epoch:0559 train loss:0.258 acc:90.48 | val loss:0.265 acc:90.22\n",
            "Epoch:0560 train loss:0.259 acc:90.23 | val loss:0.265 acc:90.27\n",
            "Epoch:0561 train loss:0.256 acc:90.54 | val loss:0.267 acc:90.19\n",
            "Epoch:0562 train loss:0.256 acc:90.62 | val loss:0.268 acc:90.21\n",
            "Epoch:0563 train loss:0.261 acc:90.47 | val loss:0.268 acc:90.22\n",
            "Epoch:0564 train loss:0.257 acc:90.44 | val loss:0.271 acc:89.97\n",
            "Epoch:0565 train loss:0.254 acc:90.50 | val loss:0.270 acc:90.10\n",
            "Epoch:0566 train loss:0.258 acc:90.20 | val loss:0.269 acc:90.11\n",
            "Epoch:0567 train loss:0.261 acc:90.19 | val loss:0.270 acc:90.08\n",
            "Epoch:0568 train loss:0.255 acc:90.50 | val loss:0.268 acc:90.13\n",
            "Epoch:0569 train loss:0.258 acc:90.56 | val loss:0.265 acc:90.10\n",
            "Epoch:0570 train loss:0.255 acc:90.59 | val loss:0.265 acc:90.14\n",
            "Epoch:0571 train loss:0.253 acc:91.00 | val loss:0.269 acc:90.05\n",
            "Epoch:0572 train loss:0.253 acc:90.44 | val loss:0.269 acc:89.94\n",
            "Epoch:0573 train loss:0.248 acc:91.03 | val loss:0.267 acc:90.17\n",
            "Epoch:0574 train loss:0.258 acc:90.48 | val loss:0.267 acc:90.16\n",
            "Epoch:0575 train loss:0.253 acc:90.35 | val loss:0.267 acc:90.17\n",
            "Epoch:0576 train loss:0.252 acc:90.92 | val loss:0.267 acc:90.17\n",
            "Epoch:0577 train loss:0.251 acc:90.63 | val loss:0.267 acc:90.27\n",
            "Epoch:0578 train loss:0.252 acc:90.57 | val loss:0.268 acc:90.25\n",
            "Epoch:0579 train loss:0.255 acc:90.58 | val loss:0.272 acc:90.05\n",
            "Epoch:0580 train loss:0.258 acc:90.46 | val loss:0.266 acc:90.25\n",
            "Epoch:0581 train loss:0.257 acc:90.57 | val loss:0.265 acc:90.33\n",
            "Epoch:0582 train loss:0.254 acc:90.75 | val loss:0.267 acc:90.10\n",
            "Epoch:0583 train loss:0.254 acc:90.89 | val loss:0.270 acc:90.06\n",
            "7 : 90.04\n",
            "Epoch:0001 train loss:1.098 acc:39.81 | val loss:1.090 acc:39.67\n",
            "Epoch:0002 train loss:1.090 acc:39.81 | val loss:1.084 acc:39.68\n",
            "Epoch:0003 train loss:1.083 acc:39.86 | val loss:1.076 acc:39.87\n",
            "Epoch:0004 train loss:1.075 acc:40.30 | val loss:1.067 acc:40.54\n",
            "Epoch:0005 train loss:1.066 acc:41.54 | val loss:1.056 acc:42.76\n",
            "Epoch:0006 train loss:1.056 acc:43.00 | val loss:1.046 acc:48.67\n",
            "Epoch:0007 train loss:1.045 acc:45.51 | val loss:1.043 acc:46.47\n",
            "Epoch:0008 train loss:1.045 acc:44.15 | val loss:1.036 acc:48.83\n",
            "Epoch:0009 train loss:1.039 acc:45.31 | val loss:1.024 acc:55.01\n",
            "Epoch:0010 train loss:1.026 acc:48.54 | val loss:1.012 acc:58.27\n",
            "Epoch:0011 train loss:1.014 acc:51.59 | val loss:0.998 acc:59.86\n",
            "Epoch:0012 train loss:1.000 acc:52.84 | val loss:0.981 acc:60.54\n",
            "Epoch:0013 train loss:0.981 acc:54.68 | val loss:0.959 acc:60.32\n",
            "Epoch:0014 train loss:0.963 acc:55.72 | val loss:0.932 acc:59.41\n",
            "Epoch:0015 train loss:0.937 acc:57.01 | val loss:0.901 acc:58.08\n",
            "Epoch:0016 train loss:0.910 acc:56.65 | val loss:0.869 acc:57.88\n",
            "Epoch:0017 train loss:0.882 acc:57.12 | val loss:0.836 acc:59.79\n",
            "Epoch:0018 train loss:0.855 acc:58.45 | val loss:0.807 acc:62.09\n",
            "Epoch:0019 train loss:0.826 acc:60.46 | val loss:0.771 acc:62.66\n",
            "Epoch:0020 train loss:0.797 acc:62.09 | val loss:0.736 acc:63.44\n",
            "Epoch:0021 train loss:0.770 acc:63.82 | val loss:0.718 acc:65.63\n",
            "Epoch:0022 train loss:0.752 acc:64.86 | val loss:0.680 acc:71.41\n",
            "Epoch:0023 train loss:0.720 acc:69.32 | val loss:0.654 acc:77.26\n",
            "Epoch:0024 train loss:0.694 acc:71.41 | val loss:0.620 acc:79.51\n",
            "Epoch:0025 train loss:0.659 acc:74.34 | val loss:0.594 acc:80.02\n",
            "Epoch:0026 train loss:0.652 acc:75.26 | val loss:0.582 acc:79.98\n",
            "Epoch:0027 train loss:0.629 acc:75.63 | val loss:0.542 acc:80.90\n",
            "Epoch:0028 train loss:0.594 acc:78.56 | val loss:0.529 acc:80.89\n",
            "Epoch:0029 train loss:0.586 acc:78.85 | val loss:0.521 acc:80.87\n",
            "Epoch:0030 train loss:0.584 acc:78.87 | val loss:0.498 acc:81.27\n",
            "Epoch:0031 train loss:0.554 acc:79.74 | val loss:0.497 acc:81.49\n",
            "Epoch:0032 train loss:0.556 acc:80.50 | val loss:0.483 acc:81.84\n",
            "Epoch:0033 train loss:0.538 acc:81.18 | val loss:0.486 acc:81.95\n",
            "Epoch:0034 train loss:0.541 acc:80.65 | val loss:0.478 acc:82.19\n",
            "Epoch:0035 train loss:0.537 acc:81.24 | val loss:0.467 acc:82.49\n",
            "Epoch:0036 train loss:0.520 acc:81.87 | val loss:0.467 acc:82.58\n",
            "Epoch:0037 train loss:0.515 acc:81.56 | val loss:0.457 acc:83.04\n",
            "Epoch:0038 train loss:0.497 acc:82.27 | val loss:0.448 acc:83.30\n",
            "Epoch:0039 train loss:0.500 acc:82.54 | val loss:0.442 acc:83.58\n",
            "Epoch:0040 train loss:0.488 acc:82.82 | val loss:0.441 acc:83.80\n",
            "Epoch:0041 train loss:0.482 acc:82.78 | val loss:0.436 acc:84.09\n",
            "Epoch:0042 train loss:0.476 acc:83.30 | val loss:0.430 acc:84.12\n",
            "Epoch:0043 train loss:0.476 acc:83.26 | val loss:0.427 acc:84.20\n",
            "Epoch:0044 train loss:0.473 acc:83.54 | val loss:0.422 acc:84.60\n",
            "Epoch:0045 train loss:0.461 acc:83.92 | val loss:0.420 acc:84.66\n",
            "Epoch:0046 train loss:0.459 acc:83.67 | val loss:0.416 acc:84.72\n",
            "Epoch:0047 train loss:0.449 acc:84.36 | val loss:0.412 acc:84.82\n",
            "Epoch:0048 train loss:0.448 acc:84.29 | val loss:0.409 acc:84.83\n",
            "Epoch:0049 train loss:0.440 acc:84.50 | val loss:0.406 acc:84.85\n",
            "Epoch:0050 train loss:0.440 acc:84.36 | val loss:0.405 acc:84.96\n",
            "Epoch:0051 train loss:0.435 acc:84.94 | val loss:0.402 acc:85.01\n",
            "Epoch:0052 train loss:0.435 acc:84.42 | val loss:0.399 acc:85.20\n",
            "Epoch:0053 train loss:0.428 acc:84.87 | val loss:0.396 acc:85.32\n",
            "Epoch:0054 train loss:0.434 acc:84.75 | val loss:0.393 acc:85.44\n",
            "Epoch:0055 train loss:0.424 acc:84.94 | val loss:0.393 acc:85.44\n",
            "Epoch:0056 train loss:0.416 acc:85.26 | val loss:0.388 acc:85.59\n",
            "Epoch:0057 train loss:0.420 acc:85.09 | val loss:0.386 acc:85.83\n",
            "Epoch:0058 train loss:0.412 acc:85.40 | val loss:0.383 acc:85.90\n",
            "Epoch:0059 train loss:0.410 acc:85.72 | val loss:0.382 acc:85.96\n",
            "Epoch:0060 train loss:0.416 acc:85.02 | val loss:0.380 acc:86.01\n",
            "Epoch:0061 train loss:0.413 acc:85.74 | val loss:0.376 acc:86.23\n",
            "Epoch:0062 train loss:0.402 acc:85.82 | val loss:0.377 acc:86.10\n",
            "Epoch:0063 train loss:0.407 acc:85.81 | val loss:0.371 acc:86.34\n",
            "Epoch:0064 train loss:0.400 acc:85.99 | val loss:0.373 acc:86.26\n",
            "Epoch:0065 train loss:0.401 acc:85.80 | val loss:0.368 acc:86.48\n",
            "Epoch:0066 train loss:0.395 acc:86.33 | val loss:0.367 acc:86.64\n",
            "Epoch:0067 train loss:0.400 acc:85.67 | val loss:0.365 acc:86.70\n",
            "Epoch:0068 train loss:0.396 acc:85.90 | val loss:0.363 acc:86.56\n",
            "Epoch:0069 train loss:0.383 acc:86.55 | val loss:0.363 acc:86.56\n",
            "Epoch:0070 train loss:0.388 acc:86.60 | val loss:0.359 acc:86.74\n",
            "Epoch:0071 train loss:0.390 acc:86.43 | val loss:0.359 acc:86.81\n",
            "Epoch:0072 train loss:0.395 acc:86.36 | val loss:0.357 acc:86.89\n",
            "Epoch:0073 train loss:0.382 acc:86.38 | val loss:0.356 acc:86.81\n",
            "Epoch:0074 train loss:0.377 acc:86.64 | val loss:0.356 acc:86.96\n",
            "Epoch:0075 train loss:0.379 acc:86.81 | val loss:0.354 acc:87.08\n",
            "Epoch:0076 train loss:0.381 acc:86.67 | val loss:0.352 acc:87.16\n",
            "Epoch:0077 train loss:0.378 acc:86.67 | val loss:0.353 acc:87.19\n",
            "Epoch:0078 train loss:0.381 acc:86.59 | val loss:0.350 acc:87.04\n",
            "Epoch:0079 train loss:0.371 acc:86.98 | val loss:0.352 acc:87.13\n",
            "Epoch:0080 train loss:0.380 acc:86.23 | val loss:0.348 acc:87.19\n",
            "Epoch:0081 train loss:0.367 acc:87.22 | val loss:0.350 acc:87.37\n",
            "Epoch:0082 train loss:0.374 acc:86.72 | val loss:0.348 acc:87.42\n",
            "Epoch:0083 train loss:0.374 acc:86.71 | val loss:0.346 acc:87.19\n",
            "Epoch:0084 train loss:0.370 acc:86.77 | val loss:0.347 acc:87.26\n",
            "Epoch:0085 train loss:0.369 acc:86.92 | val loss:0.344 acc:87.42\n",
            "Epoch:0086 train loss:0.370 acc:87.14 | val loss:0.344 acc:87.64\n",
            "Epoch:0087 train loss:0.371 acc:87.03 | val loss:0.341 acc:87.58\n",
            "Epoch:0088 train loss:0.369 acc:86.82 | val loss:0.341 acc:87.31\n",
            "Epoch:0089 train loss:0.362 acc:87.22 | val loss:0.342 acc:87.39\n",
            "Epoch:0090 train loss:0.363 acc:87.23 | val loss:0.339 acc:87.50\n",
            "Epoch:0091 train loss:0.359 acc:87.27 | val loss:0.340 acc:87.72\n",
            "Epoch:0092 train loss:0.365 acc:87.14 | val loss:0.339 acc:87.78\n",
            "Epoch:0093 train loss:0.355 acc:87.29 | val loss:0.337 acc:87.58\n",
            "Epoch:0094 train loss:0.362 acc:87.09 | val loss:0.337 acc:87.58\n",
            "Epoch:0095 train loss:0.360 acc:87.40 | val loss:0.335 acc:87.75\n",
            "Epoch:0096 train loss:0.355 acc:87.19 | val loss:0.335 acc:87.91\n",
            "Epoch:0097 train loss:0.354 acc:87.40 | val loss:0.334 acc:87.94\n",
            "Epoch:0098 train loss:0.353 acc:87.19 | val loss:0.333 acc:87.84\n",
            "Epoch:0099 train loss:0.355 acc:87.49 | val loss:0.333 acc:87.97\n",
            "Epoch:0100 train loss:0.354 acc:87.25 | val loss:0.331 acc:88.10\n",
            "Epoch:0101 train loss:0.357 acc:87.46 | val loss:0.332 acc:87.99\n",
            "Epoch:0102 train loss:0.357 acc:87.36 | val loss:0.330 acc:88.11\n",
            "Epoch:0103 train loss:0.355 acc:87.49 | val loss:0.330 acc:88.21\n",
            "Epoch:0104 train loss:0.346 acc:87.39 | val loss:0.331 acc:88.37\n",
            "Epoch:0105 train loss:0.346 acc:87.79 | val loss:0.328 acc:88.18\n",
            "Epoch:0106 train loss:0.347 acc:88.03 | val loss:0.331 acc:88.10\n",
            "Epoch:0107 train loss:0.356 acc:87.37 | val loss:0.327 acc:88.30\n",
            "Epoch:0108 train loss:0.345 acc:87.57 | val loss:0.329 acc:88.37\n",
            "Epoch:0109 train loss:0.352 acc:87.83 | val loss:0.327 acc:88.18\n",
            "Epoch:0110 train loss:0.341 acc:87.82 | val loss:0.326 acc:88.49\n",
            "Epoch:0111 train loss:0.344 acc:87.72 | val loss:0.329 acc:88.24\n",
            "Epoch:0112 train loss:0.340 acc:87.83 | val loss:0.324 acc:88.37\n",
            "Epoch:0113 train loss:0.346 acc:87.37 | val loss:0.328 acc:88.51\n",
            "Epoch:0114 train loss:0.349 acc:87.59 | val loss:0.324 acc:88.35\n",
            "Epoch:0115 train loss:0.342 acc:87.89 | val loss:0.325 acc:88.38\n",
            "Epoch:0116 train loss:0.339 acc:87.95 | val loss:0.324 acc:88.40\n",
            "Epoch:0117 train loss:0.341 acc:87.86 | val loss:0.321 acc:88.57\n",
            "Epoch:0118 train loss:0.345 acc:87.81 | val loss:0.323 acc:88.64\n",
            "Epoch:0119 train loss:0.342 acc:87.70 | val loss:0.320 acc:88.62\n",
            "Epoch:0120 train loss:0.342 acc:87.81 | val loss:0.321 acc:88.51\n",
            "Epoch:0121 train loss:0.341 acc:88.03 | val loss:0.319 acc:88.61\n",
            "Epoch:0122 train loss:0.337 acc:88.05 | val loss:0.320 acc:88.56\n",
            "Epoch:0123 train loss:0.340 acc:87.68 | val loss:0.319 acc:88.61\n",
            "Epoch:0124 train loss:0.344 acc:87.52 | val loss:0.319 acc:88.59\n",
            "Epoch:0125 train loss:0.338 acc:87.96 | val loss:0.318 acc:88.59\n",
            "Epoch:0126 train loss:0.340 acc:87.88 | val loss:0.317 acc:88.53\n",
            "Epoch:0127 train loss:0.338 acc:87.76 | val loss:0.317 acc:88.54\n",
            "Epoch:0128 train loss:0.340 acc:88.06 | val loss:0.315 acc:88.67\n",
            "Epoch:0129 train loss:0.332 acc:88.06 | val loss:0.316 acc:88.70\n",
            "Epoch:0130 train loss:0.330 acc:88.24 | val loss:0.315 acc:88.70\n",
            "Epoch:0131 train loss:0.333 acc:87.75 | val loss:0.316 acc:88.76\n",
            "Epoch:0132 train loss:0.333 acc:88.17 | val loss:0.314 acc:88.86\n",
            "Epoch:0133 train loss:0.330 acc:88.16 | val loss:0.315 acc:88.80\n",
            "Epoch:0134 train loss:0.332 acc:88.17 | val loss:0.317 acc:88.76\n",
            "Epoch:0135 train loss:0.330 acc:88.32 | val loss:0.312 acc:88.68\n",
            "Epoch:0136 train loss:0.326 acc:88.66 | val loss:0.318 acc:88.80\n",
            "Epoch:0137 train loss:0.337 acc:88.03 | val loss:0.312 acc:88.84\n",
            "Epoch:0138 train loss:0.329 acc:88.41 | val loss:0.316 acc:88.76\n",
            "Epoch:0139 train loss:0.334 acc:88.09 | val loss:0.313 acc:88.80\n",
            "Epoch:0140 train loss:0.327 acc:88.35 | val loss:0.315 acc:88.99\n",
            "Epoch:0141 train loss:0.331 acc:88.37 | val loss:0.314 acc:89.11\n",
            "Epoch:0142 train loss:0.338 acc:88.15 | val loss:0.312 acc:88.86\n",
            "Epoch:0143 train loss:0.325 acc:88.24 | val loss:0.316 acc:88.67\n",
            "Epoch:0144 train loss:0.331 acc:87.98 | val loss:0.310 acc:88.89\n",
            "Epoch:0145 train loss:0.338 acc:87.66 | val loss:0.312 acc:88.86\n",
            "Epoch:0146 train loss:0.331 acc:88.44 | val loss:0.311 acc:88.87\n",
            "Epoch:0147 train loss:0.324 acc:88.62 | val loss:0.308 acc:88.87\n",
            "Epoch:0148 train loss:0.330 acc:88.06 | val loss:0.309 acc:88.87\n",
            "Epoch:0149 train loss:0.327 acc:88.14 | val loss:0.308 acc:89.00\n",
            "Epoch:0150 train loss:0.327 acc:88.41 | val loss:0.308 acc:89.05\n",
            "Epoch:0151 train loss:0.320 acc:88.58 | val loss:0.309 acc:89.03\n",
            "Epoch:0152 train loss:0.322 acc:88.59 | val loss:0.309 acc:88.91\n",
            "Epoch:0153 train loss:0.323 acc:88.22 | val loss:0.309 acc:88.97\n",
            "Epoch:0154 train loss:0.329 acc:88.21 | val loss:0.308 acc:89.03\n",
            "Epoch:0155 train loss:0.323 acc:88.60 | val loss:0.309 acc:89.05\n",
            "Epoch:0156 train loss:0.317 acc:88.66 | val loss:0.307 acc:88.94\n",
            "Epoch:0157 train loss:0.326 acc:88.46 | val loss:0.306 acc:88.97\n",
            "Epoch:0158 train loss:0.317 acc:88.53 | val loss:0.307 acc:88.95\n",
            "Epoch:0159 train loss:0.316 acc:88.69 | val loss:0.306 acc:89.03\n",
            "Epoch:0160 train loss:0.317 acc:88.76 | val loss:0.305 acc:89.05\n",
            "Epoch:0161 train loss:0.309 acc:89.00 | val loss:0.304 acc:88.91\n",
            "Epoch:0162 train loss:0.324 acc:88.61 | val loss:0.306 acc:89.00\n",
            "Epoch:0163 train loss:0.327 acc:88.10 | val loss:0.303 acc:89.11\n",
            "Epoch:0164 train loss:0.321 acc:88.60 | val loss:0.306 acc:89.11\n",
            "Epoch:0165 train loss:0.320 acc:88.22 | val loss:0.305 acc:89.11\n",
            "Epoch:0166 train loss:0.323 acc:88.41 | val loss:0.303 acc:89.14\n",
            "Epoch:0167 train loss:0.318 acc:88.94 | val loss:0.304 acc:89.06\n",
            "Epoch:0168 train loss:0.314 acc:88.66 | val loss:0.303 acc:89.08\n",
            "Epoch:0169 train loss:0.318 acc:88.54 | val loss:0.308 acc:89.29\n",
            "Epoch:0170 train loss:0.324 acc:88.72 | val loss:0.303 acc:89.24\n",
            "Epoch:0171 train loss:0.317 acc:88.51 | val loss:0.305 acc:89.16\n",
            "Epoch:0172 train loss:0.320 acc:88.48 | val loss:0.302 acc:89.27\n",
            "Epoch:0173 train loss:0.322 acc:88.53 | val loss:0.301 acc:89.26\n",
            "Epoch:0174 train loss:0.319 acc:88.69 | val loss:0.302 acc:89.29\n",
            "Epoch:0175 train loss:0.322 acc:88.56 | val loss:0.299 acc:89.22\n",
            "Epoch:0176 train loss:0.311 acc:89.08 | val loss:0.301 acc:89.24\n",
            "Epoch:0177 train loss:0.317 acc:88.54 | val loss:0.299 acc:89.22\n",
            "Epoch:0178 train loss:0.313 acc:88.84 | val loss:0.300 acc:89.35\n",
            "Epoch:0179 train loss:0.312 acc:88.81 | val loss:0.300 acc:89.37\n",
            "Epoch:0180 train loss:0.314 acc:88.53 | val loss:0.300 acc:89.22\n",
            "Epoch:0181 train loss:0.311 acc:88.69 | val loss:0.300 acc:89.35\n",
            "Epoch:0182 train loss:0.315 acc:88.97 | val loss:0.300 acc:89.45\n",
            "Epoch:0183 train loss:0.310 acc:88.86 | val loss:0.300 acc:89.38\n",
            "Epoch:0184 train loss:0.306 acc:89.12 | val loss:0.300 acc:89.38\n",
            "Epoch:0185 train loss:0.308 acc:88.79 | val loss:0.299 acc:89.35\n",
            "Epoch:0186 train loss:0.310 acc:89.26 | val loss:0.299 acc:89.49\n",
            "Epoch:0187 train loss:0.315 acc:88.98 | val loss:0.300 acc:89.41\n",
            "Epoch:0188 train loss:0.305 acc:89.05 | val loss:0.298 acc:89.41\n",
            "Epoch:0189 train loss:0.309 acc:89.31 | val loss:0.298 acc:89.32\n",
            "Epoch:0190 train loss:0.305 acc:88.97 | val loss:0.297 acc:89.30\n",
            "Epoch:0191 train loss:0.314 acc:88.76 | val loss:0.296 acc:89.48\n",
            "Epoch:0192 train loss:0.306 acc:88.86 | val loss:0.297 acc:89.46\n",
            "Epoch:0193 train loss:0.305 acc:88.76 | val loss:0.296 acc:89.49\n",
            "Epoch:0194 train loss:0.305 acc:88.80 | val loss:0.296 acc:89.46\n",
            "Epoch:0195 train loss:0.309 acc:88.69 | val loss:0.297 acc:89.46\n",
            "Epoch:0196 train loss:0.311 acc:88.96 | val loss:0.297 acc:89.40\n",
            "Epoch:0197 train loss:0.308 acc:89.03 | val loss:0.296 acc:89.52\n",
            "Epoch:0198 train loss:0.304 acc:89.13 | val loss:0.296 acc:89.38\n",
            "Epoch:0199 train loss:0.307 acc:88.78 | val loss:0.295 acc:89.45\n",
            "Epoch:0200 train loss:0.303 acc:88.89 | val loss:0.296 acc:89.29\n",
            "Epoch:0201 train loss:0.309 acc:88.79 | val loss:0.294 acc:89.41\n",
            "Epoch:0202 train loss:0.306 acc:89.04 | val loss:0.293 acc:89.65\n",
            "Epoch:0203 train loss:0.306 acc:88.61 | val loss:0.294 acc:89.59\n",
            "Epoch:0204 train loss:0.308 acc:88.96 | val loss:0.294 acc:89.49\n",
            "Epoch:0205 train loss:0.303 acc:89.27 | val loss:0.294 acc:89.43\n",
            "Epoch:0206 train loss:0.306 acc:89.08 | val loss:0.295 acc:89.30\n",
            "Epoch:0207 train loss:0.303 acc:88.85 | val loss:0.293 acc:89.56\n",
            "Epoch:0208 train loss:0.310 acc:88.43 | val loss:0.297 acc:89.49\n",
            "Epoch:0209 train loss:0.304 acc:89.23 | val loss:0.294 acc:89.64\n",
            "Epoch:0210 train loss:0.303 acc:89.05 | val loss:0.295 acc:89.30\n",
            "Epoch:0211 train loss:0.304 acc:88.91 | val loss:0.294 acc:89.46\n",
            "Epoch:0212 train loss:0.301 acc:88.94 | val loss:0.294 acc:89.64\n",
            "Epoch:0213 train loss:0.305 acc:88.97 | val loss:0.292 acc:89.65\n",
            "Epoch:0214 train loss:0.306 acc:88.99 | val loss:0.291 acc:89.62\n",
            "Epoch:0215 train loss:0.302 acc:89.00 | val loss:0.291 acc:89.68\n",
            "Epoch:0216 train loss:0.304 acc:89.22 | val loss:0.290 acc:89.56\n",
            "Epoch:0217 train loss:0.305 acc:89.26 | val loss:0.290 acc:89.65\n",
            "Epoch:0218 train loss:0.296 acc:89.47 | val loss:0.290 acc:89.64\n",
            "Epoch:0219 train loss:0.306 acc:88.77 | val loss:0.291 acc:89.64\n",
            "Epoch:0220 train loss:0.304 acc:88.98 | val loss:0.291 acc:89.65\n",
            "Epoch:0221 train loss:0.297 acc:89.14 | val loss:0.292 acc:89.64\n",
            "Epoch:0222 train loss:0.302 acc:89.31 | val loss:0.293 acc:89.46\n",
            "Epoch:0223 train loss:0.302 acc:89.06 | val loss:0.292 acc:89.45\n",
            "Epoch:0224 train loss:0.303 acc:89.22 | val loss:0.291 acc:89.46\n",
            "Epoch:0225 train loss:0.302 acc:89.18 | val loss:0.289 acc:89.73\n",
            "Epoch:0226 train loss:0.303 acc:89.09 | val loss:0.289 acc:89.68\n",
            "Epoch:0227 train loss:0.293 acc:89.32 | val loss:0.287 acc:89.79\n",
            "Epoch:0228 train loss:0.302 acc:89.12 | val loss:0.288 acc:89.67\n",
            "Epoch:0229 train loss:0.295 acc:89.19 | val loss:0.289 acc:89.60\n",
            "Epoch:0230 train loss:0.289 acc:89.44 | val loss:0.291 acc:89.65\n",
            "Epoch:0231 train loss:0.296 acc:89.22 | val loss:0.291 acc:89.60\n",
            "Epoch:0232 train loss:0.291 acc:89.78 | val loss:0.292 acc:89.57\n",
            "Epoch:0233 train loss:0.292 acc:89.59 | val loss:0.294 acc:89.38\n",
            "Epoch:0234 train loss:0.293 acc:89.51 | val loss:0.292 acc:89.52\n",
            "Epoch:0235 train loss:0.299 acc:89.28 | val loss:0.290 acc:89.64\n",
            "Epoch:0236 train loss:0.292 acc:89.33 | val loss:0.289 acc:89.67\n",
            "Epoch:0237 train loss:0.294 acc:89.19 | val loss:0.288 acc:89.68\n",
            "Epoch:0238 train loss:0.295 acc:89.53 | val loss:0.286 acc:89.62\n",
            "Epoch:0239 train loss:0.300 acc:89.10 | val loss:0.290 acc:89.71\n",
            "Epoch:0240 train loss:0.293 acc:89.60 | val loss:0.287 acc:89.60\n",
            "Epoch:0241 train loss:0.296 acc:89.27 | val loss:0.289 acc:89.56\n",
            "Epoch:0242 train loss:0.294 acc:89.36 | val loss:0.289 acc:89.73\n",
            "Epoch:0243 train loss:0.293 acc:89.70 | val loss:0.295 acc:89.56\n",
            "Epoch:0244 train loss:0.297 acc:89.09 | val loss:0.290 acc:89.54\n",
            "Epoch:0245 train loss:0.294 acc:89.21 | val loss:0.292 acc:89.48\n",
            "Epoch:0246 train loss:0.296 acc:89.20 | val loss:0.287 acc:89.73\n",
            "Epoch:0247 train loss:0.293 acc:89.59 | val loss:0.286 acc:89.83\n",
            "Epoch:0248 train loss:0.297 acc:89.10 | val loss:0.285 acc:89.78\n",
            "Epoch:0249 train loss:0.287 acc:89.61 | val loss:0.287 acc:89.67\n",
            "Epoch:0250 train loss:0.295 acc:89.20 | val loss:0.287 acc:89.71\n",
            "Epoch:0251 train loss:0.288 acc:89.57 | val loss:0.287 acc:89.79\n",
            "Epoch:0252 train loss:0.291 acc:89.53 | val loss:0.289 acc:89.65\n",
            "Epoch:0253 train loss:0.289 acc:89.70 | val loss:0.290 acc:89.65\n",
            "Epoch:0254 train loss:0.295 acc:89.37 | val loss:0.289 acc:89.76\n",
            "Epoch:0255 train loss:0.291 acc:89.63 | val loss:0.290 acc:89.67\n",
            "Epoch:0256 train loss:0.289 acc:89.58 | val loss:0.287 acc:89.81\n",
            "Epoch:0257 train loss:0.288 acc:89.33 | val loss:0.287 acc:89.78\n",
            "Epoch:0258 train loss:0.295 acc:89.40 | val loss:0.287 acc:89.79\n",
            "Epoch:0259 train loss:0.295 acc:89.13 | val loss:0.285 acc:89.67\n",
            "Epoch:0260 train loss:0.291 acc:89.63 | val loss:0.286 acc:89.57\n",
            "Epoch:0261 train loss:0.296 acc:89.13 | val loss:0.284 acc:90.05\n",
            "Epoch:0262 train loss:0.287 acc:89.77 | val loss:0.285 acc:89.89\n",
            "Epoch:0263 train loss:0.288 acc:89.31 | val loss:0.285 acc:89.84\n",
            "Epoch:0264 train loss:0.290 acc:89.41 | val loss:0.288 acc:89.78\n",
            "Epoch:0265 train loss:0.290 acc:89.52 | val loss:0.288 acc:89.83\n",
            "Epoch:0266 train loss:0.291 acc:89.32 | val loss:0.286 acc:89.86\n",
            "Epoch:0267 train loss:0.286 acc:89.88 | val loss:0.287 acc:89.65\n",
            "Epoch:0268 train loss:0.289 acc:89.28 | val loss:0.287 acc:89.76\n",
            "Epoch:0269 train loss:0.283 acc:89.46 | val loss:0.287 acc:89.71\n",
            "Epoch:0270 train loss:0.288 acc:89.39 | val loss:0.288 acc:89.56\n",
            "Epoch:0271 train loss:0.284 acc:89.59 | val loss:0.285 acc:89.78\n",
            "Epoch:0272 train loss:0.290 acc:89.69 | val loss:0.283 acc:89.87\n",
            "Epoch:0273 train loss:0.285 acc:89.51 | val loss:0.282 acc:89.83\n",
            "Epoch:0274 train loss:0.286 acc:89.84 | val loss:0.283 acc:89.86\n",
            "Epoch:0275 train loss:0.289 acc:89.59 | val loss:0.283 acc:89.76\n",
            "Epoch:0276 train loss:0.290 acc:89.35 | val loss:0.282 acc:90.02\n",
            "Epoch:0277 train loss:0.283 acc:89.88 | val loss:0.283 acc:89.95\n",
            "Epoch:0278 train loss:0.288 acc:89.56 | val loss:0.283 acc:89.81\n",
            "Epoch:0279 train loss:0.291 acc:89.42 | val loss:0.283 acc:89.84\n",
            "Epoch:0280 train loss:0.283 acc:89.79 | val loss:0.284 acc:89.92\n",
            "Epoch:0281 train loss:0.287 acc:89.70 | val loss:0.285 acc:89.79\n",
            "Epoch:0282 train loss:0.287 acc:89.45 | val loss:0.284 acc:89.59\n",
            "Epoch:0283 train loss:0.287 acc:89.26 | val loss:0.281 acc:89.94\n",
            "Epoch:0284 train loss:0.286 acc:89.69 | val loss:0.286 acc:89.81\n",
            "Epoch:0285 train loss:0.290 acc:89.50 | val loss:0.283 acc:89.62\n",
            "Epoch:0286 train loss:0.277 acc:90.09 | val loss:0.284 acc:89.59\n",
            "Epoch:0287 train loss:0.285 acc:89.74 | val loss:0.285 acc:89.83\n",
            "Epoch:0288 train loss:0.280 acc:89.69 | val loss:0.282 acc:89.95\n",
            "Epoch:0289 train loss:0.291 acc:88.88 | val loss:0.283 acc:89.76\n",
            "Epoch:0290 train loss:0.285 acc:89.82 | val loss:0.284 acc:89.78\n",
            "Epoch:0291 train loss:0.281 acc:89.87 | val loss:0.285 acc:89.84\n",
            "Epoch:0292 train loss:0.286 acc:89.77 | val loss:0.282 acc:89.90\n",
            "Epoch:0293 train loss:0.282 acc:89.58 | val loss:0.280 acc:89.90\n",
            "Epoch:0294 train loss:0.286 acc:89.61 | val loss:0.279 acc:90.16\n",
            "Epoch:0295 train loss:0.279 acc:90.30 | val loss:0.279 acc:90.06\n",
            "Epoch:0296 train loss:0.282 acc:89.86 | val loss:0.281 acc:89.86\n",
            "Epoch:0297 train loss:0.287 acc:89.76 | val loss:0.281 acc:89.98\n",
            "Epoch:0298 train loss:0.281 acc:89.87 | val loss:0.284 acc:89.92\n",
            "Epoch:0299 train loss:0.289 acc:89.40 | val loss:0.280 acc:89.92\n",
            "Epoch:0300 train loss:0.287 acc:89.70 | val loss:0.279 acc:90.05\n",
            "Epoch:0301 train loss:0.281 acc:89.81 | val loss:0.279 acc:90.05\n",
            "Epoch:0302 train loss:0.283 acc:90.01 | val loss:0.277 acc:90.05\n",
            "Epoch:0303 train loss:0.280 acc:89.84 | val loss:0.279 acc:89.90\n",
            "Epoch:0304 train loss:0.280 acc:89.84 | val loss:0.282 acc:89.94\n",
            "Epoch:0305 train loss:0.282 acc:89.92 | val loss:0.278 acc:90.03\n",
            "Epoch:0306 train loss:0.281 acc:89.77 | val loss:0.279 acc:89.95\n",
            "Epoch:0307 train loss:0.281 acc:89.81 | val loss:0.280 acc:89.94\n",
            "Epoch:0308 train loss:0.278 acc:89.88 | val loss:0.282 acc:89.94\n",
            "Epoch:0309 train loss:0.279 acc:90.09 | val loss:0.283 acc:89.94\n",
            "Epoch:0310 train loss:0.279 acc:89.99 | val loss:0.281 acc:89.87\n",
            "Epoch:0311 train loss:0.277 acc:90.06 | val loss:0.280 acc:89.94\n",
            "Epoch:0312 train loss:0.284 acc:89.63 | val loss:0.279 acc:90.03\n",
            "Epoch:0313 train loss:0.277 acc:89.89 | val loss:0.279 acc:89.89\n",
            "Epoch:0314 train loss:0.275 acc:90.07 | val loss:0.280 acc:89.84\n",
            "Epoch:0315 train loss:0.286 acc:89.60 | val loss:0.280 acc:90.14\n",
            "Epoch:0316 train loss:0.278 acc:90.09 | val loss:0.278 acc:89.95\n",
            "Epoch:0317 train loss:0.281 acc:89.51 | val loss:0.279 acc:89.98\n",
            "Epoch:0318 train loss:0.278 acc:90.39 | val loss:0.280 acc:90.03\n",
            "Epoch:0319 train loss:0.278 acc:89.83 | val loss:0.282 acc:89.97\n",
            "Epoch:0320 train loss:0.278 acc:89.97 | val loss:0.279 acc:90.13\n",
            "Epoch:0321 train loss:0.273 acc:90.24 | val loss:0.278 acc:90.14\n",
            "Epoch:0322 train loss:0.275 acc:89.76 | val loss:0.278 acc:89.90\n",
            "Epoch:0323 train loss:0.273 acc:89.80 | val loss:0.276 acc:90.22\n",
            "Epoch:0324 train loss:0.279 acc:89.89 | val loss:0.276 acc:90.05\n",
            "Epoch:0325 train loss:0.276 acc:89.88 | val loss:0.281 acc:89.95\n",
            "Epoch:0326 train loss:0.285 acc:89.67 | val loss:0.277 acc:89.95\n",
            "Epoch:0327 train loss:0.278 acc:90.01 | val loss:0.276 acc:90.10\n",
            "Epoch:0328 train loss:0.275 acc:89.94 | val loss:0.281 acc:89.78\n",
            "Epoch:0329 train loss:0.286 acc:89.45 | val loss:0.279 acc:89.92\n",
            "Epoch:0330 train loss:0.274 acc:90.14 | val loss:0.278 acc:89.94\n",
            "Epoch:0331 train loss:0.268 acc:90.43 | val loss:0.279 acc:90.06\n",
            "Epoch:0332 train loss:0.275 acc:90.08 | val loss:0.278 acc:90.05\n",
            "Epoch:0333 train loss:0.276 acc:90.02 | val loss:0.280 acc:89.90\n",
            "Epoch:0334 train loss:0.271 acc:90.13 | val loss:0.279 acc:90.24\n",
            "Epoch:0335 train loss:0.275 acc:89.80 | val loss:0.279 acc:90.14\n",
            "Epoch:0336 train loss:0.272 acc:90.21 | val loss:0.278 acc:90.19\n",
            "Epoch:0337 train loss:0.278 acc:90.24 | val loss:0.276 acc:90.05\n",
            "Epoch:0338 train loss:0.269 acc:90.05 | val loss:0.277 acc:90.13\n",
            "Epoch:0339 train loss:0.272 acc:90.28 | val loss:0.278 acc:90.08\n",
            "Epoch:0340 train loss:0.272 acc:89.87 | val loss:0.278 acc:90.06\n",
            "Epoch:0341 train loss:0.268 acc:90.10 | val loss:0.277 acc:90.16\n",
            "Epoch:0342 train loss:0.271 acc:90.09 | val loss:0.281 acc:89.95\n",
            "Epoch:0343 train loss:0.277 acc:89.79 | val loss:0.279 acc:89.94\n",
            "Epoch:0344 train loss:0.270 acc:90.25 | val loss:0.281 acc:89.87\n",
            "Epoch:0345 train loss:0.273 acc:90.03 | val loss:0.280 acc:90.21\n",
            "Epoch:0346 train loss:0.274 acc:90.19 | val loss:0.278 acc:90.22\n",
            "Epoch:0347 train loss:0.270 acc:90.46 | val loss:0.277 acc:90.00\n",
            "Epoch:0348 train loss:0.273 acc:90.01 | val loss:0.277 acc:89.92\n",
            "Epoch:0349 train loss:0.263 acc:90.39 | val loss:0.279 acc:90.14\n",
            "Epoch:0350 train loss:0.263 acc:90.53 | val loss:0.280 acc:89.98\n",
            "Epoch:0351 train loss:0.275 acc:89.88 | val loss:0.280 acc:90.14\n",
            "Epoch:0352 train loss:0.275 acc:90.28 | val loss:0.279 acc:90.10\n",
            "Epoch:0353 train loss:0.268 acc:90.31 | val loss:0.276 acc:90.06\n",
            "Epoch:0354 train loss:0.271 acc:90.00 | val loss:0.278 acc:90.13\n",
            "Epoch:0355 train loss:0.265 acc:90.66 | val loss:0.277 acc:89.94\n",
            "Epoch:0356 train loss:0.266 acc:90.47 | val loss:0.278 acc:89.92\n",
            "Epoch:0357 train loss:0.269 acc:90.06 | val loss:0.277 acc:90.08\n",
            "Epoch:0358 train loss:0.272 acc:90.00 | val loss:0.274 acc:90.14\n",
            "Epoch:0359 train loss:0.267 acc:90.32 | val loss:0.275 acc:90.10\n",
            "Epoch:0360 train loss:0.266 acc:90.28 | val loss:0.279 acc:90.03\n",
            "Epoch:0361 train loss:0.273 acc:90.30 | val loss:0.275 acc:90.16\n",
            "Epoch:0362 train loss:0.269 acc:90.12 | val loss:0.274 acc:90.17\n",
            "Epoch:0363 train loss:0.271 acc:89.95 | val loss:0.274 acc:90.17\n",
            "Epoch:0364 train loss:0.274 acc:90.24 | val loss:0.274 acc:90.27\n",
            "Epoch:0365 train loss:0.269 acc:90.20 | val loss:0.276 acc:90.14\n",
            "Epoch:0366 train loss:0.266 acc:90.33 | val loss:0.277 acc:89.98\n",
            "Epoch:0367 train loss:0.271 acc:89.83 | val loss:0.278 acc:90.11\n",
            "Epoch:0368 train loss:0.267 acc:89.70 | val loss:0.278 acc:90.11\n",
            "Epoch:0369 train loss:0.274 acc:89.93 | val loss:0.279 acc:89.92\n",
            "Epoch:0370 train loss:0.270 acc:90.10 | val loss:0.275 acc:90.24\n",
            "Epoch:0371 train loss:0.271 acc:90.23 | val loss:0.280 acc:89.87\n",
            "Epoch:0372 train loss:0.274 acc:90.23 | val loss:0.274 acc:90.00\n",
            "Epoch:0373 train loss:0.269 acc:90.17 | val loss:0.274 acc:90.08\n",
            "Epoch:0374 train loss:0.270 acc:89.95 | val loss:0.279 acc:89.92\n",
            "Epoch:0375 train loss:0.274 acc:89.98 | val loss:0.275 acc:90.08\n",
            "Epoch:0376 train loss:0.271 acc:90.21 | val loss:0.277 acc:89.94\n",
            "Epoch:0377 train loss:0.273 acc:90.63 | val loss:0.281 acc:89.87\n",
            "Epoch:0378 train loss:0.267 acc:90.24 | val loss:0.277 acc:89.92\n",
            "Epoch:0379 train loss:0.267 acc:90.42 | val loss:0.282 acc:89.67\n",
            "Epoch:0380 train loss:0.275 acc:90.01 | val loss:0.279 acc:90.02\n",
            "Epoch:0381 train loss:0.269 acc:90.19 | val loss:0.282 acc:89.79\n",
            "Epoch:0382 train loss:0.284 acc:89.76 | val loss:0.280 acc:89.79\n",
            "Epoch:0383 train loss:0.279 acc:89.38 | val loss:0.273 acc:90.11\n",
            "Epoch:0384 train loss:0.271 acc:90.21 | val loss:0.282 acc:89.86\n",
            "Epoch:0385 train loss:0.282 acc:89.76 | val loss:0.272 acc:90.03\n",
            "Epoch:0386 train loss:0.263 acc:90.47 | val loss:0.282 acc:89.65\n",
            "Epoch:0387 train loss:0.273 acc:90.09 | val loss:0.276 acc:90.08\n",
            "Epoch:0388 train loss:0.263 acc:90.48 | val loss:0.291 acc:89.65\n",
            "Epoch:0389 train loss:0.287 acc:89.19 | val loss:0.283 acc:89.60\n",
            "Epoch:0390 train loss:0.279 acc:89.79 | val loss:0.283 acc:89.64\n",
            "Epoch:0391 train loss:0.279 acc:89.84 | val loss:0.278 acc:89.90\n",
            "Epoch:0392 train loss:0.272 acc:90.27 | val loss:0.284 acc:89.78\n",
            "Epoch:0393 train loss:0.276 acc:89.64 | val loss:0.272 acc:90.06\n",
            "Epoch:0394 train loss:0.262 acc:90.65 | val loss:0.284 acc:89.52\n",
            "Epoch:0395 train loss:0.282 acc:89.41 | val loss:0.274 acc:90.03\n",
            "Epoch:0396 train loss:0.271 acc:90.10 | val loss:0.290 acc:89.65\n",
            "Epoch:0397 train loss:0.278 acc:89.64 | val loss:0.281 acc:89.68\n",
            "Epoch:0398 train loss:0.268 acc:90.25 | val loss:0.286 acc:89.49\n",
            "Epoch:0399 train loss:0.278 acc:89.69 | val loss:0.273 acc:90.08\n",
            "Epoch:0400 train loss:0.267 acc:90.43 | val loss:0.281 acc:89.83\n",
            "Epoch:0401 train loss:0.269 acc:90.07 | val loss:0.272 acc:90.14\n",
            "Epoch:0402 train loss:0.265 acc:90.30 | val loss:0.280 acc:89.75\n",
            "Epoch:0403 train loss:0.277 acc:89.74 | val loss:0.274 acc:90.00\n",
            "Epoch:0404 train loss:0.262 acc:90.20 | val loss:0.277 acc:89.94\n",
            "Epoch:0405 train loss:0.271 acc:90.09 | val loss:0.276 acc:89.98\n",
            "Epoch:0406 train loss:0.265 acc:90.39 | val loss:0.275 acc:90.10\n",
            "Epoch:0407 train loss:0.260 acc:90.29 | val loss:0.279 acc:89.76\n",
            "Epoch:0408 train loss:0.264 acc:90.45 | val loss:0.278 acc:90.02\n",
            "Epoch:0409 train loss:0.267 acc:90.38 | val loss:0.276 acc:90.05\n",
            "Epoch:0410 train loss:0.262 acc:90.46 | val loss:0.276 acc:89.87\n",
            "Epoch:0411 train loss:0.266 acc:90.69 | val loss:0.277 acc:89.98\n",
            "Epoch:0412 train loss:0.272 acc:90.25 | val loss:0.276 acc:89.95\n",
            "Epoch:0413 train loss:0.259 acc:90.37 | val loss:0.278 acc:89.95\n",
            "Epoch:0414 train loss:0.264 acc:90.40 | val loss:0.274 acc:90.22\n",
            "Epoch:0415 train loss:0.266 acc:90.43 | val loss:0.272 acc:90.02\n",
            "Epoch:0416 train loss:0.264 acc:90.25 | val loss:0.274 acc:89.97\n",
            "Epoch:0417 train loss:0.263 acc:90.38 | val loss:0.273 acc:90.06\n",
            "Epoch:0418 train loss:0.269 acc:90.31 | val loss:0.278 acc:90.08\n",
            "Epoch:0419 train loss:0.261 acc:90.36 | val loss:0.278 acc:89.86\n",
            "Epoch:0420 train loss:0.261 acc:90.23 | val loss:0.276 acc:90.14\n",
            "Epoch:0421 train loss:0.268 acc:90.31 | val loss:0.275 acc:90.11\n",
            "Epoch:0422 train loss:0.251 acc:90.90 | val loss:0.275 acc:90.00\n",
            "Epoch:0423 train loss:0.262 acc:90.38 | val loss:0.275 acc:90.14\n",
            "Epoch:0424 train loss:0.261 acc:90.67 | val loss:0.279 acc:90.03\n",
            "Epoch:0425 train loss:0.264 acc:90.24 | val loss:0.277 acc:89.95\n",
            "Epoch:0426 train loss:0.257 acc:90.72 | val loss:0.274 acc:90.03\n",
            "Epoch:0427 train loss:0.262 acc:90.68 | val loss:0.272 acc:90.08\n",
            "Epoch:0428 train loss:0.270 acc:89.75 | val loss:0.272 acc:90.10\n",
            "Epoch:0429 train loss:0.255 acc:90.68 | val loss:0.275 acc:90.14\n",
            "Epoch:0430 train loss:0.259 acc:90.66 | val loss:0.277 acc:90.00\n",
            "Epoch:0431 train loss:0.260 acc:90.61 | val loss:0.278 acc:89.98\n",
            "Epoch:0432 train loss:0.263 acc:90.62 | val loss:0.275 acc:90.08\n",
            "Epoch:0433 train loss:0.262 acc:90.36 | val loss:0.276 acc:89.81\n",
            "Epoch:0434 train loss:0.259 acc:90.36 | val loss:0.274 acc:89.97\n",
            "Epoch:0435 train loss:0.258 acc:90.23 | val loss:0.275 acc:90.06\n",
            "Epoch:0436 train loss:0.259 acc:90.71 | val loss:0.276 acc:90.06\n",
            "Epoch:0437 train loss:0.266 acc:90.42 | val loss:0.274 acc:90.10\n",
            "Epoch:0438 train loss:0.260 acc:90.21 | val loss:0.273 acc:89.94\n",
            "Epoch:0439 train loss:0.261 acc:90.62 | val loss:0.273 acc:90.08\n",
            "Epoch:0440 train loss:0.252 acc:90.98 | val loss:0.274 acc:89.89\n",
            "Epoch:0441 train loss:0.266 acc:90.26 | val loss:0.274 acc:90.17\n",
            "Epoch:0442 train loss:0.253 acc:90.83 | val loss:0.274 acc:90.10\n",
            "Epoch:0443 train loss:0.261 acc:90.34 | val loss:0.271 acc:90.27\n",
            "Epoch:0444 train loss:0.260 acc:90.63 | val loss:0.271 acc:90.25\n",
            "Epoch:0445 train loss:0.267 acc:90.55 | val loss:0.270 acc:90.25\n",
            "Epoch:0446 train loss:0.254 acc:90.74 | val loss:0.271 acc:90.24\n",
            "Epoch:0447 train loss:0.260 acc:90.30 | val loss:0.272 acc:90.21\n",
            "Epoch:0448 train loss:0.253 acc:90.75 | val loss:0.276 acc:90.03\n",
            "Epoch:0449 train loss:0.265 acc:90.35 | val loss:0.274 acc:90.11\n",
            "Epoch:0450 train loss:0.253 acc:90.71 | val loss:0.273 acc:90.33\n",
            "Epoch:0451 train loss:0.255 acc:90.64 | val loss:0.273 acc:90.24\n",
            "Epoch:0452 train loss:0.262 acc:90.44 | val loss:0.271 acc:90.30\n",
            "Epoch:0453 train loss:0.248 acc:91.10 | val loss:0.272 acc:90.24\n",
            "Epoch:0454 train loss:0.254 acc:90.94 | val loss:0.271 acc:90.17\n",
            "Epoch:0455 train loss:0.258 acc:90.69 | val loss:0.270 acc:90.48\n",
            "Epoch:0456 train loss:0.253 acc:90.58 | val loss:0.269 acc:90.35\n",
            "Epoch:0457 train loss:0.250 acc:90.87 | val loss:0.270 acc:90.29\n",
            "Epoch:0458 train loss:0.251 acc:90.48 | val loss:0.271 acc:90.33\n",
            "Epoch:0459 train loss:0.255 acc:91.01 | val loss:0.273 acc:90.25\n",
            "Epoch:0460 train loss:0.255 acc:90.93 | val loss:0.272 acc:90.22\n",
            "Epoch:0461 train loss:0.258 acc:90.50 | val loss:0.275 acc:90.19\n",
            "Epoch:0462 train loss:0.263 acc:90.49 | val loss:0.270 acc:90.27\n",
            "Epoch:0463 train loss:0.254 acc:90.50 | val loss:0.273 acc:89.98\n",
            "Epoch:0464 train loss:0.258 acc:90.48 | val loss:0.268 acc:90.36\n",
            "Epoch:0465 train loss:0.253 acc:90.80 | val loss:0.270 acc:90.16\n",
            "Epoch:0466 train loss:0.252 acc:91.02 | val loss:0.271 acc:90.10\n",
            "Epoch:0467 train loss:0.254 acc:90.68 | val loss:0.275 acc:90.11\n",
            "Epoch:0468 train loss:0.256 acc:90.75 | val loss:0.272 acc:90.27\n",
            "Epoch:0469 train loss:0.254 acc:90.87 | val loss:0.275 acc:90.16\n",
            "Epoch:0470 train loss:0.260 acc:90.44 | val loss:0.271 acc:90.21\n",
            "Epoch:0471 train loss:0.264 acc:90.14 | val loss:0.275 acc:90.17\n",
            "Epoch:0472 train loss:0.263 acc:90.32 | val loss:0.270 acc:90.32\n",
            "Epoch:0473 train loss:0.252 acc:91.06 | val loss:0.270 acc:90.25\n",
            "Epoch:0474 train loss:0.262 acc:90.37 | val loss:0.270 acc:90.29\n",
            "Epoch:0475 train loss:0.252 acc:90.82 | val loss:0.273 acc:90.38\n",
            "Epoch:0476 train loss:0.261 acc:90.54 | val loss:0.271 acc:90.33\n",
            "Epoch:0477 train loss:0.253 acc:90.57 | val loss:0.271 acc:90.29\n",
            "Epoch:0478 train loss:0.253 acc:90.95 | val loss:0.272 acc:90.10\n",
            "Epoch:0479 train loss:0.247 acc:90.82 | val loss:0.272 acc:90.35\n",
            "Epoch:0480 train loss:0.256 acc:90.46 | val loss:0.273 acc:90.36\n",
            "Epoch:0481 train loss:0.251 acc:90.85 | val loss:0.272 acc:90.33\n",
            "Epoch:0482 train loss:0.254 acc:91.01 | val loss:0.271 acc:90.19\n",
            "Epoch:0483 train loss:0.256 acc:90.55 | val loss:0.271 acc:90.29\n",
            "Epoch:0484 train loss:0.251 acc:90.75 | val loss:0.272 acc:90.27\n",
            "Epoch:0485 train loss:0.252 acc:91.04 | val loss:0.272 acc:90.22\n",
            "Epoch:0486 train loss:0.251 acc:90.61 | val loss:0.270 acc:90.41\n",
            "Epoch:0487 train loss:0.254 acc:91.02 | val loss:0.271 acc:90.19\n",
            "Epoch:0488 train loss:0.248 acc:91.11 | val loss:0.270 acc:90.21\n",
            "Epoch:0489 train loss:0.254 acc:90.89 | val loss:0.272 acc:90.29\n",
            "Epoch:0490 train loss:0.253 acc:90.96 | val loss:0.272 acc:90.11\n",
            "Epoch:0491 train loss:0.253 acc:90.77 | val loss:0.272 acc:90.10\n",
            "Epoch:0492 train loss:0.253 acc:90.47 | val loss:0.275 acc:89.92\n",
            "Epoch:0493 train loss:0.258 acc:90.57 | val loss:0.273 acc:90.17\n",
            "Epoch:0494 train loss:0.244 acc:91.10 | val loss:0.277 acc:90.08\n",
            "Epoch:0495 train loss:0.259 acc:90.52 | val loss:0.275 acc:90.14\n",
            "Epoch:0496 train loss:0.245 acc:91.00 | val loss:0.277 acc:89.94\n",
            "Epoch:0497 train loss:0.254 acc:90.75 | val loss:0.274 acc:90.16\n",
            "Epoch:0498 train loss:0.244 acc:91.00 | val loss:0.275 acc:90.03\n",
            "Epoch:0499 train loss:0.254 acc:90.50 | val loss:0.273 acc:90.19\n",
            "Epoch:0500 train loss:0.245 acc:91.11 | val loss:0.273 acc:90.16\n",
            "Epoch:0501 train loss:0.255 acc:90.73 | val loss:0.271 acc:90.14\n",
            "Epoch:0502 train loss:0.247 acc:90.95 | val loss:0.271 acc:90.05\n",
            "Epoch:0503 train loss:0.247 acc:91.00 | val loss:0.271 acc:90.27\n",
            "Epoch:0504 train loss:0.246 acc:90.99 | val loss:0.273 acc:90.16\n",
            "Epoch:0505 train loss:0.251 acc:90.83 | val loss:0.276 acc:90.06\n",
            "Epoch:0506 train loss:0.253 acc:90.75 | val loss:0.274 acc:90.11\n",
            "Epoch:0507 train loss:0.254 acc:90.86 | val loss:0.274 acc:90.14\n",
            "Epoch:0508 train loss:0.253 acc:90.89 | val loss:0.271 acc:90.25\n",
            "Epoch:0509 train loss:0.254 acc:90.68 | val loss:0.271 acc:90.19\n",
            "Epoch:0510 train loss:0.251 acc:90.84 | val loss:0.270 acc:90.22\n",
            "Epoch:0511 train loss:0.241 acc:91.40 | val loss:0.270 acc:90.21\n",
            "Epoch:0512 train loss:0.247 acc:90.85 | val loss:0.269 acc:90.22\n",
            "Epoch:0513 train loss:0.256 acc:90.53 | val loss:0.270 acc:90.19\n",
            "Epoch:0514 train loss:0.246 acc:91.33 | val loss:0.272 acc:90.36\n",
            "8 : 89.20\n",
            "Epoch:0001 train loss:1.113 acc:21.39 | val loss:1.103 acc:40.06\n",
            "Epoch:0002 train loss:1.102 acc:38.48 | val loss:1.089 acc:40.06\n",
            "Epoch:0003 train loss:1.090 acc:39.71 | val loss:1.070 acc:40.06\n",
            "Epoch:0004 train loss:1.074 acc:39.83 | val loss:1.049 acc:40.06\n",
            "Epoch:0005 train loss:1.057 acc:40.43 | val loss:1.036 acc:40.06\n",
            "Epoch:0006 train loss:1.054 acc:42.82 | val loss:1.027 acc:50.87\n",
            "Epoch:0007 train loss:1.046 acc:43.79 | val loss:1.017 acc:51.35\n",
            "Epoch:0008 train loss:1.031 acc:43.64 | val loss:1.008 acc:53.55\n",
            "Epoch:0009 train loss:1.021 acc:45.84 | val loss:0.999 acc:58.51\n",
            "Epoch:0010 train loss:1.010 acc:49.85 | val loss:0.987 acc:63.12\n",
            "Epoch:0011 train loss:1.000 acc:51.97 | val loss:0.972 acc:64.07\n",
            "Epoch:0012 train loss:0.985 acc:52.70 | val loss:0.953 acc:64.42\n",
            "Epoch:0013 train loss:0.966 acc:54.04 | val loss:0.930 acc:65.59\n",
            "Epoch:0014 train loss:0.946 acc:54.98 | val loss:0.905 acc:66.74\n",
            "Epoch:0015 train loss:0.925 acc:55.51 | val loss:0.878 acc:65.69\n",
            "Epoch:0016 train loss:0.902 acc:57.75 | val loss:0.851 acc:63.45\n",
            "Epoch:0017 train loss:0.883 acc:57.76 | val loss:0.823 acc:63.38\n",
            "Epoch:0018 train loss:0.857 acc:59.09 | val loss:0.794 acc:66.04\n",
            "Epoch:0019 train loss:0.826 acc:61.27 | val loss:0.764 acc:72.11\n",
            "Epoch:0020 train loss:0.797 acc:63.92 | val loss:0.728 acc:75.99\n",
            "Epoch:0021 train loss:0.763 acc:67.17 | val loss:0.686 acc:77.31\n",
            "Epoch:0022 train loss:0.734 acc:70.01 | val loss:0.649 acc:77.83\n",
            "Epoch:0023 train loss:0.700 acc:72.28 | val loss:0.616 acc:80.27\n",
            "Epoch:0024 train loss:0.671 acc:74.67 | val loss:0.600 acc:79.87\n",
            "Epoch:0025 train loss:0.654 acc:76.58 | val loss:0.572 acc:82.31\n",
            "Epoch:0026 train loss:0.633 acc:78.78 | val loss:0.552 acc:82.28\n",
            "Epoch:0027 train loss:0.607 acc:80.15 | val loss:0.535 acc:82.36\n",
            "Epoch:0028 train loss:0.596 acc:80.32 | val loss:0.522 acc:83.04\n",
            "Epoch:0029 train loss:0.592 acc:80.16 | val loss:0.546 acc:82.22\n",
            "Epoch:0030 train loss:0.609 acc:80.27 | val loss:0.534 acc:81.32\n",
            "Epoch:0031 train loss:0.592 acc:79.74 | val loss:0.503 acc:83.00\n",
            "Epoch:0032 train loss:0.567 acc:81.36 | val loss:0.508 acc:82.74\n",
            "Epoch:0033 train loss:0.568 acc:81.22 | val loss:0.481 acc:83.55\n",
            "Epoch:0034 train loss:0.536 acc:82.20 | val loss:0.505 acc:82.01\n",
            "Epoch:0035 train loss:0.572 acc:80.51 | val loss:0.469 acc:84.04\n",
            "Epoch:0036 train loss:0.530 acc:82.01 | val loss:0.477 acc:83.50\n",
            "Epoch:0037 train loss:0.539 acc:81.76 | val loss:0.456 acc:83.77\n",
            "Epoch:0038 train loss:0.516 acc:81.80 | val loss:0.455 acc:83.99\n",
            "Epoch:0039 train loss:0.515 acc:82.17 | val loss:0.458 acc:83.76\n",
            "Epoch:0040 train loss:0.516 acc:82.07 | val loss:0.436 acc:84.48\n",
            "Epoch:0041 train loss:0.504 acc:82.63 | val loss:0.434 acc:84.44\n",
            "Epoch:0042 train loss:0.492 acc:83.32 | val loss:0.438 acc:84.22\n",
            "Epoch:0043 train loss:0.502 acc:82.65 | val loss:0.425 acc:84.50\n",
            "Epoch:0044 train loss:0.491 acc:82.78 | val loss:0.417 acc:84.94\n",
            "Epoch:0045 train loss:0.476 acc:83.13 | val loss:0.424 acc:84.87\n",
            "Epoch:0046 train loss:0.483 acc:83.06 | val loss:0.418 acc:84.99\n",
            "Epoch:0047 train loss:0.483 acc:82.76 | val loss:0.404 acc:85.34\n",
            "Epoch:0048 train loss:0.461 acc:83.67 | val loss:0.404 acc:85.18\n",
            "Epoch:0049 train loss:0.459 acc:84.18 | val loss:0.406 acc:85.21\n",
            "Epoch:0050 train loss:0.475 acc:83.08 | val loss:0.395 acc:85.59\n",
            "Epoch:0051 train loss:0.456 acc:83.91 | val loss:0.391 acc:85.71\n",
            "Epoch:0052 train loss:0.453 acc:84.33 | val loss:0.396 acc:85.47\n",
            "Epoch:0053 train loss:0.457 acc:83.80 | val loss:0.390 acc:85.64\n",
            "Epoch:0054 train loss:0.453 acc:84.03 | val loss:0.382 acc:85.78\n",
            "Epoch:0055 train loss:0.441 acc:84.44 | val loss:0.382 acc:85.64\n",
            "Epoch:0056 train loss:0.448 acc:84.33 | val loss:0.380 acc:86.01\n",
            "Epoch:0057 train loss:0.440 acc:84.49 | val loss:0.375 acc:86.39\n",
            "Epoch:0058 train loss:0.432 acc:84.60 | val loss:0.375 acc:86.34\n",
            "Epoch:0059 train loss:0.431 acc:84.87 | val loss:0.373 acc:86.35\n",
            "Epoch:0060 train loss:0.428 acc:84.97 | val loss:0.368 acc:86.45\n",
            "Epoch:0061 train loss:0.426 acc:84.93 | val loss:0.369 acc:86.26\n",
            "Epoch:0062 train loss:0.433 acc:84.55 | val loss:0.367 acc:86.21\n",
            "Epoch:0063 train loss:0.425 acc:84.63 | val loss:0.361 acc:86.62\n",
            "Epoch:0064 train loss:0.421 acc:84.93 | val loss:0.361 acc:86.69\n",
            "Epoch:0065 train loss:0.419 acc:85.15 | val loss:0.361 acc:86.75\n",
            "Epoch:0066 train loss:0.419 acc:85.21 | val loss:0.356 acc:86.93\n",
            "Epoch:0067 train loss:0.413 acc:85.62 | val loss:0.353 acc:86.99\n",
            "Epoch:0068 train loss:0.413 acc:85.14 | val loss:0.353 acc:86.86\n",
            "Epoch:0069 train loss:0.412 acc:85.34 | val loss:0.351 acc:87.08\n",
            "Epoch:0070 train loss:0.404 acc:85.72 | val loss:0.349 acc:87.10\n",
            "Epoch:0071 train loss:0.410 acc:85.51 | val loss:0.346 acc:87.21\n",
            "Epoch:0072 train loss:0.419 acc:85.74 | val loss:0.344 acc:87.23\n",
            "Epoch:0073 train loss:0.406 acc:85.43 | val loss:0.342 acc:87.48\n",
            "Epoch:0074 train loss:0.400 acc:85.79 | val loss:0.341 acc:87.50\n",
            "Epoch:0075 train loss:0.401 acc:85.54 | val loss:0.340 acc:87.54\n",
            "Epoch:0076 train loss:0.400 acc:85.83 | val loss:0.339 acc:87.58\n",
            "Epoch:0077 train loss:0.393 acc:86.08 | val loss:0.338 acc:87.61\n",
            "Epoch:0078 train loss:0.392 acc:85.88 | val loss:0.336 acc:87.67\n",
            "Epoch:0079 train loss:0.395 acc:86.35 | val loss:0.334 acc:87.81\n",
            "Epoch:0080 train loss:0.392 acc:85.89 | val loss:0.332 acc:88.00\n",
            "Epoch:0081 train loss:0.392 acc:86.19 | val loss:0.331 acc:87.91\n",
            "Epoch:0082 train loss:0.388 acc:85.99 | val loss:0.330 acc:88.07\n",
            "Epoch:0083 train loss:0.383 acc:86.55 | val loss:0.330 acc:87.96\n",
            "Epoch:0084 train loss:0.385 acc:86.44 | val loss:0.330 acc:87.83\n",
            "Epoch:0085 train loss:0.387 acc:86.38 | val loss:0.328 acc:88.00\n",
            "Epoch:0086 train loss:0.387 acc:86.36 | val loss:0.327 acc:87.97\n",
            "Epoch:0087 train loss:0.384 acc:86.54 | val loss:0.326 acc:88.11\n",
            "Epoch:0088 train loss:0.384 acc:85.93 | val loss:0.324 acc:88.13\n",
            "Epoch:0089 train loss:0.386 acc:86.56 | val loss:0.326 acc:88.08\n",
            "Epoch:0090 train loss:0.379 acc:86.48 | val loss:0.324 acc:88.16\n",
            "Epoch:0091 train loss:0.379 acc:86.86 | val loss:0.323 acc:88.08\n",
            "Epoch:0092 train loss:0.376 acc:86.85 | val loss:0.322 acc:88.05\n",
            "Epoch:0093 train loss:0.371 acc:87.07 | val loss:0.320 acc:88.21\n",
            "Epoch:0094 train loss:0.367 acc:86.92 | val loss:0.320 acc:88.45\n",
            "Epoch:0095 train loss:0.385 acc:86.70 | val loss:0.318 acc:88.48\n",
            "Epoch:0096 train loss:0.376 acc:86.65 | val loss:0.317 acc:88.51\n",
            "Epoch:0097 train loss:0.373 acc:86.86 | val loss:0.316 acc:88.54\n",
            "Epoch:0098 train loss:0.368 acc:86.57 | val loss:0.316 acc:88.43\n",
            "Epoch:0099 train loss:0.377 acc:86.43 | val loss:0.316 acc:88.35\n",
            "Epoch:0100 train loss:0.366 acc:86.89 | val loss:0.316 acc:88.43\n",
            "Epoch:0101 train loss:0.369 acc:86.85 | val loss:0.314 acc:88.35\n",
            "Epoch:0102 train loss:0.365 acc:86.77 | val loss:0.314 acc:88.32\n",
            "Epoch:0103 train loss:0.371 acc:86.85 | val loss:0.313 acc:88.56\n",
            "Epoch:0104 train loss:0.366 acc:87.17 | val loss:0.313 acc:88.49\n",
            "Epoch:0105 train loss:0.364 acc:87.04 | val loss:0.313 acc:88.49\n",
            "Epoch:0106 train loss:0.367 acc:86.63 | val loss:0.312 acc:88.46\n",
            "Epoch:0107 train loss:0.367 acc:86.84 | val loss:0.312 acc:88.42\n",
            "Epoch:0108 train loss:0.360 acc:87.03 | val loss:0.311 acc:88.48\n",
            "Epoch:0109 train loss:0.358 acc:87.10 | val loss:0.311 acc:88.70\n",
            "Epoch:0110 train loss:0.360 acc:87.22 | val loss:0.309 acc:88.65\n",
            "Epoch:0111 train loss:0.358 acc:87.26 | val loss:0.309 acc:88.65\n",
            "Epoch:0112 train loss:0.358 acc:86.98 | val loss:0.309 acc:88.49\n",
            "Epoch:0113 train loss:0.354 acc:87.23 | val loss:0.309 acc:88.56\n",
            "Epoch:0114 train loss:0.356 acc:87.23 | val loss:0.309 acc:88.59\n",
            "Epoch:0115 train loss:0.358 acc:87.32 | val loss:0.308 acc:88.61\n",
            "Epoch:0116 train loss:0.362 acc:87.25 | val loss:0.307 acc:88.80\n",
            "Epoch:0117 train loss:0.357 acc:87.32 | val loss:0.307 acc:88.75\n",
            "Epoch:0118 train loss:0.357 acc:87.31 | val loss:0.306 acc:88.80\n",
            "Epoch:0119 train loss:0.352 acc:87.19 | val loss:0.307 acc:88.81\n",
            "Epoch:0120 train loss:0.353 acc:87.50 | val loss:0.304 acc:88.83\n",
            "Epoch:0121 train loss:0.353 acc:87.46 | val loss:0.304 acc:88.94\n",
            "Epoch:0122 train loss:0.359 acc:87.49 | val loss:0.303 acc:88.87\n",
            "Epoch:0123 train loss:0.356 acc:87.23 | val loss:0.304 acc:88.94\n",
            "Epoch:0124 train loss:0.358 acc:87.36 | val loss:0.304 acc:88.87\n",
            "Epoch:0125 train loss:0.352 acc:87.41 | val loss:0.302 acc:88.94\n",
            "Epoch:0126 train loss:0.353 acc:87.41 | val loss:0.301 acc:88.92\n",
            "Epoch:0127 train loss:0.345 acc:87.93 | val loss:0.301 acc:88.89\n",
            "Epoch:0128 train loss:0.347 acc:87.34 | val loss:0.301 acc:89.06\n",
            "Epoch:0129 train loss:0.345 acc:87.87 | val loss:0.302 acc:88.99\n",
            "Epoch:0130 train loss:0.350 acc:87.30 | val loss:0.302 acc:89.02\n",
            "Epoch:0131 train loss:0.344 acc:87.74 | val loss:0.301 acc:88.97\n",
            "Epoch:0132 train loss:0.348 acc:87.55 | val loss:0.301 acc:88.97\n",
            "Epoch:0133 train loss:0.348 acc:87.63 | val loss:0.301 acc:88.95\n",
            "Epoch:0134 train loss:0.350 acc:87.42 | val loss:0.300 acc:89.05\n",
            "Epoch:0135 train loss:0.344 acc:87.71 | val loss:0.299 acc:89.03\n",
            "Epoch:0136 train loss:0.340 acc:87.60 | val loss:0.299 acc:89.19\n",
            "Epoch:0137 train loss:0.345 acc:87.36 | val loss:0.298 acc:89.14\n",
            "Epoch:0138 train loss:0.343 acc:87.85 | val loss:0.298 acc:89.14\n",
            "Epoch:0139 train loss:0.349 acc:87.70 | val loss:0.299 acc:89.16\n",
            "Epoch:0140 train loss:0.338 acc:87.92 | val loss:0.298 acc:89.14\n",
            "Epoch:0141 train loss:0.341 acc:88.10 | val loss:0.297 acc:89.24\n",
            "Epoch:0142 train loss:0.337 acc:87.77 | val loss:0.296 acc:89.16\n",
            "Epoch:0143 train loss:0.339 acc:88.07 | val loss:0.297 acc:89.22\n",
            "Epoch:0144 train loss:0.339 acc:88.04 | val loss:0.296 acc:89.24\n",
            "Epoch:0145 train loss:0.341 acc:87.73 | val loss:0.298 acc:89.14\n",
            "Epoch:0146 train loss:0.344 acc:87.71 | val loss:0.297 acc:89.14\n",
            "Epoch:0147 train loss:0.339 acc:87.73 | val loss:0.294 acc:89.22\n",
            "Epoch:0148 train loss:0.346 acc:87.91 | val loss:0.294 acc:89.19\n",
            "Epoch:0149 train loss:0.338 acc:87.71 | val loss:0.293 acc:89.37\n",
            "Epoch:0150 train loss:0.334 acc:88.10 | val loss:0.295 acc:89.03\n",
            "Epoch:0151 train loss:0.336 acc:88.13 | val loss:0.297 acc:89.02\n",
            "Epoch:0152 train loss:0.336 acc:87.42 | val loss:0.295 acc:89.16\n",
            "Epoch:0153 train loss:0.339 acc:87.84 | val loss:0.293 acc:89.27\n",
            "Epoch:0154 train loss:0.341 acc:87.69 | val loss:0.294 acc:89.32\n",
            "Epoch:0155 train loss:0.337 acc:88.03 | val loss:0.294 acc:89.29\n",
            "Epoch:0156 train loss:0.345 acc:87.58 | val loss:0.297 acc:89.06\n",
            "Epoch:0157 train loss:0.337 acc:87.78 | val loss:0.296 acc:89.11\n",
            "Epoch:0158 train loss:0.340 acc:87.88 | val loss:0.293 acc:89.26\n",
            "Epoch:0159 train loss:0.335 acc:88.03 | val loss:0.292 acc:89.40\n",
            "Epoch:0160 train loss:0.341 acc:87.85 | val loss:0.291 acc:89.48\n",
            "Epoch:0161 train loss:0.345 acc:87.83 | val loss:0.291 acc:89.40\n",
            "Epoch:0162 train loss:0.331 acc:87.70 | val loss:0.295 acc:89.24\n",
            "Epoch:0163 train loss:0.340 acc:87.69 | val loss:0.292 acc:89.22\n",
            "Epoch:0164 train loss:0.341 acc:87.45 | val loss:0.291 acc:89.48\n",
            "Epoch:0165 train loss:0.332 acc:88.00 | val loss:0.290 acc:89.46\n",
            "Epoch:0166 train loss:0.335 acc:87.63 | val loss:0.293 acc:89.30\n",
            "Epoch:0167 train loss:0.339 acc:87.49 | val loss:0.291 acc:89.21\n",
            "Epoch:0168 train loss:0.334 acc:87.74 | val loss:0.296 acc:89.02\n",
            "Epoch:0169 train loss:0.341 acc:87.37 | val loss:0.290 acc:89.35\n",
            "Epoch:0170 train loss:0.332 acc:87.87 | val loss:0.291 acc:89.51\n",
            "Epoch:0171 train loss:0.330 acc:88.12 | val loss:0.289 acc:89.56\n",
            "Epoch:0172 train loss:0.334 acc:87.82 | val loss:0.289 acc:89.43\n",
            "Epoch:0173 train loss:0.334 acc:87.93 | val loss:0.290 acc:89.43\n",
            "Epoch:0174 train loss:0.333 acc:87.87 | val loss:0.291 acc:89.41\n",
            "Epoch:0175 train loss:0.329 acc:88.12 | val loss:0.289 acc:89.54\n",
            "Epoch:0176 train loss:0.324 acc:88.43 | val loss:0.287 acc:89.62\n",
            "Epoch:0177 train loss:0.334 acc:88.65 | val loss:0.288 acc:89.59\n",
            "Epoch:0178 train loss:0.329 acc:87.79 | val loss:0.288 acc:89.62\n",
            "Epoch:0179 train loss:0.330 acc:88.21 | val loss:0.290 acc:89.24\n",
            "Epoch:0180 train loss:0.331 acc:88.12 | val loss:0.288 acc:89.48\n",
            "Epoch:0181 train loss:0.331 acc:88.37 | val loss:0.287 acc:89.62\n",
            "Epoch:0182 train loss:0.329 acc:88.12 | val loss:0.286 acc:89.68\n",
            "Epoch:0183 train loss:0.336 acc:87.82 | val loss:0.288 acc:89.62\n",
            "Epoch:0184 train loss:0.326 acc:88.38 | val loss:0.289 acc:89.33\n",
            "Epoch:0185 train loss:0.323 acc:88.43 | val loss:0.289 acc:89.26\n",
            "Epoch:0186 train loss:0.326 acc:88.49 | val loss:0.287 acc:89.49\n",
            "Epoch:0187 train loss:0.332 acc:87.87 | val loss:0.286 acc:89.70\n",
            "Epoch:0188 train loss:0.324 acc:88.11 | val loss:0.286 acc:89.60\n",
            "Epoch:0189 train loss:0.327 acc:88.42 | val loss:0.285 acc:89.64\n",
            "Epoch:0190 train loss:0.322 acc:88.40 | val loss:0.287 acc:89.40\n",
            "Epoch:0191 train loss:0.325 acc:88.17 | val loss:0.287 acc:89.64\n",
            "Epoch:0192 train loss:0.325 acc:88.37 | val loss:0.285 acc:89.79\n",
            "Epoch:0193 train loss:0.327 acc:88.24 | val loss:0.283 acc:89.78\n",
            "Epoch:0194 train loss:0.323 acc:88.17 | val loss:0.283 acc:89.68\n",
            "Epoch:0195 train loss:0.324 acc:88.24 | val loss:0.283 acc:89.89\n",
            "Epoch:0196 train loss:0.319 acc:88.77 | val loss:0.286 acc:89.59\n",
            "Epoch:0197 train loss:0.329 acc:88.45 | val loss:0.286 acc:89.54\n",
            "Epoch:0198 train loss:0.328 acc:88.12 | val loss:0.284 acc:89.75\n",
            "Epoch:0199 train loss:0.333 acc:87.82 | val loss:0.284 acc:89.84\n",
            "Epoch:0200 train loss:0.320 acc:88.37 | val loss:0.286 acc:89.68\n",
            "Epoch:0201 train loss:0.326 acc:88.16 | val loss:0.284 acc:89.75\n",
            "Epoch:0202 train loss:0.323 acc:88.24 | val loss:0.288 acc:89.56\n",
            "Epoch:0203 train loss:0.327 acc:87.85 | val loss:0.286 acc:89.64\n",
            "Epoch:0204 train loss:0.316 acc:88.77 | val loss:0.284 acc:89.92\n",
            "Epoch:0205 train loss:0.324 acc:88.21 | val loss:0.282 acc:89.81\n",
            "Epoch:0206 train loss:0.327 acc:88.20 | val loss:0.282 acc:89.84\n",
            "Epoch:0207 train loss:0.321 acc:88.57 | val loss:0.283 acc:89.70\n",
            "Epoch:0208 train loss:0.317 acc:88.51 | val loss:0.284 acc:89.62\n",
            "Epoch:0209 train loss:0.326 acc:88.14 | val loss:0.282 acc:89.60\n",
            "Epoch:0210 train loss:0.327 acc:88.17 | val loss:0.280 acc:90.00\n",
            "Epoch:0211 train loss:0.322 acc:88.63 | val loss:0.281 acc:90.03\n",
            "Epoch:0212 train loss:0.318 acc:88.65 | val loss:0.280 acc:89.71\n",
            "Epoch:0213 train loss:0.315 acc:88.56 | val loss:0.283 acc:89.75\n",
            "Epoch:0214 train loss:0.321 acc:88.17 | val loss:0.284 acc:89.67\n",
            "Epoch:0215 train loss:0.319 acc:88.10 | val loss:0.283 acc:89.67\n",
            "Epoch:0216 train loss:0.317 acc:88.21 | val loss:0.282 acc:89.70\n",
            "Epoch:0217 train loss:0.318 acc:88.51 | val loss:0.282 acc:89.65\n",
            "Epoch:0218 train loss:0.312 acc:88.57 | val loss:0.282 acc:89.62\n",
            "Epoch:0219 train loss:0.320 acc:88.50 | val loss:0.281 acc:89.62\n",
            "Epoch:0220 train loss:0.321 acc:88.25 | val loss:0.280 acc:89.65\n",
            "Epoch:0221 train loss:0.314 acc:88.77 | val loss:0.279 acc:89.78\n",
            "Epoch:0222 train loss:0.323 acc:88.13 | val loss:0.280 acc:89.64\n",
            "Epoch:0223 train loss:0.310 acc:88.50 | val loss:0.280 acc:89.64\n",
            "Epoch:0224 train loss:0.313 acc:88.49 | val loss:0.279 acc:89.57\n",
            "Epoch:0225 train loss:0.319 acc:88.17 | val loss:0.280 acc:89.79\n",
            "Epoch:0226 train loss:0.314 acc:88.62 | val loss:0.281 acc:89.67\n",
            "Epoch:0227 train loss:0.317 acc:88.60 | val loss:0.281 acc:89.62\n",
            "Epoch:0228 train loss:0.321 acc:88.39 | val loss:0.281 acc:89.57\n",
            "Epoch:0229 train loss:0.327 acc:88.00 | val loss:0.281 acc:89.76\n",
            "Epoch:0230 train loss:0.315 acc:88.76 | val loss:0.281 acc:89.81\n",
            "Epoch:0231 train loss:0.310 acc:88.69 | val loss:0.280 acc:89.46\n",
            "Epoch:0232 train loss:0.319 acc:88.51 | val loss:0.281 acc:89.52\n",
            "Epoch:0233 train loss:0.318 acc:88.40 | val loss:0.278 acc:89.97\n",
            "Epoch:0234 train loss:0.315 acc:88.29 | val loss:0.278 acc:90.08\n",
            "Epoch:0235 train loss:0.316 acc:88.79 | val loss:0.277 acc:89.65\n",
            "Epoch:0236 train loss:0.313 acc:88.63 | val loss:0.277 acc:89.68\n",
            "Epoch:0237 train loss:0.314 acc:88.48 | val loss:0.278 acc:90.00\n",
            "Epoch:0238 train loss:0.311 acc:88.74 | val loss:0.280 acc:89.81\n",
            "Epoch:0239 train loss:0.312 acc:88.84 | val loss:0.276 acc:89.73\n",
            "Epoch:0240 train loss:0.310 acc:89.10 | val loss:0.277 acc:89.78\n",
            "Epoch:0241 train loss:0.312 acc:88.79 | val loss:0.278 acc:90.02\n",
            "Epoch:0242 train loss:0.311 acc:88.86 | val loss:0.280 acc:89.90\n",
            "Epoch:0243 train loss:0.310 acc:88.45 | val loss:0.278 acc:89.76\n",
            "Epoch:0244 train loss:0.313 acc:88.61 | val loss:0.276 acc:89.68\n",
            "Epoch:0245 train loss:0.306 acc:88.84 | val loss:0.277 acc:89.92\n",
            "Epoch:0246 train loss:0.311 acc:88.42 | val loss:0.276 acc:89.83\n",
            "Epoch:0247 train loss:0.309 acc:88.71 | val loss:0.279 acc:89.70\n",
            "Epoch:0248 train loss:0.311 acc:88.71 | val loss:0.276 acc:89.68\n",
            "Epoch:0249 train loss:0.307 acc:88.88 | val loss:0.281 acc:89.68\n",
            "Epoch:0250 train loss:0.317 acc:88.46 | val loss:0.274 acc:90.03\n",
            "Epoch:0251 train loss:0.300 acc:89.08 | val loss:0.282 acc:89.59\n",
            "Epoch:0252 train loss:0.314 acc:88.37 | val loss:0.275 acc:89.68\n",
            "Epoch:0253 train loss:0.311 acc:88.76 | val loss:0.283 acc:89.49\n",
            "Epoch:0254 train loss:0.321 acc:88.30 | val loss:0.274 acc:89.89\n",
            "Epoch:0255 train loss:0.303 acc:88.78 | val loss:0.280 acc:89.67\n",
            "Epoch:0256 train loss:0.316 acc:88.56 | val loss:0.276 acc:89.79\n",
            "Epoch:0257 train loss:0.304 acc:89.09 | val loss:0.278 acc:89.90\n",
            "Epoch:0258 train loss:0.310 acc:88.25 | val loss:0.274 acc:89.94\n",
            "Epoch:0259 train loss:0.304 acc:88.69 | val loss:0.275 acc:89.86\n",
            "Epoch:0260 train loss:0.303 acc:89.07 | val loss:0.275 acc:90.00\n",
            "Epoch:0261 train loss:0.308 acc:88.82 | val loss:0.276 acc:89.97\n",
            "Epoch:0262 train loss:0.303 acc:89.25 | val loss:0.276 acc:89.84\n",
            "Epoch:0263 train loss:0.304 acc:88.97 | val loss:0.275 acc:89.90\n",
            "Epoch:0264 train loss:0.307 acc:89.09 | val loss:0.274 acc:90.16\n",
            "Epoch:0265 train loss:0.297 acc:88.97 | val loss:0.274 acc:90.19\n",
            "Epoch:0266 train loss:0.306 acc:88.61 | val loss:0.276 acc:89.89\n",
            "Epoch:0267 train loss:0.304 acc:88.67 | val loss:0.275 acc:89.83\n",
            "Epoch:0268 train loss:0.306 acc:88.52 | val loss:0.273 acc:90.13\n",
            "Epoch:0269 train loss:0.305 acc:88.95 | val loss:0.273 acc:90.14\n",
            "Epoch:0270 train loss:0.299 acc:89.18 | val loss:0.274 acc:89.98\n",
            "Epoch:0271 train loss:0.306 acc:89.05 | val loss:0.275 acc:89.95\n",
            "Epoch:0272 train loss:0.305 acc:88.77 | val loss:0.273 acc:90.22\n",
            "Epoch:0273 train loss:0.301 acc:88.77 | val loss:0.274 acc:90.00\n",
            "Epoch:0274 train loss:0.305 acc:89.07 | val loss:0.273 acc:90.02\n",
            "Epoch:0275 train loss:0.305 acc:88.86 | val loss:0.272 acc:90.02\n",
            "Epoch:0276 train loss:0.304 acc:88.91 | val loss:0.274 acc:90.03\n",
            "Epoch:0277 train loss:0.312 acc:88.83 | val loss:0.273 acc:90.13\n",
            "Epoch:0278 train loss:0.297 acc:89.08 | val loss:0.272 acc:90.02\n",
            "Epoch:0279 train loss:0.295 acc:89.02 | val loss:0.271 acc:90.14\n",
            "Epoch:0280 train loss:0.302 acc:88.80 | val loss:0.273 acc:90.27\n",
            "Epoch:0281 train loss:0.305 acc:88.65 | val loss:0.273 acc:90.16\n",
            "Epoch:0282 train loss:0.300 acc:88.81 | val loss:0.272 acc:90.10\n",
            "Epoch:0283 train loss:0.305 acc:88.93 | val loss:0.272 acc:90.11\n",
            "Epoch:0284 train loss:0.304 acc:88.71 | val loss:0.273 acc:90.11\n",
            "Epoch:0285 train loss:0.304 acc:88.63 | val loss:0.271 acc:90.17\n",
            "Epoch:0286 train loss:0.295 acc:89.23 | val loss:0.272 acc:90.08\n",
            "Epoch:0287 train loss:0.304 acc:88.77 | val loss:0.271 acc:90.16\n",
            "Epoch:0288 train loss:0.297 acc:89.37 | val loss:0.271 acc:90.25\n",
            "Epoch:0289 train loss:0.298 acc:88.68 | val loss:0.270 acc:90.17\n",
            "Epoch:0290 train loss:0.289 acc:89.57 | val loss:0.271 acc:90.16\n",
            "Epoch:0291 train loss:0.303 acc:88.91 | val loss:0.274 acc:90.11\n",
            "Epoch:0292 train loss:0.305 acc:89.04 | val loss:0.272 acc:90.17\n",
            "Epoch:0293 train loss:0.296 acc:89.16 | val loss:0.273 acc:90.03\n",
            "Epoch:0294 train loss:0.298 acc:88.95 | val loss:0.271 acc:90.14\n",
            "Epoch:0295 train loss:0.299 acc:89.06 | val loss:0.272 acc:90.32\n",
            "Epoch:0296 train loss:0.300 acc:89.16 | val loss:0.271 acc:90.19\n",
            "Epoch:0297 train loss:0.294 acc:88.98 | val loss:0.271 acc:90.17\n",
            "Epoch:0298 train loss:0.293 acc:89.51 | val loss:0.269 acc:90.21\n",
            "Epoch:0299 train loss:0.297 acc:89.32 | val loss:0.269 acc:90.21\n",
            "Epoch:0300 train loss:0.304 acc:88.67 | val loss:0.269 acc:90.10\n",
            "Epoch:0301 train loss:0.289 acc:89.25 | val loss:0.270 acc:90.10\n",
            "Epoch:0302 train loss:0.292 acc:89.09 | val loss:0.269 acc:90.14\n",
            "Epoch:0303 train loss:0.298 acc:88.76 | val loss:0.270 acc:90.22\n",
            "Epoch:0304 train loss:0.295 acc:88.99 | val loss:0.269 acc:90.11\n",
            "Epoch:0305 train loss:0.290 acc:89.27 | val loss:0.270 acc:90.08\n",
            "Epoch:0306 train loss:0.298 acc:89.18 | val loss:0.270 acc:90.24\n",
            "Epoch:0307 train loss:0.291 acc:89.25 | val loss:0.270 acc:90.24\n",
            "Epoch:0308 train loss:0.289 acc:89.35 | val loss:0.269 acc:90.24\n",
            "Epoch:0309 train loss:0.298 acc:89.18 | val loss:0.267 acc:90.29\n",
            "Epoch:0310 train loss:0.291 acc:89.25 | val loss:0.267 acc:90.21\n",
            "Epoch:0311 train loss:0.293 acc:89.49 | val loss:0.268 acc:90.17\n",
            "Epoch:0312 train loss:0.299 acc:88.91 | val loss:0.268 acc:90.14\n",
            "Epoch:0313 train loss:0.292 acc:89.28 | val loss:0.271 acc:90.36\n",
            "Epoch:0314 train loss:0.291 acc:89.21 | val loss:0.271 acc:90.03\n",
            "Epoch:0315 train loss:0.289 acc:89.72 | val loss:0.269 acc:90.13\n",
            "Epoch:0316 train loss:0.292 acc:89.42 | val loss:0.271 acc:90.32\n",
            "Epoch:0317 train loss:0.295 acc:89.00 | val loss:0.271 acc:89.92\n",
            "Epoch:0318 train loss:0.287 acc:89.26 | val loss:0.271 acc:90.10\n",
            "Epoch:0319 train loss:0.296 acc:89.32 | val loss:0.268 acc:90.13\n",
            "Epoch:0320 train loss:0.295 acc:89.26 | val loss:0.267 acc:90.38\n",
            "Epoch:0321 train loss:0.301 acc:88.81 | val loss:0.268 acc:90.27\n",
            "Epoch:0322 train loss:0.291 acc:89.52 | val loss:0.273 acc:89.78\n",
            "Epoch:0323 train loss:0.294 acc:89.16 | val loss:0.266 acc:90.24\n",
            "Epoch:0324 train loss:0.296 acc:88.99 | val loss:0.267 acc:90.05\n",
            "Epoch:0325 train loss:0.300 acc:88.91 | val loss:0.266 acc:90.24\n",
            "Epoch:0326 train loss:0.295 acc:89.14 | val loss:0.272 acc:90.11\n",
            "Epoch:0327 train loss:0.291 acc:89.18 | val loss:0.271 acc:90.14\n",
            "Epoch:0328 train loss:0.288 acc:89.16 | val loss:0.270 acc:90.05\n",
            "Epoch:0329 train loss:0.292 acc:89.46 | val loss:0.270 acc:90.11\n",
            "Epoch:0330 train loss:0.302 acc:88.96 | val loss:0.267 acc:90.19\n",
            "Epoch:0331 train loss:0.295 acc:89.44 | val loss:0.276 acc:90.00\n",
            "Epoch:0332 train loss:0.299 acc:89.22 | val loss:0.269 acc:90.30\n",
            "Epoch:0333 train loss:0.297 acc:89.19 | val loss:0.266 acc:90.29\n",
            "Epoch:0334 train loss:0.291 acc:89.22 | val loss:0.269 acc:90.03\n",
            "Epoch:0335 train loss:0.293 acc:89.28 | val loss:0.270 acc:90.10\n",
            "Epoch:0336 train loss:0.284 acc:89.37 | val loss:0.278 acc:90.02\n",
            "Epoch:0337 train loss:0.289 acc:89.36 | val loss:0.268 acc:90.05\n",
            "Epoch:0338 train loss:0.286 acc:89.69 | val loss:0.268 acc:90.03\n",
            "Epoch:0339 train loss:0.294 acc:89.33 | val loss:0.266 acc:90.25\n",
            "Epoch:0340 train loss:0.294 acc:89.22 | val loss:0.266 acc:90.36\n",
            "Epoch:0341 train loss:0.293 acc:89.14 | val loss:0.269 acc:90.27\n",
            "Epoch:0342 train loss:0.288 acc:89.33 | val loss:0.266 acc:90.22\n",
            "Epoch:0343 train loss:0.291 acc:89.15 | val loss:0.265 acc:90.30\n",
            "Epoch:0344 train loss:0.289 acc:89.39 | val loss:0.265 acc:90.36\n",
            "Epoch:0345 train loss:0.290 acc:88.99 | val loss:0.269 acc:90.13\n",
            "Epoch:0346 train loss:0.285 acc:89.68 | val loss:0.270 acc:90.11\n",
            "Epoch:0347 train loss:0.288 acc:89.46 | val loss:0.268 acc:90.25\n",
            "Epoch:0348 train loss:0.287 acc:89.67 | val loss:0.266 acc:90.08\n",
            "Epoch:0349 train loss:0.287 acc:89.70 | val loss:0.265 acc:90.11\n",
            "Epoch:0350 train loss:0.283 acc:89.42 | val loss:0.264 acc:90.33\n",
            "Epoch:0351 train loss:0.289 acc:89.67 | val loss:0.264 acc:90.29\n",
            "Epoch:0352 train loss:0.284 acc:89.36 | val loss:0.268 acc:90.29\n",
            "Epoch:0353 train loss:0.292 acc:89.13 | val loss:0.264 acc:90.41\n",
            "Epoch:0354 train loss:0.283 acc:89.64 | val loss:0.263 acc:90.21\n",
            "Epoch:0355 train loss:0.284 acc:89.38 | val loss:0.265 acc:90.02\n",
            "Epoch:0356 train loss:0.284 acc:89.42 | val loss:0.269 acc:90.36\n",
            "Epoch:0357 train loss:0.279 acc:89.77 | val loss:0.270 acc:90.25\n",
            "Epoch:0358 train loss:0.293 acc:89.02 | val loss:0.268 acc:90.10\n",
            "Epoch:0359 train loss:0.289 acc:89.38 | val loss:0.263 acc:90.35\n",
            "Epoch:0360 train loss:0.291 acc:89.46 | val loss:0.264 acc:90.46\n",
            "Epoch:0361 train loss:0.278 acc:89.73 | val loss:0.267 acc:90.11\n",
            "Epoch:0362 train loss:0.280 acc:89.42 | val loss:0.268 acc:90.11\n",
            "Epoch:0363 train loss:0.284 acc:89.74 | val loss:0.266 acc:90.22\n",
            "Epoch:0364 train loss:0.284 acc:89.38 | val loss:0.266 acc:90.17\n",
            "Epoch:0365 train loss:0.285 acc:89.50 | val loss:0.267 acc:90.32\n",
            "Epoch:0366 train loss:0.285 acc:89.52 | val loss:0.269 acc:90.14\n",
            "Epoch:0367 train loss:0.279 acc:89.56 | val loss:0.267 acc:90.38\n",
            "Epoch:0368 train loss:0.285 acc:89.57 | val loss:0.266 acc:90.25\n",
            "Epoch:0369 train loss:0.284 acc:89.65 | val loss:0.267 acc:89.95\n",
            "Epoch:0370 train loss:0.288 acc:89.72 | val loss:0.263 acc:90.19\n",
            "Epoch:0371 train loss:0.283 acc:89.59 | val loss:0.270 acc:90.13\n",
            "Epoch:0372 train loss:0.291 acc:89.10 | val loss:0.266 acc:90.02\n",
            "Epoch:0373 train loss:0.279 acc:89.33 | val loss:0.269 acc:90.02\n",
            "Epoch:0374 train loss:0.286 acc:89.07 | val loss:0.265 acc:90.33\n",
            "Epoch:0375 train loss:0.285 acc:89.67 | val loss:0.265 acc:90.36\n",
            "Epoch:0376 train loss:0.287 acc:89.86 | val loss:0.275 acc:89.89\n",
            "Epoch:0377 train loss:0.300 acc:88.83 | val loss:0.267 acc:90.22\n",
            "Epoch:0378 train loss:0.280 acc:89.58 | val loss:0.267 acc:90.43\n",
            "Epoch:0379 train loss:0.286 acc:89.24 | val loss:0.261 acc:90.21\n",
            "Epoch:0380 train loss:0.279 acc:89.74 | val loss:0.266 acc:90.03\n",
            "Epoch:0381 train loss:0.284 acc:89.44 | val loss:0.269 acc:90.24\n",
            "Epoch:0382 train loss:0.282 acc:89.65 | val loss:0.267 acc:90.13\n",
            "Epoch:0383 train loss:0.277 acc:89.56 | val loss:0.266 acc:90.08\n",
            "Epoch:0384 train loss:0.280 acc:89.46 | val loss:0.265 acc:90.22\n",
            "Epoch:0385 train loss:0.275 acc:89.81 | val loss:0.266 acc:90.29\n",
            "Epoch:0386 train loss:0.279 acc:89.39 | val loss:0.265 acc:90.33\n",
            "Epoch:0387 train loss:0.277 acc:89.77 | val loss:0.264 acc:90.25\n",
            "Epoch:0388 train loss:0.281 acc:89.77 | val loss:0.264 acc:90.27\n",
            "Epoch:0389 train loss:0.277 acc:89.83 | val loss:0.266 acc:90.40\n",
            "Epoch:0390 train loss:0.284 acc:89.56 | val loss:0.265 acc:90.38\n",
            "Epoch:0391 train loss:0.277 acc:89.65 | val loss:0.264 acc:90.11\n",
            "Epoch:0392 train loss:0.279 acc:89.55 | val loss:0.262 acc:90.22\n",
            "Epoch:0393 train loss:0.279 acc:89.64 | val loss:0.263 acc:90.19\n",
            "Epoch:0394 train loss:0.279 acc:89.58 | val loss:0.269 acc:90.08\n",
            "Epoch:0395 train loss:0.283 acc:89.58 | val loss:0.262 acc:90.25\n",
            "Epoch:0396 train loss:0.277 acc:89.75 | val loss:0.261 acc:90.36\n",
            "Epoch:0397 train loss:0.288 acc:89.41 | val loss:0.271 acc:89.86\n",
            "Epoch:0398 train loss:0.298 acc:89.07 | val loss:0.267 acc:90.33\n",
            "Epoch:0399 train loss:0.281 acc:89.46 | val loss:0.271 acc:90.16\n",
            "Epoch:0400 train loss:0.283 acc:89.19 | val loss:0.267 acc:90.00\n",
            "Epoch:0401 train loss:0.284 acc:89.43 | val loss:0.263 acc:90.16\n",
            "Epoch:0402 train loss:0.282 acc:89.80 | val loss:0.263 acc:90.29\n",
            "Epoch:0403 train loss:0.287 acc:89.34 | val loss:0.263 acc:90.29\n",
            "Epoch:0404 train loss:0.283 acc:89.39 | val loss:0.272 acc:90.24\n",
            "Epoch:0405 train loss:0.286 acc:89.21 | val loss:0.263 acc:90.36\n",
            "Epoch:0406 train loss:0.274 acc:90.15 | val loss:0.265 acc:90.36\n",
            "Epoch:0407 train loss:0.286 acc:89.69 | val loss:0.261 acc:90.25\n",
            "Epoch:0408 train loss:0.279 acc:89.53 | val loss:0.267 acc:90.17\n",
            "Epoch:0409 train loss:0.284 acc:89.44 | val loss:0.276 acc:89.95\n",
            "Epoch:0410 train loss:0.286 acc:89.70 | val loss:0.263 acc:90.41\n",
            "Epoch:0411 train loss:0.282 acc:89.76 | val loss:0.262 acc:90.21\n",
            "Epoch:0412 train loss:0.280 acc:89.80 | val loss:0.260 acc:90.19\n",
            "Epoch:0413 train loss:0.282 acc:89.59 | val loss:0.261 acc:90.38\n",
            "Epoch:0414 train loss:0.280 acc:89.89 | val loss:0.266 acc:90.29\n",
            "Epoch:0415 train loss:0.279 acc:89.60 | val loss:0.268 acc:90.00\n",
            "Epoch:0416 train loss:0.281 acc:89.94 | val loss:0.262 acc:90.29\n",
            "Epoch:0417 train loss:0.273 acc:89.69 | val loss:0.261 acc:90.43\n",
            "Epoch:0418 train loss:0.282 acc:89.46 | val loss:0.263 acc:90.25\n",
            "Epoch:0419 train loss:0.283 acc:89.45 | val loss:0.265 acc:90.21\n",
            "Epoch:0420 train loss:0.272 acc:90.07 | val loss:0.270 acc:90.21\n",
            "Epoch:0421 train loss:0.272 acc:90.08 | val loss:0.266 acc:90.19\n",
            "Epoch:0422 train loss:0.274 acc:89.96 | val loss:0.260 acc:90.32\n",
            "Epoch:0423 train loss:0.279 acc:89.77 | val loss:0.259 acc:90.44\n",
            "Epoch:0424 train loss:0.276 acc:89.77 | val loss:0.259 acc:90.35\n",
            "Epoch:0425 train loss:0.276 acc:89.92 | val loss:0.263 acc:90.29\n",
            "Epoch:0426 train loss:0.269 acc:90.27 | val loss:0.263 acc:90.13\n",
            "Epoch:0427 train loss:0.277 acc:89.86 | val loss:0.260 acc:90.29\n",
            "Epoch:0428 train loss:0.273 acc:89.93 | val loss:0.259 acc:90.41\n",
            "Epoch:0429 train loss:0.275 acc:89.81 | val loss:0.259 acc:90.32\n",
            "Epoch:0430 train loss:0.269 acc:90.08 | val loss:0.261 acc:90.40\n",
            "Epoch:0431 train loss:0.270 acc:90.13 | val loss:0.263 acc:90.49\n",
            "Epoch:0432 train loss:0.274 acc:90.00 | val loss:0.262 acc:90.30\n",
            "Epoch:0433 train loss:0.269 acc:90.09 | val loss:0.260 acc:90.38\n",
            "Epoch:0434 train loss:0.272 acc:90.02 | val loss:0.260 acc:90.36\n",
            "Epoch:0435 train loss:0.272 acc:89.86 | val loss:0.265 acc:90.36\n",
            "Epoch:0436 train loss:0.273 acc:89.89 | val loss:0.265 acc:90.49\n",
            "Epoch:0437 train loss:0.273 acc:90.17 | val loss:0.261 acc:90.48\n",
            "Epoch:0438 train loss:0.271 acc:90.17 | val loss:0.259 acc:90.52\n",
            "Epoch:0439 train loss:0.268 acc:89.94 | val loss:0.259 acc:90.41\n",
            "Epoch:0440 train loss:0.270 acc:89.93 | val loss:0.259 acc:90.43\n",
            "Epoch:0441 train loss:0.269 acc:90.33 | val loss:0.262 acc:90.43\n",
            "Epoch:0442 train loss:0.275 acc:89.80 | val loss:0.263 acc:90.19\n",
            "Epoch:0443 train loss:0.273 acc:89.96 | val loss:0.264 acc:90.24\n",
            "Epoch:0444 train loss:0.276 acc:89.77 | val loss:0.262 acc:90.30\n",
            "Epoch:0445 train loss:0.268 acc:90.54 | val loss:0.260 acc:90.21\n",
            "Epoch:0446 train loss:0.270 acc:89.91 | val loss:0.263 acc:90.17\n",
            "Epoch:0447 train loss:0.273 acc:89.97 | val loss:0.263 acc:90.36\n",
            "Epoch:0448 train loss:0.278 acc:89.90 | val loss:0.260 acc:90.33\n",
            "Epoch:0449 train loss:0.271 acc:90.12 | val loss:0.261 acc:90.11\n",
            "Epoch:0450 train loss:0.267 acc:90.45 | val loss:0.260 acc:90.17\n",
            "Epoch:0451 train loss:0.272 acc:89.94 | val loss:0.263 acc:90.19\n",
            "Epoch:0452 train loss:0.279 acc:89.71 | val loss:0.266 acc:90.16\n",
            "Epoch:0453 train loss:0.271 acc:89.94 | val loss:0.265 acc:90.24\n",
            "Epoch:0454 train loss:0.271 acc:90.13 | val loss:0.262 acc:90.35\n",
            "Epoch:0455 train loss:0.272 acc:89.90 | val loss:0.262 acc:90.27\n",
            "Epoch:0456 train loss:0.270 acc:90.23 | val loss:0.263 acc:90.32\n",
            "Epoch:0457 train loss:0.269 acc:90.06 | val loss:0.265 acc:90.38\n",
            "Epoch:0458 train loss:0.270 acc:90.30 | val loss:0.261 acc:90.44\n",
            "Epoch:0459 train loss:0.267 acc:89.79 | val loss:0.264 acc:90.08\n",
            "Epoch:0460 train loss:0.277 acc:89.53 | val loss:0.262 acc:90.35\n",
            "Epoch:0461 train loss:0.269 acc:89.83 | val loss:0.262 acc:90.54\n",
            "Epoch:0462 train loss:0.264 acc:90.17 | val loss:0.272 acc:90.11\n",
            "Epoch:0463 train loss:0.272 acc:90.06 | val loss:0.262 acc:90.33\n",
            "Epoch:0464 train loss:0.271 acc:89.96 | val loss:0.266 acc:90.40\n",
            "Epoch:0465 train loss:0.282 acc:89.27 | val loss:0.264 acc:90.19\n",
            "Epoch:0466 train loss:0.266 acc:90.49 | val loss:0.265 acc:90.21\n",
            "Epoch:0467 train loss:0.271 acc:90.16 | val loss:0.261 acc:90.57\n",
            "Epoch:0468 train loss:0.268 acc:90.31 | val loss:0.259 acc:90.51\n",
            "Epoch:0469 train loss:0.270 acc:90.26 | val loss:0.262 acc:90.21\n",
            "Epoch:0470 train loss:0.272 acc:89.97 | val loss:0.261 acc:90.43\n",
            "Epoch:0471 train loss:0.271 acc:89.95 | val loss:0.266 acc:90.41\n",
            "Epoch:0472 train loss:0.265 acc:90.05 | val loss:0.263 acc:90.60\n",
            "Epoch:0473 train loss:0.271 acc:89.95 | val loss:0.259 acc:90.46\n",
            "Epoch:0474 train loss:0.263 acc:90.40 | val loss:0.258 acc:90.38\n",
            "Epoch:0475 train loss:0.269 acc:90.17 | val loss:0.258 acc:90.41\n",
            "Epoch:0476 train loss:0.260 acc:90.51 | val loss:0.259 acc:90.51\n",
            "Epoch:0477 train loss:0.262 acc:90.11 | val loss:0.262 acc:90.52\n",
            "Epoch:0478 train loss:0.270 acc:90.05 | val loss:0.260 acc:90.51\n",
            "Epoch:0479 train loss:0.268 acc:89.78 | val loss:0.257 acc:90.43\n",
            "Epoch:0480 train loss:0.274 acc:89.57 | val loss:0.258 acc:90.57\n",
            "Epoch:0481 train loss:0.269 acc:90.15 | val loss:0.261 acc:90.35\n",
            "Epoch:0482 train loss:0.263 acc:90.27 | val loss:0.263 acc:90.43\n",
            "Epoch:0483 train loss:0.270 acc:89.86 | val loss:0.263 acc:90.51\n",
            "Epoch:0484 train loss:0.269 acc:90.16 | val loss:0.260 acc:90.41\n",
            "Epoch:0485 train loss:0.262 acc:90.52 | val loss:0.260 acc:90.36\n",
            "Epoch:0486 train loss:0.262 acc:90.25 | val loss:0.261 acc:90.48\n",
            "Epoch:0487 train loss:0.266 acc:90.13 | val loss:0.264 acc:90.49\n",
            "Epoch:0488 train loss:0.266 acc:90.39 | val loss:0.264 acc:90.35\n",
            "Epoch:0489 train loss:0.261 acc:90.31 | val loss:0.258 acc:90.41\n",
            "Epoch:0490 train loss:0.264 acc:90.42 | val loss:0.261 acc:90.51\n",
            "Epoch:0491 train loss:0.264 acc:90.48 | val loss:0.260 acc:90.46\n",
            "Epoch:0492 train loss:0.256 acc:90.57 | val loss:0.266 acc:90.19\n",
            "Epoch:0493 train loss:0.271 acc:90.24 | val loss:0.262 acc:90.38\n",
            "Epoch:0494 train loss:0.268 acc:89.94 | val loss:0.260 acc:90.36\n",
            "Epoch:0495 train loss:0.270 acc:90.14 | val loss:0.264 acc:90.03\n",
            "Epoch:0496 train loss:0.274 acc:89.62 | val loss:0.260 acc:90.43\n",
            "Epoch:0497 train loss:0.266 acc:90.18 | val loss:0.262 acc:90.48\n",
            "Epoch:0498 train loss:0.268 acc:90.19 | val loss:0.260 acc:90.35\n",
            "Epoch:0499 train loss:0.261 acc:90.47 | val loss:0.261 acc:90.27\n",
            "Epoch:0500 train loss:0.266 acc:90.31 | val loss:0.260 acc:90.46\n",
            "Epoch:0501 train loss:0.258 acc:90.65 | val loss:0.261 acc:90.44\n",
            "Epoch:0502 train loss:0.263 acc:90.40 | val loss:0.263 acc:90.44\n",
            "Epoch:0503 train loss:0.264 acc:90.37 | val loss:0.262 acc:90.40\n",
            "Epoch:0504 train loss:0.257 acc:90.96 | val loss:0.259 acc:90.44\n",
            "Epoch:0505 train loss:0.260 acc:90.46 | val loss:0.259 acc:90.51\n",
            "Epoch:0506 train loss:0.260 acc:90.24 | val loss:0.260 acc:90.36\n",
            "Epoch:0507 train loss:0.265 acc:90.40 | val loss:0.259 acc:90.49\n",
            "Epoch:0508 train loss:0.269 acc:90.09 | val loss:0.260 acc:90.44\n",
            "Epoch:0509 train loss:0.264 acc:90.02 | val loss:0.262 acc:90.14\n",
            "Epoch:0510 train loss:0.265 acc:90.28 | val loss:0.260 acc:90.36\n",
            "Epoch:0511 train loss:0.257 acc:90.68 | val loss:0.263 acc:90.30\n",
            "Epoch:0512 train loss:0.260 acc:90.16 | val loss:0.261 acc:90.48\n",
            "Epoch:0513 train loss:0.262 acc:90.42 | val loss:0.273 acc:90.00\n",
            "Epoch:0514 train loss:0.277 acc:89.64 | val loss:0.260 acc:90.54\n",
            "Epoch:0515 train loss:0.267 acc:90.20 | val loss:0.262 acc:90.32\n",
            "Epoch:0516 train loss:0.265 acc:90.44 | val loss:0.261 acc:90.35\n",
            "Epoch:0517 train loss:0.263 acc:90.53 | val loss:0.262 acc:90.25\n",
            "Epoch:0518 train loss:0.265 acc:90.42 | val loss:0.263 acc:90.36\n",
            "Epoch:0519 train loss:0.259 acc:90.56 | val loss:0.262 acc:90.52\n",
            "Epoch:0520 train loss:0.259 acc:90.52 | val loss:0.263 acc:90.25\n",
            "Epoch:0521 train loss:0.262 acc:90.45 | val loss:0.260 acc:90.35\n",
            "Epoch:0522 train loss:0.257 acc:90.35 | val loss:0.262 acc:90.52\n",
            "Epoch:0523 train loss:0.258 acc:90.65 | val loss:0.263 acc:90.36\n",
            "Epoch:0524 train loss:0.260 acc:90.43 | val loss:0.258 acc:90.44\n",
            "Epoch:0525 train loss:0.257 acc:90.39 | val loss:0.259 acc:90.33\n",
            "Epoch:0526 train loss:0.262 acc:90.55 | val loss:0.259 acc:90.49\n",
            "Epoch:0527 train loss:0.252 acc:90.63 | val loss:0.263 acc:90.48\n",
            "Epoch:0528 train loss:0.256 acc:90.50 | val loss:0.262 acc:90.52\n",
            "Epoch:0529 train loss:0.261 acc:90.26 | val loss:0.259 acc:90.38\n",
            "9 : 89.60\n",
            "Train cost: 458.7453s\n",
            "Test acc.:89.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bgTlthoO1NY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}